{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import math, pyperclip, os, re\n",
    "from decimal import Decimal as _Decimal\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data types: Real, Complex, Int, Boolean, String, Undefined\n",
    "Data structures: Scalar, Vector, Matrix, ...\n",
    "Variables: v\n",
    "Functions: fun\n",
    "Named operators: v operation u\n",
    "Conversion specifier: 45deg\n",
    "Data properties: object.property\n",
    "Oppertation: Numeric, Sets, Comparison \n",
    "\n",
    "Data Structures\n",
    "Tensor: [a, b,, c, d,,, ...]\n",
    "List: (a, b, c, ...)\n",
    "Function Body: {expression}\n",
    "\n",
    "Implicit Operations\n",
    "2(expression)      *\n",
    "(expression)2      *\n",
    "var(expression)    *\n",
    "fun(parameters)    call\n",
    "\n",
    "Named operators\n",
    "on two values: v operation u\n",
    "on one value: v.operation\n",
    "\n",
    "Input and Output conversion\n",
    "1m + 12cm @ cm\n",
    "2hr + 45min + 1hr + 30min @ datetime\n",
    "0b1100 * 0xFF @ dec\n",
    "\n",
    "Basic Operations:\n",
    "Standard:       | Bitwise: int&bool | Comparison:           | \n",
    "+           add | ~             not | ==             equals | \n",
    "-      subtract | &&            and | !=          not equal | \n",
    "*      multiply | ||             or | <           less than | \n",
    "/        divide | <xor>         xor | >        greater then | \n",
    "//      int div | <<     left shift | <=      less or equal | \n",
    "%       modulus | >>    right shift | >=   greater or equal | \n",
    "^         power |                   |                       | \n",
    "!     factorial |                   |                       | \n",
    "|val|  absolute |                   |                       | \n",
    "=    assignment |                   |                       | \n",
    "\n",
    "Ternary Operators\n",
    "= =                return values = function = body\n",
    "a < x < b          between\n",
    "a if cond else b   \n",
    "\n",
    "Higher Ranking Data Structure Operations:\n",
    "Vector:                 | Matrix:                          | Reductions:\n",
    "<dot>       dot product | <matmul>   matrix multiplication | <all>\n",
    "<cross>   cross product | |mat|                            | <any>\n",
    "|vec|            length | .T              transpose matrix | <\n",
    ".length          length | \n",
    ".angle            angle | \n",
    "\n",
    "\n",
    "\n",
    "1 + sqrt 4\n",
    "1 + sqrt x\n",
    "1 + $4\n",
    "1 + 3 root 8\n",
    "1 + b root x\n",
    "1 + b $ x\n",
    "\n",
    "10 nPr 2\n",
    "n nPr r\n",
    "10 nCr 2\n",
    "n nCr r\n",
    "\n",
    "[1, 2,, 3, 4] # [5, 6,, 7, 8]\n",
    "[1, 2,, 3, 4].T\n",
    "mat1.T\n",
    "\n",
    "5*x\n",
    "\n",
    "sin 30deg\n",
    "sin pi\n",
    "sin2 pi\n",
    "sini 0.5\n",
    "\n",
    "Function definitions\n",
    "fun = x => x^2               single value output\n",
    "fun = x => [x, x*2, x^2]     tensor outputs\n",
    "fun = x => (x, x*2, x^2)     multiple outputs\n",
    "fun = x => {                 piecewise function\n",
    "    0,   if x < 0 ; \n",
    "    x^2, if 0 <= x <= 1 ; \n",
    "    x,   else\n",
    "}\n",
    "\n",
    "fun = (x,y,z) => {\n",
    "    a = x+2 ; \n",
    "    b = y*2 ; \n",
    "    c = z^2 ; \n",
    "    (a,b,c)\n",
    "}\n",
    "\n",
    "if x < 0 do {\n",
    "    x = 0\n",
    "}\n",
    "\n",
    "for i in 0:10 do {\n",
    "    x += i\n",
    "}\n",
    "\n",
    "while x < 0 do {\n",
    "    x += 1\n",
    "}\n",
    "\n",
    "@display = scientific 8\n",
    "@display = hex\n",
    "\n",
    "\n",
    "Statistical Operations:\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Token Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### TokenOperandDefinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class TokenOperandDefinition():\n",
    "    def __init__(self, token, precedence):\n",
    "        \n",
    "        self.token = token\n",
    "        self.precedence = float(precedence)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'TokenOperandDefinition({self.token}, {self.precedence})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### TokenGroupDefinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class TokenGroupDefinition():\n",
    "    def __init__(self, open_token, close_token, function):\n",
    "        \n",
    "        self.open_token = open_token\n",
    "        self.close_token = close_token\n",
    "        \n",
    "        self.function = function\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'TokenGroupDefinition({self.open_token}, {self.close_token})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### TokenNewItemDefinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class TokenNewItemDefinition():\n",
    "    def __init__(self, token, depth):\n",
    "        \n",
    "        self.token = token\n",
    "        self.depth = int(depth)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'TokenNewItemDefinition({self.token}, {self.levels})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Token Tree Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Abstract NodeToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NodeToken():\n",
    "    \"\"\"\n",
    "    represents a token that can be parsed\n",
    "    \"\"\"\n",
    "    \n",
    "    def is_complete(self):\n",
    "        raise Exception('is_complete() not implemented')\n",
    "        \n",
    "    def set_left(self, node):\n",
    "        raise Exception('set_left(node) not implemented')\n",
    "\n",
    "    def set_right(self, node):\n",
    "        raise Exception('set_right(node) not implemented')\n",
    "        \n",
    "    def get_right(self):\n",
    "        raise Exception('get_right() not implemented')\n",
    "        \n",
    "    def get_evaluable(self):\n",
    "        raise Exception('get_evaluable() not implemented')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### NodeBinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NodeBinary(NodeToken):\n",
    "    \"\"\"\n",
    "    represents a token that can be parsed into a value/operation\n",
    "    \"\"\"\n",
    "    def __init__(self, operation_definition, parent=None):\n",
    "        self.parent = parent\n",
    "        self.operation_definition = operation_definition\n",
    "        self.precedence = operation_definition.precedence\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "    \n",
    "    def is_complete(self):\n",
    "        return self.left != None and self.right != None\n",
    "        \n",
    "    def set_left(self, node):\n",
    "        self.left = node\n",
    "        node.parent = self\n",
    "\n",
    "    def set_right(self, node):\n",
    "        self.right = node\n",
    "        node.parent = self\n",
    "        \n",
    "    def get_right(self):\n",
    "        return self.right\n",
    "    \n",
    "    def get_evaluable(self):\n",
    "        return VariableFunction(self.operation_definition.token, (self.left.get_evaluable(), self.right.get_evaluable()))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'NodeBinary({self.operation_definition}, left={self.left}, right={self.right})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### NodeUnaryLeft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NodeUnaryLeft(NodeToken):\n",
    "    \n",
    "    def __init__(self, operation_definition, parent=None):\n",
    "        self.parent = parent\n",
    "        self.operation_definition = operation_definition\n",
    "        self.precedence = operation_definition.precedence\n",
    "        self.child = None\n",
    "    \n",
    "    def is_complete(self):\n",
    "        return self.child != None\n",
    "        \n",
    "    def set_left(self, node):\n",
    "        self.child = node\n",
    "        node.parent = self\n",
    "\n",
    "    def set_right(self, node):\n",
    "        self.child = node\n",
    "        node.parent = self\n",
    "        \n",
    "    def get_right(self):\n",
    "        return self.child\n",
    "    \n",
    "    def get_evaluable(self):\n",
    "        return VariableFunction(self.operation_definition.token, (self.child.get_evaluable(), ))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'NodeUnaryLeft({self.operation_definition}, child={self.child})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### NodeUnaryRight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NodeUnaryRight(NodeToken):\n",
    "    \n",
    "    def __init__(self, operation_definition, parent=None):\n",
    "        self.parent = parent\n",
    "        self.operation_definition = operation_definition\n",
    "        self.precedence = operation_definition.precedence\n",
    "        self.child = None\n",
    "    \n",
    "    def is_complete(self):\n",
    "        return self.child != None\n",
    "        \n",
    "    def set_left(self, node):\n",
    "        self.child = node\n",
    "        node.parent = self\n",
    "\n",
    "    def set_right(self, node):\n",
    "        self.child = node\n",
    "        node.parent = self\n",
    "        \n",
    "    def get_right(self):\n",
    "        return self.child\n",
    "    \n",
    "    def get_evaluable(self):\n",
    "        return VariableFunction(self.operation_definition.token, (self.child.get_evaluable(), ))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'NodeUnaryRight({self.operation_definition}, child={self.child})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### NodeGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NodeGroup(NodeToken):\n",
    "    \n",
    "    def __init__(self, group_definition, parent=None):\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        \n",
    "        self.group_definition = group_definition\n",
    "        self.complete = False\n",
    "        \n",
    "        self.shape = {}\n",
    "        self.sep_count = 0\n",
    "    \n",
    "    def is_complete(self):\n",
    "        return self.complete\n",
    "\n",
    "    def close(self):\n",
    "        self.sep_count = 0\n",
    "        self.complete = True\n",
    "        \n",
    "        expected_size = 1\n",
    "        for d,s in self.shape.items(): expected_size *= s\n",
    "        \n",
    "        assert len(self.children) == expected_size, f'Inconsistent dimensions shape={self.shape}, expected={expected_size}, actual={len(self.children)}'\n",
    "    \n",
    "    def set_right(self, node):\n",
    "        self.children[-1] = node\n",
    "        node.parent = self\n",
    "        \n",
    "    def get_right(self):\n",
    "        return self.children[-1]\n",
    "\n",
    "    def add(self, node):\n",
    "        self.children.append(node)\n",
    "        node.parent = self\n",
    "        \n",
    "        if len(self.shape) > 0 and self.sep_count >= len(self.shape):\n",
    "            for i in range(len(self.shape), self.sep_count+1):\n",
    "                self.shape[i-1] = self.shape.get(i-1, 1)\n",
    "            self.shape[self.sep_count-1] += 1\n",
    "            \n",
    "        self.sep_count = 0\n",
    "        \n",
    "    def increase(self, depth=1):\n",
    "        self.sep_count += depth\n",
    "        \n",
    "        if len(self.shape) == 0:\n",
    "            self.shape[0] = 1\n",
    "        \n",
    "        # ensure minumum number of dimensions exists\n",
    "        for i in range(len(self.shape), self.sep_count+1):\n",
    "            self.shape[i-1] = self.shape.get(i-1, 1)\n",
    "    \n",
    "    def get_shape(self):\n",
    "        shape = list(self.shape.items())\n",
    "        shape.sort(key=lambda x:x[0], reverse=True)\n",
    "        shape = tuple(s for d,s in shape)\n",
    "        return shape\n",
    "    \n",
    "    def get_children(self):\n",
    "        return self.children\n",
    "    \n",
    "    def get_evaluable(self):\n",
    "        \n",
    "        evaluables = [v.get_evaluable() for v in self.children]\n",
    "        \n",
    "        return VariableTensor(evaluables, self.get_shape(), self.group_definition.function)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'NodeGroup({self.group_definition}, children={self.children})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### NodeValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NodeValue(NodeToken):\n",
    "    \n",
    "    def __init__(self, value, value_type, parent=None):\n",
    "        self.parent = parent\n",
    "        self.value = value\n",
    "        self.value_type = value_type\n",
    "    \n",
    "    def is_complete(self):\n",
    "        return True\n",
    "    \n",
    "    def get_evaluable(self):\n",
    "\n",
    "        value = None\n",
    "        if self.value_type == TOKEN_TYPE_STRING:\n",
    "            value = String(self.value)\n",
    "            value = VariableTensor([value], ())\n",
    "            \n",
    "        if self.value_type == TOKEN_TYPE_INTEGER:\n",
    "            value = Integer(self.value)\n",
    "            value = VariableTensor([value], ())\n",
    "            \n",
    "        if self.value_type == TOKEN_TYPE_NUMBER:\n",
    "            value = Real(self.value)\n",
    "            value = VariableTensor([value], ())\n",
    "            \n",
    "        if self.value_type == TOKEN_TYPE_LITERAL:\n",
    "            value = Variable(self.value)\n",
    "        \n",
    "        return value\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'NodeValue({self.value}, {self.value_type})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Evaluable Tree Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Abstract Evaluable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Evaluable():\n",
    "    \"\"\"\n",
    "    represents a node that can be evaluated\n",
    "    \"\"\"\n",
    "    \n",
    "    def eval(self, environment):\n",
    "        raise Exception('eval(environment) not implemented')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Statement - results in one print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Statement():\n",
    "    \n",
    "    def __init__(self, node):\n",
    "        self.node = node\n",
    "        \n",
    "    def eval(self, environment):\n",
    "        \n",
    "        result = self.node.eval(environment)\n",
    "        print(result)\n",
    "        return result\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'Statement({self.node})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### VariableFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class VariableFunction(Evaluable):\n",
    "    \n",
    "    def __init__(self, name, parameters):\n",
    "        self.name = name\n",
    "        self.parameters = parameters\n",
    "        if isinstance(parameters, VariableTensor):\n",
    "            self.parameters = parameters.data\n",
    "    \n",
    "    def eval(self, environment):\n",
    "        \n",
    "        assert self.name in environment, f'Function {self.name} not found'\n",
    "        assert type(environment[self.name]) == FunctionSet, f'{self.name} is not a function'\n",
    "        \n",
    "        return environment[self.name].eval(environment, self.parameters)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'VariableFunction_{self.name}({self.parameters})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Variable(Evaluable):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "    def eval(self, environment):\n",
    "        \n",
    "        if self.name not in environment:\n",
    "            raise Exception(f'Variable {self.name} not found')\n",
    "        \n",
    "        return environment[self.name]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"Variable({self.name})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### VariableTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class VariableTensor(Evaluable):\n",
    "    \n",
    "    def __init__(self, data, shape, function=None):\n",
    "        self.data = data\n",
    "        self.shape = shape\n",
    "        self.function = function\n",
    "    \n",
    "    def eval(self, environment):\n",
    "        \n",
    "        values = [v.eval(environment) for v in self.data]\n",
    "        \n",
    "        if self.function == None and self.shape == ():\n",
    "            return Tensor(values[:1], self.shape)\n",
    "        else:\n",
    "            return self.function(environment, values, self.shape)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'VariableTensor({self.data}, {self.shape})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### DType [DEPRICATED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# class DType():\n",
    "    \n",
    "#     def __init__(self, dtype=None, rank=None, shape=None):\n",
    "#         self.dtype = dtype\n",
    "#         self.rank = rank\n",
    "#         self.shape = shape\n",
    "        \n",
    "#     def __repr__(self):\n",
    "#         return str(self)\n",
    "    \n",
    "#     def __str__(self):\n",
    "#         return f'DType({dtype}, {rank}, {shape})'\n",
    "    \n",
    "#     def __eq__(left, right):\n",
    "#         return left.dtype == right.dtype and left.rank == right.rank and left.shape == right.shape\n",
    "    \n",
    "#     def __lt__(left, right):\n",
    "        \n",
    "#         if issubclass()\n",
    "        \n",
    "        \n",
    "#     def __gt__(left, right):\n",
    "#         return right < left\n",
    "        \n",
    "#     def __le__(left, right):\n",
    "#         return left == right or left < right\n",
    "        \n",
    "#     def __ge__(left, right):\n",
    "#         return left == right or left > right\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Tensor(Evaluable):\n",
    "    \"\"\"\n",
    "    represents a value/tensor of any type, shape and rank\n",
    "    \"\"\"\n",
    "    def __init__(self, data, shape=()):\n",
    "        \n",
    "        data = np.array(data, object)\n",
    "        data = data.reshape((data.size,))\n",
    "        \n",
    "        assert data.size > 0, 'Tensor cannot be empty'\n",
    "        \n",
    "        if all(type(t) == Tensor for t in data):\n",
    "            inner_shape = data[0].shape\n",
    "            assert all(t.shape == inner_shape for t in data), 'Cannot combine tensors of different shapes'\n",
    "            \n",
    "            data = np.concatenate([t.data for t in data])\n",
    "            shape = shape + inner_shape\n",
    "        \n",
    "        self._data = np.array(data, object).reshape(shape)\n",
    "        self.data = self._data.reshape((self._data.size))\n",
    "        \n",
    "        self.first = self.data[0]\n",
    "        self.shape = self._data.shape\n",
    "        self.size = self._data.size\n",
    "        self.rank = self._data.ndim\n",
    "        self.dtype = type(self.data[0])\n",
    "        \n",
    "        assert all([type(i) == self.dtype for i in self.data]), 'All items in a Tensor must be of the same type'\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        data = self.data[index] if type(index) == int else self._data[index]\n",
    "        shape = data.shape if type(data) == np.ndarray else ()\n",
    "            \n",
    "        return Tensor(data, shape)\n",
    "        \n",
    "    def __setitem__(self, index, value):\n",
    "        \n",
    "        if type(value) == Tensor:\n",
    "            value = value._data\n",
    "        \n",
    "        if type(index) == int:\n",
    "            self.data[index] = value\n",
    "        else:\n",
    "            self._data[index] = value\n",
    "    \n",
    "    def eval(self, environment):\n",
    "        return self\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        \n",
    "        if self.rank == 0:\n",
    "            return f'Tensor({self.data[()]})'\n",
    "        else:\n",
    "            return f'Tensor({self.data}, {self.shape})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Array(Evaluable):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = np.array(data, object)\n",
    "        self.data = self.data.reshape((self.data.size,))\n",
    "        self.size = self.data.size\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return Array(self.data[index])\n",
    "        \n",
    "    def __setitem__(self, index, value):\n",
    "        self.data[index] = value\n",
    "    \n",
    "    def eval(self, environment):\n",
    "        return self\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'Array({self.data[()]})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### FunctionSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class FunctionSet(Evaluable):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.signatures = {}\n",
    "        \n",
    "    def __contains__(self, partial_signature):\n",
    "        l = len(partial_signature)\n",
    "        for signature in self.signatures:\n",
    "            if signature[:l] == partial_signature:\n",
    "                return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    def __getitem__(self, signature):\n",
    "        return self.signatures[signature]\n",
    "    \n",
    "    def __setitem__(self, signature, value):\n",
    "        par_names, function = value\n",
    "        self.signatures[signature] = (par_names, function)\n",
    "        \n",
    "    def add(self, function_signature):\n",
    "        self.signatures[function_signature.parameter_types] = function_signature\n",
    "        \n",
    "    def eval(self, environment, parameters):\n",
    "        \n",
    "        parameters = list(parameters)\n",
    "        signature = [type(p) for p in parameters]\n",
    "        \n",
    "        for i, parameter in enumerate(parameters):\n",
    "            if tuple(signature[:i+1]) not in self:\n",
    "                parameters[i] = parameter.eval(environment)\n",
    "                signature[i] = parameters[i].dtype\n",
    "        \n",
    "        signature = tuple(signature)\n",
    "        \n",
    "        assert signature in self.signatures, f'Signature {self.name}{tuple(p.__name__ for p in signature)} has no matching overload'\n",
    "            \n",
    "        function_signature = self.signatures[signature]\n",
    "        \n",
    "        function = function_signature.function\n",
    "        parameter_names = function_signature.parameter_names\n",
    "        \n",
    "        actual_shapes = [p.shape if type(p) == Tensor else () for p in parameters]\n",
    "        actual_ranks = [len(s) for s in actual_shapes]\n",
    "        \n",
    "        ranks = [r if r!=None else a for r,a in zip(function_signature.parameter_ranks, actual_ranks)]\n",
    "        extended_shapes = [s if r==0 else s[:-r] for s,r in zip(actual_shapes, ranks)]\n",
    "        \n",
    "        extended_shape = reduce(lambda x,y: x if len(x) > len(y) else y, extended_shapes)\n",
    "        extended_ranks = [len(s) for s in extended_shapes]\n",
    "        \n",
    "        assert all([s in [extended_shape, ()] for s in extended_shapes]), f'Ranks, shape or extended shapes do not match'\n",
    "        \n",
    "        if extended_shape == ():\n",
    "            return self.runFunction(function, environment, parameter_names, parameters)\n",
    "        \n",
    "        else:\n",
    "            data = np.empty(extended_shape, dtype=object)\n",
    "            \n",
    "            for i in product(*[range(d) for d in extended_shape]):\n",
    "                extracted_parameters = [p if r == 0 else p[i] for p, r in zip(parameters, extended_ranks)]\n",
    "                \n",
    "                data[i] = self.runFunction(function, environment, parameter_names, extracted_parameters)._data.tolist()\n",
    "                    \n",
    "            data = np.array(data.tolist())\n",
    "            \n",
    "            return Tensor(data, data.shape)\n",
    "        \n",
    "    def runFunction(self, function, environment, parameter_names, parameters):\n",
    "        \n",
    "        if parameter_names == None:\n",
    "            return function(*parameters)\n",
    "\n",
    "        else:\n",
    "            new_scoped_environment = {**environment, **{k:v for k,v in zip(parameter_names, parameters)}}\n",
    "            return function(new_scoped_environment)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'FunctionSet({self.name}, {self.signatures})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Abstract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Data(Evaluable):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class String(Data):\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "    \n",
    "    def eval(self, environment):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Integer(Data):\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "    \n",
    "    def eval(self, environment):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Real(Data):\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        self.value = float(value)\n",
    "    \n",
    "    def eval(self, environment):\n",
    "        return self\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'Real({self.value})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Boolean(Data):\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "    \n",
    "    def eval(self, environment):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### FunctionSignature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class FunctionSignature():\n",
    "    \n",
    "    def __init__(self, name, function, parameter_names, parameter_types, parameter_ranks=None, parameter_shapes=None):\n",
    "        \n",
    "        self.name = name\n",
    "        self.function = function\n",
    "        self.parameter_count = len(parameter_types)\n",
    "        self.parameter_names = parameter_names\n",
    "        self.parameter_types = parameter_types\n",
    "        self.parameter_ranks = parameter_ranks or self.parameter_count*(None,)\n",
    "        self.parameter_shapes = parameter_shapes or self.parameter_count*(None,)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'FunctionSignature{(self.name, self.function, self.parameter_names, self.parameter_types, self.parameter_ranks, self.parameter_shapes)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Function [DEPTRICATED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# class Function(Data):\n",
    "        \n",
    "#     def __init__(self, name):\n",
    "#         self.name = name\n",
    "#         self.signatures = {}\n",
    "    \n",
    "#     def eval(self, environment, parameters):\n",
    "        \n",
    "#         signature = tuple(p.dtype for p in parameters)\n",
    "#         print('Function','eval', 'parameters', parameters, 'signature', signature)\n",
    "            \n",
    "#         function, parameter_names = None, []\n",
    "        \n",
    "#         for candidate_signature in self.signatures:\n",
    "            \n",
    "#             if len(signature) != len(candidate_signature):\n",
    "#                 continue\n",
    "            \n",
    "#             if all(issubclass(a,b) for a,b in zip(signature, candidate_signature)):\n",
    "#                 parameter_names, function = self.signatures[candidate_signature]\n",
    "#                 break;\n",
    "                \n",
    "#         if function == None:\n",
    "#             raise Exception(f'Signature {self.name}{tuple(p.__name__ for p in signature)} has no matching overload')\n",
    "        \n",
    "#         new_scoped_environment = {**environment, **{k:v for k,v in zip(parameter_names, parameters)}}\n",
    "        \n",
    "#         return function(new_scoped_environment)\n",
    "    \n",
    "#     def __getitem__(self, signature):\n",
    "#         return self.signatures[signature]\n",
    "    \n",
    "#     def __setitem__(self, signature, value):\n",
    "#         self.signatures[signature] = value\n",
    "        \n",
    "#     def __repr__(self):\n",
    "#         return str(self)\n",
    "    \n",
    "#     def __str__(self):\n",
    "#         return f'Function({self.name}, {self.signatures})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built In Functions, Operators and Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### BuiltIns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class BuiltIns():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.functions = []\n",
    "        self.vars = []\n",
    "        self.binary_operators = []\n",
    "        self.left_unary_operators = []\n",
    "        self.right_unary_operators = []\n",
    "        self.groups = []\n",
    "        self.new_items = []\n",
    "        \n",
    "    def register_function(self, name, function, parameter_names, parameter_types, parameter_ranks=None, parameter_shapes=None):\n",
    "        self.functions.append((name, function, parameter_names, parameter_types, parameter_ranks, parameter_shapes))\n",
    "        \n",
    "    def register_binary_operator(self, name, function, precedence, parameter_names, parameter_types, parameter_ranks=None, parameter_shapes=None):\n",
    "        self.register_function(name, function, parameter_names, parameter_types, parameter_ranks, parameter_shapes)\n",
    "        self.binary_operators.append(TokenOperandDefinition(name, precedence))\n",
    "        \n",
    "    def register_left_unary_operator(self, name, function, precedence, parameter_names, parameter_types, parameter_ranks=None, parameter_shapes=None):\n",
    "        self.register_function(name, function, parameter_names, parameter_types, parameter_ranks, parameter_shapes)\n",
    "        self.left_unary_operators.append(TokenOperandDefinition(name, precedence))\n",
    "        \n",
    "    def register_right_unary_operator(self, name, function, precedence, parameter_names, parameter_types, parameter_ranks=None, parameter_shapes=None):\n",
    "        self.register_function(name, function, parameter_names, parameter_types, parameter_ranks, parameter_shapes)\n",
    "        self.right_unary_operators.append(TokenOperandDefinition(name, precedence))\n",
    "        \n",
    "    def register_var(self, name, value):\n",
    "        self.vars.append((name, value))\n",
    "        \n",
    "    def register_grouping(self, open_token, close_token, function):\n",
    "        self.groups.append(TokenGroupDefinition(open_token, close_token, function))\n",
    "        \n",
    "    def register_new_item_seperator(self, token, depth):\n",
    "        self.new_items.append(TokenNewItemDefinition(token, depth))\n",
    "        \n",
    "        \n",
    "built_ins = BuiltIns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Group ( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def group_round(environment, items, shape):\n",
    "    \n",
    "    if shape == ():\n",
    "        print(items)\n",
    "        return items[0]\n",
    "    else:\n",
    "        return Array(items)\n",
    "\n",
    "built_ins.register_grouping('(', ')', group_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Group [ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def group_squre(environment, items, shape):\n",
    "    \n",
    "    assert len(items) > 0, 'Tensors can not be empty'\n",
    "    \n",
    "    base_shape = items[0].shape\n",
    "    assert all([i.shape == base_shape for i in items]), 'Tensor elements have inconsistent shapes'\n",
    "    \n",
    "    extended_shape = shape + base_shape\n",
    "    data = np.array([i.data for i in items]).reshape(extended_shape)\n",
    "    \n",
    "    return Tensor(data, extended_shape)\n",
    "\n",
    "built_ins.register_grouping('[', ']', group_squre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Group { }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Group | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def group_straight(environment, items, shape):\n",
    "    \n",
    "    assert shape == (), 'Cannot take absolute value of an array'\n",
    "    assert items[0].dtype == Real, 'Cannot take absolute value of non Real value'\n",
    "    \n",
    "#     return Tensor(Real(abs(items[0].first.value)))\n",
    "\n",
    "    return VariableFunction('abs', items).eval(environment)\n",
    "\n",
    "built_ins.register_grouping('|', '|', group_straight)\n",
    "built_ins.register_grouping('||', '||', group_straight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### New Item Seperators ',' and ';'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "built_ins.register_new_item_seperator(',', 1)\n",
    "built_ins.register_new_item_seperator(';', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Variabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "built_ins.register_var('PI', Tensor([Real(3.141592653589793238462643383279502884197)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Binary Operantors: +, -, *, /, //, %, ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# A + B\n",
    "built_ins.register_binary_operator('+', lambda a, b: Tensor(Real(a.first.value + b.first.value)), 3, None, (Real, Real), (0, 0))\n",
    "\n",
    "# A - B\n",
    "built_ins.register_binary_operator('-', lambda a, b: Tensor(Real(a.first.value - b.first.value)), 3, None, (Real, Real), (0, 0))\n",
    "\n",
    "# A * B\n",
    "built_ins.register_binary_operator('*', lambda a, b: Tensor(Real(a.first.value * b.first.value)), 4, None, (Real, Real), (0, 0))\n",
    "\n",
    "# A / B\n",
    "built_ins.register_binary_operator('/', lambda a, b: Tensor(Real(a.first.value / b.first.value)), 4, None, (Real, Real), (0, 0))\n",
    "\n",
    "# A // B\n",
    "built_ins.register_binary_operator('//', lambda a, b: Tensor(Real(a.first.value // b.first.value)), 4, None, (Real, Real), (0, 0))\n",
    "\n",
    "# A % B\n",
    "built_ins.register_binary_operator('%', lambda a, b: Tensor(Real(a.first.value % b.first.value)), 4, None, (Real, Real), (0, 0))\n",
    "\n",
    "# A ^ B\n",
    "built_ins.register_binary_operator('^', lambda a, b: Tensor(Real(a.first.value ** b.first.value)), 5, None, (Real, Real), (0, 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Matrix Multiplication: # #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def matmul(A, B):\n",
    "    \n",
    "    a_shape = A.shape\n",
    "    b_shape = B.shape\n",
    "    \n",
    "    assert A.rank >= 2 and B.rank >= 2, 'left and right sides must be matrices'\n",
    "    assert a_shape[-1] == b_shape[-2], 'left n_cols must equal right n_rows'\n",
    "    \n",
    "    n_rows = a_shape[0]\n",
    "    n_cols = b_shape[1]\n",
    "    n_vec = a_shape[1]\n",
    "    shape = (n_rows , n_cols)\n",
    "    \n",
    "    data = np.empty(shape, dtype=object)\n",
    "    \n",
    "    for row in range(n_rows):\n",
    "        for col in range(n_cols):\n",
    "            v = 0\n",
    "            for i in range(n_vec):\n",
    "                v += A[(row, i)].first.value * B[(i, col)].first.value\n",
    "            data[row,col] = Real(v)\n",
    "    \n",
    "    return Tensor(data, shape)\n",
    "\n",
    "built_ins.register_binary_operator('#', matmul, 4, None, (Real, Real), (2, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Absolute value abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def absolute(A):\n",
    "    return Tensor(Real(abs(A.first.value)))\n",
    "\n",
    "built_ins.register_left_unary_operator('abs', absolute, 2, None, (Real,), (0,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Define Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Tokens Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "# operand kinds\n",
    "# group, close_group, return_to_group, binary, unary_left, unary_right, *_ = enum(10)\n",
    "# (\n",
    "#     OPERAND_TYPE_GROUP, \n",
    "#     OPERAND_TYPE_CLOSE_GROUP, \n",
    "#     OPERAND_TYPE_RETURN_TO_GROUP, \n",
    "#     OPERAND_TYPE_BINARY, \n",
    "#     OPERAND_TYPE_UNARY_LEFT, \n",
    "#     OPERAND_TYPE_UNARY_RIGHT, \n",
    "# *_) = enum(10)\n",
    "\n",
    "\n",
    "TOKEN_TYPE_STRING =   'string'\n",
    "TOKEN_TYPE_INTEGER =  'integer'\n",
    "TOKEN_TYPE_NUMBER =   'number'\n",
    "TOKEN_TYPE_OPERATOR = 'operand'\n",
    "TOKEN_TYPE_OPEN_GROUP =    'group'\n",
    "TOKEN_TYPE_LITERAL =  'literal'\n",
    "\n",
    "TOKEN_TYPE_OPEN_GROUP = 'open group'\n",
    "TOKEN_TYPE_CLOSE_GROUP = 'close group'\n",
    "TOKEN_TYPE_NEW_ITEM    = 'new item'\n",
    "TOKEN_TYPE_BINARY      = 'binary operand'\n",
    "TOKEN_TYPE_UNARY_LEFT  = 'left unary operand'\n",
    "TOKEN_TYPE_UNARY_RIGHT = 'right unary operand'\n",
    "\n",
    "OPERAND_TYPES = [\n",
    "    TOKEN_TYPE_OPEN_GROUP,\n",
    "    TOKEN_TYPE_CLOSE_GROUP, \n",
    "    TOKEN_TYPE_NEW_ITEM, \n",
    "    TOKEN_TYPE_BINARY, \n",
    "    TOKEN_TYPE_UNARY_LEFT, \n",
    "    TOKEN_TYPE_UNARY_RIGHT, \n",
    "]\n",
    "\n",
    "TOKEN_TYPE_VALUE = [\n",
    "    TOKEN_TYPE_STRING,\n",
    "    TOKEN_TYPE_INTEGER,\n",
    "    TOKEN_TYPE_NUMBER,\n",
    "    TOKEN_TYPE_LITERAL,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Token Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# binary_operands = [\n",
    "#     Operand(r'.',   8), \n",
    "#     Operand(r':',   6), \n",
    "#     Operand(r'^',   5), \n",
    "#     Operand(r'*',   4), \n",
    "#     Operand(r'/',   4), \n",
    "#     Operand(r'//',  4), \n",
    "#     Operand(r'%',   4), \n",
    "#     Operand(r'+',   3), \n",
    "#     Operand(r'-',   3), \n",
    "#     Operand(r'&&',  2), \n",
    "#     Operand(r'||',  2), \n",
    "#     Operand(r'xor', 2), \n",
    "#     Operand(r'==',  1), \n",
    "#     Operand(r'!=',  1), \n",
    "#     Operand(r'>',   1), \n",
    "#     Operand(r'>=',  1), \n",
    "#     Operand(r'<',   1), \n",
    "#     Operand(r'<=',  1), \n",
    "#     Operand(r'=',   0),\n",
    "# ]\n",
    "\n",
    "# binary_operands = built_ins.binary_operators\n",
    "\n",
    "# left_unary_operands = [\n",
    "#     Operand(r'+', 7), \n",
    "#     Operand(r'-', 7), \n",
    "#     Operand(r'~', 7), \n",
    "#     Operand(r'=', 0),\n",
    "# ]\n",
    "\n",
    "# right_unary_operands = [\n",
    "#     Operand(r'!', 7),\n",
    "# ]\n",
    "\n",
    "# new_item = [\n",
    "#     TokenNewItemDefinition(',', 1),\n",
    "#     TokenNewItemDefinition(';', 2),\n",
    "# ]\n",
    "\n",
    "# groups = [\n",
    "#     Group(r'\\(', r')'),\n",
    "#     Group(r'\\[', r']'),\n",
    "#     Group(r'\\{', r'}'),\n",
    "#     Group(r'[a-zA-Z][a-zA-Z0-9_]*\\(', r')'),\n",
    "# ]\n",
    "\n",
    "# close_group = [Operand(g.close_op, -1) for g in groups]\n",
    "\n",
    "# sort by length\n",
    "# binary_operands.sort(key = lambda o:(len(o.match), o.precedence), reverse=True)\n",
    "# left_unary_operands.sort(key = lambda o:(len(o.match), o.precedence), reverse=True)\n",
    "# right_unary_operands.sort(key = lambda o:(len(o.match), o.precedence), reverse=True)\n",
    "# new_item.sort(key = lambda o:(len(o.match), o.precedence), reverse=True)\n",
    "\n",
    "# (\n",
    "#     binary_operands,\n",
    "#     left_unary_operands,\n",
    "#     right_unary_operands,\n",
    "#     new_item,\n",
    "#     close_group,\n",
    "# )\n",
    "\n",
    "# TODO sort built in tokens\n",
    "\n",
    "token_definitions = {\n",
    "    TOKEN_TYPE_OPEN_GROUP:  built_ins.groups,\n",
    "    TOKEN_TYPE_CLOSE_GROUP: built_ins.groups, \n",
    "    TOKEN_TYPE_NEW_ITEM:    built_ins.new_items, \n",
    "    TOKEN_TYPE_BINARY:      built_ins.binary_operators, \n",
    "    TOKEN_TYPE_UNARY_LEFT:  built_ins.left_unary_operators, \n",
    "    TOKEN_TYPE_UNARY_RIGHT: built_ins.right_unary_operators, \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Operation Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def find_token_definition(string, token_type, f = lambda x:x.token):\n",
    "    for token_definition in token_definitions[token_type]:\n",
    "        if string == f(token_definition):\n",
    "#         if re.fullmatch(operator.re_match, string) != None:\n",
    "            return token_definition\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Define Token Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'string': '((\\\\\"\"\".*?\\\\\"\"\")|(\\'\\'\\'.*?\\'\\'\\')|(\".*?\")|(\\'.*?\\'))',\n",
       " 'integer': '((0b|0o|0d|0x|[0-9]+_)[0-9a-zA-Z,]+)',\n",
       " 'number': '((([\\\\.][0-9]+)|([0-9]+[\\\\.]?[0-9]*))([eE][-+]?[0-9]+)?[a-z]*)',\n",
       " 'literal': '([A-Za-z_][A-Za-z0-9_]*)',\n",
       " 'open group': '(\\\\|\\\\|)|(\\\\()|(\\\\[)|(\\\\|)',\n",
       " 'binary operand': '(\\\\/\\\\/)|(\\\\+)|(\\\\-)|(\\\\*)|(\\\\/)|(\\\\%)|(\\\\^)|(\\\\#)',\n",
       " 'left unary operand': '()',\n",
       " 'right unary operand': '()',\n",
       " 'new item': '(\\\\,)|(\\\\;)',\n",
       " 'close group': '(\\\\|\\\\|)|(\\\\))|(\\\\])|(\\\\|)'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def re_join(l, f=lambda x:x):\n",
    "    items = [f(i) for i in l]\n",
    "    items.sort(key=lambda x:len(x), reverse=True)\n",
    "    return '(' + ')|('.join([re.escape(i) for i in items]) + ')'\n",
    "\n",
    "# regex\n",
    "re_number =    r\"\"\"((([\\.][0-9]+)|([0-9]+[\\.]?[0-9]*))([eE][-+]?[0-9]+)?[a-z]*)\"\"\"\n",
    "re_integer =   r\"\"\"((0b|0o|0d|0x|[0-9]+_)[0-9a-zA-Z,]+)\"\"\"\n",
    "re_string =    r\"\"\"((\\\"\"\".*?\\\"\"\")|('''.*?''')|(\".*?\")|('.*?'))\"\"\"\n",
    "re_literal =   r\"\"\"([A-Za-z_][A-Za-z0-9_]*)\"\"\"\n",
    "\n",
    "\n",
    "re_open_group =           re_join(built_ins.groups, lambda x:x.open_token)\n",
    "re_close_group =          re_join(built_ins.groups, lambda x:x.close_token)\n",
    "re_binary_operands =      re_join(built_ins.binary_operators, lambda x:x.token)\n",
    "re_left_unary_operands =  re_join(built_ins.left_unary_operators, lambda x:x.token)\n",
    "re_right_unary_operands = re_join(built_ins.right_unary_operators, lambda x:x.token)\n",
    "re_new_item =             re_join(built_ins.new_items, lambda x:x.token)\n",
    "\n",
    "\n",
    "re_tokens = {\n",
    "    TOKEN_TYPE_STRING:      re_string,\n",
    "    TOKEN_TYPE_INTEGER:     re_integer,\n",
    "    TOKEN_TYPE_NUMBER:      re_number,\n",
    "    TOKEN_TYPE_LITERAL:     re_literal,\n",
    "    TOKEN_TYPE_OPEN_GROUP:  re_open_group,\n",
    "    TOKEN_TYPE_BINARY:      re_binary_operands,\n",
    "    TOKEN_TYPE_UNARY_LEFT:  re_left_unary_operands,\n",
    "    TOKEN_TYPE_UNARY_RIGHT: re_right_unary_operands,\n",
    "    TOKEN_TYPE_NEW_ITEM:    re_new_item,\n",
    "    TOKEN_TYPE_CLOSE_GROUP: re_close_group,\n",
    "}\n",
    "\n",
    "re_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Lexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def re_match_length(string, re_pattern):\n",
    "    match = re.match(re_pattern, string)\n",
    "    return match.span()[1] if match != None else 0\n",
    "\n",
    "# TOKEN_TYPE_STRING\n",
    "# TOKEN_TYPE_INTEGER\n",
    "# TOKEN_TYPE_NUMBER\n",
    "# TOKEN_TYPE_LITERAL\n",
    "\n",
    "# TOKEN_TYPE_OPEN_GROUP\n",
    "# TOKEN_TYPE_BINARY\n",
    "# TOKEN_TYPE_UNARY_LEFT\n",
    "# TOKEN_TYPE_UNARY_RIGHT\n",
    "# TOKEN_TYPE_NEW_ITEM\n",
    "# TOKEN_TYPE_CLOSE_GROUP\n",
    "\n",
    "def lexing(string, ans_available=False):\n",
    "    tokens = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(string):\n",
    "            \n",
    "        last_token_type = tokens[-1][0] if len(tokens) > 0 else None\n",
    "        allowed_token_types = []\n",
    "\n",
    "        # begin with\n",
    "        if last_token_type in [\n",
    "            None,\n",
    "        ]:\n",
    "            \n",
    "            allowed_token_types = [TOKEN_TYPE_BINARY] if ans_available else []\n",
    "            allowed_token_types += [\n",
    "                TOKEN_TYPE_UNARY_LEFT,\n",
    "                TOKEN_TYPE_OPEN_GROUP,\n",
    "                TOKEN_TYPE_NEW_ITEM,\n",
    "                TOKEN_TYPE_CLOSE_GROUP,\n",
    "                *TOKEN_TYPE_VALUE,\n",
    "            ]\n",
    "        \n",
    "        if last_token_type in [\\\n",
    "            TOKEN_TYPE_OPEN_GROUP,\n",
    "            TOKEN_TYPE_NEW_ITEM,\n",
    "        ]:\n",
    "            allowed_token_types = [\n",
    "                TOKEN_TYPE_UNARY_LEFT,\n",
    "                TOKEN_TYPE_OPEN_GROUP,\n",
    "                TOKEN_TYPE_NEW_ITEM,\n",
    "                TOKEN_TYPE_CLOSE_GROUP,\n",
    "                *TOKEN_TYPE_VALUE,\n",
    "            ]\n",
    "\n",
    "        # after value\n",
    "        if last_token_type in [\n",
    "            TOKEN_TYPE_CLOSE_GROUP,\n",
    "            TOKEN_TYPE_UNARY_RIGHT,\n",
    "            *TOKEN_TYPE_VALUE,\n",
    "        ]:\n",
    "            allowed_token_types = [\n",
    "                TOKEN_TYPE_UNARY_RIGHT,\n",
    "                TOKEN_TYPE_BINARY,\n",
    "                TOKEN_TYPE_NEW_ITEM,\n",
    "                TOKEN_TYPE_CLOSE_GROUP,\n",
    "            ]\n",
    "\n",
    "        # after operator\n",
    "        if last_token_type in [\n",
    "            TOKEN_TYPE_BINARY,\n",
    "            TOKEN_TYPE_UNARY_LEFT,\n",
    "\n",
    "        ]:\n",
    "            allowed_token_types = [\n",
    "                TOKEN_TYPE_OPEN_GROUP,\n",
    "                TOKEN_TYPE_UNARY_LEFT,\n",
    "                *TOKEN_TYPE_VALUE,\n",
    "            ]\n",
    "            \n",
    "        \n",
    "        # find matching token type\n",
    "        token_type, token_str = None, None\n",
    "        \n",
    "        for possible_token_type in allowed_token_types:\n",
    "            re_pattern = re_tokens[possible_token_type]\n",
    "            \n",
    "            l = re_match_length(string[i:], re_pattern)\n",
    "            if l > 0:\n",
    "                token_type = possible_token_type\n",
    "                token_str = string[i:i+l]\n",
    "                break\n",
    "                \n",
    "\n",
    "                    \n",
    "        # invalid token\n",
    "        if token_type == None:\n",
    "#             raise Exception(f\"Token not allowed at position {i}\")\n",
    "            i += 1\n",
    "        else:\n",
    "            tokens.append((token_type, token_str))\n",
    "            i += len(token_str)\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Treeify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bubble_up(focus, new):\n",
    "    \"\"\"\n",
    "    Finds ancestor/parent in tree upwards from `token` thats the first group token or the first\n",
    "    \"\"\"\n",
    "    \n",
    "    while True:\n",
    "#         print('bubble_up', focus.value, type(focus))\n",
    "#         if type(focus) != NodeValue and (type(focus) == NodeGroup or focus.precedence < new.precedence):\n",
    "        if type(focus) == NodeGroup or focus.precedence < new.precedence:\n",
    "#             print('return', focus.value)\n",
    "            return focus\n",
    "        else:\n",
    "            focus = focus.parent\n",
    "        \n",
    "def bubble_up_to_group(focus):\n",
    "    while True:\n",
    "        if type(focus) == NodeGroup:\n",
    "            return focus\n",
    "        else:\n",
    "            focus = focus.parent\n",
    "\n",
    "# TOKEN_TYPE_STRING\n",
    "# TOKEN_TYPE_INTEGER\n",
    "# TOKEN_TYPE_NUMBER\n",
    "# TOKEN_TYPE_LITERAL\n",
    "\n",
    "# TOKEN_TYPE_OPEN_GROUP\n",
    "# TOKEN_TYPE_BINARY\n",
    "# TOKEN_TYPE_UNARY_LEFT\n",
    "# TOKEN_TYPE_UNARY_RIGHT\n",
    "\n",
    "# TOKEN_TYPE_NEW_ITEM\n",
    "# TOKEN_TYPE_CLOSE_GROUP\n",
    "\n",
    "def build_token_tree(tokens):\n",
    "    \n",
    "    root = NodeGroup(\"ROOT\", None)\n",
    "    focus = root\n",
    "    \n",
    "    for token_type, value in tokens:\n",
    "        \n",
    "        \n",
    "        # focus is\n",
    "        # Binary Operator\n",
    "        # Unary Operator\n",
    "        if type(focus) in [\n",
    "            NodeBinary,\n",
    "            NodeUnaryLeft,\n",
    "        ]:\n",
    "            \n",
    "            # next is \n",
    "            # Unary left\n",
    "            if token_type == TOKEN_TYPE_UNARY_LEFT:\n",
    "#                 print('insert lef unary')\n",
    "                \n",
    "                operand = find_token_definition(value, TOKEN_TYPE_UNARY_LEFT)\n",
    "                next_node = NodeUnaryLeft(operand)\n",
    "                \n",
    "                focus.set_right(next_node)\n",
    "                focus = next_node\n",
    "                \n",
    "            # next is\n",
    "            # Group\n",
    "            elif token_type == TOKEN_TYPE_OPEN_GROUP:\n",
    "#                 print('insert open group')\n",
    "                \n",
    "                group = find_token_definition(value, TOKEN_TYPE_OPEN_GROUP, lambda x:x.open_token)\n",
    "                next_node = NodeGroup(group)\n",
    "                focus.set_right(next_node)\n",
    "                focus = next_node\n",
    "            \n",
    "            # next is\n",
    "            # TOKEN_TYPE_STRING\n",
    "            # TOKEN_TYPE_INTEGER\n",
    "            # TOKEN_TYPE_NUMBER\n",
    "            # TOKEN_TYPE_LITERAL\n",
    "            elif token_type in TOKEN_TYPE_VALUE:\n",
    "#                 print('insert value')\n",
    "                \n",
    "                next_node = NodeValue(value, token_type)\n",
    "                focus.set_right(next_node)\n",
    "                focus = next_node\n",
    "                \n",
    "            else:\n",
    "                raise Exception(f\"token '{value}' not allowed here\")\n",
    "            \n",
    "            \n",
    "        # focus is\n",
    "        # Value\n",
    "        # Closed Group\n",
    "        elif type(focus) == NodeValue or (type(focus) == NodeGroup and focus.is_complete()):\n",
    "            \n",
    "            # next is\n",
    "            # Binary\n",
    "            if token_type == TOKEN_TYPE_BINARY:\n",
    "#                 print('insert binary')\n",
    "                \n",
    "                operand = find_token_definition(value, TOKEN_TYPE_BINARY)\n",
    "                next_node = NodeBinary(operand)\n",
    "                    \n",
    "                parent_node = bubble_up(focus.parent, next_node)\n",
    "                child_node = parent_node.get_right()\n",
    "                parent_node.set_right(next_node)\n",
    "                next_node.set_left(child_node)\n",
    "                focus = next_node\n",
    "                \n",
    "            \n",
    "            # next is\n",
    "            # Unary right\n",
    "            elif token_type == TOKEN_TYPE_UNARY_RIGHT:\n",
    "#                 print('insert right unary')\n",
    "                \n",
    "                operand = find_token_definition(value, TOKEN_TYPE_UNARY_RIGHT)\n",
    "                next_node = NodeUnaryRight(operand)\n",
    "                    \n",
    "                parent_node = focus.parent # bubble_up(focus.parent, next_node)\n",
    "                child_node = parent_node.get_right()\n",
    "                parent_node.set_right(next_node)\n",
    "                next_node.set_left(child_node)\n",
    "                # focus = next_node\n",
    "            \n",
    "            # next is\n",
    "            # New item\n",
    "            elif token_type == TOKEN_TYPE_NEW_ITEM:\n",
    "#                 print('new item')\n",
    "                \n",
    "                token_definition = find_token_definition(value, TOKEN_TYPE_NEW_ITEM)\n",
    "    \n",
    "                parent_node = bubble_up_to_group(focus.parent)\n",
    "                parent_node.increase(token_definition.depth)\n",
    "                focus = parent_node\n",
    "            \n",
    "            # next is\n",
    "            # New item\n",
    "            elif token_type == TOKEN_TYPE_CLOSE_GROUP:\n",
    "#                 print('close group')\n",
    "                \n",
    "                parent_node = bubble_up_to_group(focus.parent)\n",
    "                parent_node.close()\n",
    "                focus = parent_node\n",
    "            \n",
    "            # next is\n",
    "            else:\n",
    "                raise Exception(f\"token '{value}' not allowed here\")\n",
    "#                 print('start new item in parent group')\n",
    "        \n",
    "        \n",
    "        # focus is\n",
    "        # Open Group\n",
    "        elif type(focus) == NodeGroup and not focus.is_complete(): \n",
    "            \n",
    "            # next is\n",
    "            # Binary - use ans on left\n",
    "            if token_type == TOKEN_TYPE_BINARY:\n",
    "#                 print('insert binary with ans as left')\n",
    "\n",
    "                left = NodeValue('ans', TOKEN_TYPE_LITERAL)\n",
    "                \n",
    "                operand = find_token_definition(value, TOKEN_TYPE_BINARY)\n",
    "                next_node = NodeBinary(operand)\n",
    "                next_node.set_left(left)\n",
    "                \n",
    "                focus.add(next_node)\n",
    "                focus = next_node\n",
    "            \n",
    "            # next is\n",
    "            # Unary left\n",
    "            elif token_type == TOKEN_TYPE_UNARY_LEFT:\n",
    "#                 print('add unary left')\n",
    "                \n",
    "                operand = find_token_definition(value, TOKEN_TYPE_UNARY_LEFT)\n",
    "                next_node = NodeUnaryLeft(operand)\n",
    "                \n",
    "                focus.add(next_node)\n",
    "                focus = next_node\n",
    "            \n",
    "            # next is\n",
    "            # Group\n",
    "            elif token_type == TOKEN_TYPE_OPEN_GROUP:\n",
    "#                 print('add open group')\n",
    "                \n",
    "                group = find_token_definition(value, TOKEN_TYPE_OPEN_GROUP, lambda x:x.open_token)\n",
    "                next_node = NodeGroup(group)\n",
    "                focus.add(next_node)\n",
    "                focus = next_node\n",
    "            \n",
    "            # next is\n",
    "            # New item\n",
    "            elif token_type == TOKEN_TYPE_CLOSE_GROUP:\n",
    "#                 print('close group')\n",
    "                \n",
    "                focus.close()\n",
    "            \n",
    "            # next is\n",
    "            # TOKEN_TYPE_STRING\n",
    "            # TOKEN_TYPE_INTEGER\n",
    "            # TOKEN_TYPE_NUMBER\n",
    "            # TOKEN_TYPE_LITERAL\n",
    "            elif token_type in TOKEN_TYPE_VALUE:\n",
    "#                 print('add value')\n",
    "                \n",
    "                next_node = NodeValue(value, token_type)\n",
    "                focus.add(next_node)\n",
    "                focus = next_node\n",
    "                \n",
    "            # next is \n",
    "            # TOKEN_TYPE_NEW_ITEM\n",
    "            elif token_type == TOKEN_TYPE_NEW_ITEM:\n",
    "#                 print('new item/dimension')\n",
    "                \n",
    "                focus.increase()\n",
    "                \n",
    "            # next is\n",
    "            else:\n",
    "                raise Exception(f\"token '{value}' not allowed here\")\n",
    "#                 print('start new item in parent group')\n",
    "            \n",
    "        \n",
    "    \n",
    "    return root\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Computation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_computation_graphs(token_tree):\n",
    "    \n",
    "    satatement_root_tokens = token_tree.get_children()\n",
    "    statements = [Statement(t.get_evaluable()) for t in satatement_root_tokens]\n",
    "    \n",
    "    return statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excecute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def evaluate(computation_graphs, environment):\n",
    "    return [g.eval(environment) for g in computation_graphs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def calc(query, ans_available=False, debug=False):\n",
    "        \n",
    "#     commands\n",
    "#     if   query == 'exit':   break\n",
    "#     elif query == 'help':   help()\n",
    "#     elif query == 'ref':    ref()\n",
    "#     elif query == 'clear':  clear()\n",
    "#     elif query == 'copy':   pyperclip.copy(ans)\n",
    "#     elif query == '=':      pyperclip.copy(ans)\n",
    "\n",
    "#     # evaluate query\n",
    "#     elif query != \"\":\n",
    "    \n",
    "    built_in_variables = {k:v for k,v in built_ins.vars}\n",
    "    built_in_functions = {}\n",
    "    \n",
    "    for name, function, parameter_names, parameter_types, parameter_ranks, parameter_shapes in built_ins.functions:\n",
    "        \n",
    "        built_in_functions[name] = built_in_functions.get(name, FunctionSet(name))\n",
    "        built_in_functions[name].add(FunctionSignature(\n",
    "            name, \n",
    "            function, \n",
    "            parameter_names, \n",
    "            parameter_types, \n",
    "            parameter_ranks, \n",
    "            parameter_shapes\n",
    "        ))\n",
    "        \n",
    "    \n",
    "    environment = {**built_in_variables, **built_in_functions}\n",
    "    if debug: print(environment, end='\\n\\n')\n",
    "    \n",
    "    tokens = lexing(query, ans_available)\n",
    "    if debug: print(tokens, end='\\n\\n')\n",
    "    \n",
    "    token_tree = build_token_tree(tokens)\n",
    "    if debug: print(token_tree, end='\\n\\n')\n",
    "    \n",
    "    computation_graphs = build_computation_graphs(token_tree)\n",
    "    if debug: print(computation_graphs, end='\\n\\n')\n",
    "    \n",
    "    results = evaluate(computation_graphs, environment)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tensor([Real(2.0) Real(3.0) Real(4.0)], (3,))]\n",
      "Tensor([Real(4.0) Real(6.0) Real(8.0)], (3,))\n",
      "Tensor([Real(3.0) Real(5.0) Real(7.0)], (3,))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Tensor([Real(4.0) Real(6.0) Real(8.0)], (3,)),\n",
       " Tensor([Real(3.0) Real(5.0) Real(7.0)], (3,))]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc('(1 + [1,2,3]) * 2, 1 + [1,2,3] * 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor([Real(2.0) Real(4.0) Real(8.0) Real(16.0)], (4,))\n",
      "Tensor([Real(1.0) Real(4.0) Real(9.0) Real(16.0)], (4,))\n",
      "Tensor([Real(4.0) Real(64.0) Real(4096.0)], (3,))\n",
      "Tensor([Real(1.5707963267948966) Real(3.141592653589793) Real(6.283185307179586)], (1, 1, 3))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Tensor([Real(2.0) Real(4.0) Real(8.0) Real(16.0)], (4,)),\n",
       " Tensor([Real(1.0) Real(4.0) Real(9.0) Real(16.0)], (4,)),\n",
       " Tensor([Real(4.0) Real(64.0) Real(4096.0)], (3,)),\n",
       " Tensor([Real(1.5707963267948966) Real(3.141592653589793) Real(6.283185307179586)], (1, 1, 3))]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc('2 ^ [1,2,3,4], [1,2,3,4] ^ 2, [2,4,8] ^ [2,3,4], PI * [1/2, 1, 2,,,]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor([Real(9.0) Real(12.0) Real(15.0) Real(19.0) Real(26.0) Real(33.0)\n",
      " Real(29.0) Real(40.0) Real(51.0)], (3, 3))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Tensor([Real(9.0) Real(12.0) Real(15.0) Real(19.0) Real(26.0) Real(33.0)\n",
       "  Real(29.0) Real(40.0) Real(51.0)], (3, 3))]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc('[1,2,,3,4,,5,6] # [1,2,3,,4,5,6]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor([Real(90.0)])\n",
      "Tensor([Real(1.0)])\n",
      "Tensor([Real(1.0)])\n",
      "Tensor([Real(1.0) Real(1.0) Real(2.0) Real(2.0)], (4,))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Tensor([Real(90.0)]),\n",
       " Tensor([Real(1.0)]),\n",
       " Tensor([Real(1.0)]),\n",
       " Tensor([Real(1.0) Real(1.0) Real(2.0) Real(2.0)], (4,))]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc('|0 - |10-100| |, |0-1|, ||0-1||, |[1,0-1,2,0-2]|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
