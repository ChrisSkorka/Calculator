{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import math, pyperclip, os, re\n",
    "from decimal import Decimal as _Decimal\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data types: Real, Complex, Int, Boolean, String, Undefined\n",
    "Data structures: Scalar, Vector, Matrix, ...\n",
    "Variables: v\n",
    "Functions: fun\n",
    "Named operators: v operation u\n",
    "Conversion specifier: 45deg\n",
    "Data properties: object.property\n",
    "Oppertation: Numeric, Sets, Comparison \n",
    "\n",
    "Data Structures\n",
    "Tensor: [a, b,, c, d,,, ...]\n",
    "List: (a, b, c, ...)\n",
    "Function Body: {expression}\n",
    "\n",
    "Implicit Operations\n",
    "2(expression)      *\n",
    "(expression)2      *\n",
    "var(expression)    *\n",
    "fun(parameters)    call\n",
    "\n",
    "Named operators\n",
    "on two values: v operation u\n",
    "on one value: v.operation\n",
    "\n",
    "Input and Output conversion\n",
    "1m + 12cm @ cm\n",
    "2hr + 45min + 1hr + 30min @ datetime\n",
    "0b1100 * 0xFF @ dec\n",
    "\n",
    "Basic Operations:\n",
    "Standard:       | Bitwise: int&bool | Comparison:           | \n",
    "+           add | ~             not | ==             equals | \n",
    "-      subtract | &&            and | !=          not equal | \n",
    "*      multiply | ||             or | <           less than | \n",
    "/        divide | <xor>         xor | >        greater then | \n",
    "//      int div | <<     left shift | <=      less or equal | \n",
    "%       modulus | >>    right shift | >=   greater or equal | \n",
    "^         power |                   |                       | \n",
    "!     factorial |                   |                       | \n",
    "|val|  absolute |                   |                       | \n",
    "=    assignment |                   |                       | \n",
    "\n",
    "Ternary Operators\n",
    "= =                return values = function = body\n",
    "a < x < b          between\n",
    "a if cond else b   \n",
    "\n",
    "Higher Ranking Data Structure Operations:\n",
    "Vector:                 | Matrix:                          | Reductions:\n",
    "<dot>       dot product | <matmul>   matrix multiplication | <all>\n",
    "<cross>   cross product | |mat|                            | <any>\n",
    "|vec|            length | .T              transpose matrix | <\n",
    ".length          length | \n",
    ".angle            angle | \n",
    "\n",
    "\n",
    "\n",
    "1 + sqrt 4\n",
    "1 + sqrt x\n",
    "1 + $4\n",
    "1 + 3 root 8\n",
    "1 + b root x\n",
    "1 + b $ x\n",
    "\n",
    "10 nPr 2\n",
    "n nPr r\n",
    "10 nCr 2\n",
    "n nCr r\n",
    "\n",
    "[1, 2,, 3, 4] # [5, 6,, 7, 8]\n",
    "[1, 2,, 3, 4].T\n",
    "mat1.T\n",
    "\n",
    "5*x\n",
    "\n",
    "sin pi\n",
    "sin2 pi\n",
    "sini 0.5\n",
    "\n",
    "Function definitions\n",
    "fun(x) = x^2\n",
    "fun(x) = [x, x*2, x^2]     tensor outputs\n",
    "fun(x) = (x, x*2, x^2)     multiple outputs\n",
    "fun(x) = {\n",
    "    0,   if x < 0 ; \n",
    "    x^2, if 0 <= x <= 1 ; \n",
    "    x,   else\n",
    "}                          piecewise function\n",
    "\n",
    "fun(x,y,z) = {a = x+2 ; b = y*2 ; c = z^2 ; (a,b,c)}\n",
    "fun = (x,y,z):{a = x+2 ; b = y*2 ; c = z^2 ; (a,b,c)}\n",
    "\n",
    "@display = scientific 8\n",
    "@display = hex\n",
    "\n",
    "\n",
    "Statistical Operations:\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### TokenOperandDefinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class TokenOperandDefinition():\n",
    "    def __init__(self, token, precedence):\n",
    "        \n",
    "        self.token = token\n",
    "        self.precedence = float(precedence)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'TokenOperandDefinition({self.token}, {self.precedence})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### TokenGroupDefinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class TokenGroupDefinition():\n",
    "    def __init__(self, open_token, close_token, function):\n",
    "        \n",
    "        self.open_token = open_token\n",
    "        self.close_token = close_token\n",
    "        \n",
    "        self.function = function\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'TokenGroupDefinition({self.open_token}, {self.close_token})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### TokenNewItemDefinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class TokenNewItemDefinition():\n",
    "    def __init__(self, token, depth):\n",
    "        \n",
    "        self.token = token\n",
    "        self.depth = int(depth)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'TokenNewItemDefinition({self.token}, {self.levels})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Tree Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Abstract NodeToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NodeToken():\n",
    "    \"\"\"\n",
    "    represents a token that can be parsed\n",
    "    \"\"\"\n",
    "    \n",
    "    def is_complete(self):\n",
    "        raise Exception('is_complete() not implemented')\n",
    "        \n",
    "    def set_left(self, node):\n",
    "        raise Exception('set_left(node) not implemented')\n",
    "\n",
    "    def set_right(self, node):\n",
    "        raise Exception('set_right(node) not implemented')\n",
    "        \n",
    "    def get_right(self):\n",
    "        raise Exception('get_right() not implemented')\n",
    "        \n",
    "    def get_evaluable(self):\n",
    "        raise Exception('get_evaluable() not implemented')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### NodeBinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NodeBinary(NodeToken):\n",
    "    \"\"\"\n",
    "    represents a token that can be parsed into a value/operation\n",
    "    \"\"\"\n",
    "    def __init__(self, operation_definition, parent=None):\n",
    "        self.parent = parent\n",
    "        self.operation_definition = operation_definition\n",
    "        self.precedence = operation_definition.precedence\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "    \n",
    "    def is_complete(self):\n",
    "        return self.left != None and self.right != None\n",
    "        \n",
    "    def set_left(self, node):\n",
    "        self.left = node\n",
    "        node.parent = self\n",
    "\n",
    "    def set_right(self, node):\n",
    "        self.right = node\n",
    "        node.parent = self\n",
    "        \n",
    "    def get_right(self):\n",
    "        return self.right\n",
    "    \n",
    "    def get_evaluable(self):\n",
    "        return VariableFunction(self.operation_definition.token, (self.left.get_evaluable(), self.right.get_evaluable()))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'NodeBinary({self.operation_definition}, left={self.left}, right={self.right})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### NodeUnaryLeft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NodeUnaryLeft(NodeToken):\n",
    "    \n",
    "    def __init__(self, operation_definition, parent=None):\n",
    "        self.parent = parent\n",
    "        self.operation_definition = operation_definition\n",
    "        self.precedence = operation_definition.precedence\n",
    "        self.child = None\n",
    "    \n",
    "    def is_complete(self):\n",
    "        return self.child != None\n",
    "        \n",
    "    def set_left(self, node):\n",
    "        self.child = node\n",
    "        node.parent = self\n",
    "\n",
    "    def set_right(self, node):\n",
    "        self.child = node\n",
    "        node.parent = self\n",
    "        \n",
    "    def get_right(self):\n",
    "        return self.child\n",
    "    \n",
    "    def get_evaluable(self):\n",
    "        return VariableFunction(self.operation_definition.token, (self.child.get_evaluable(), ))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'NodeUnaryLeft({self.value}, child={self.child})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### NodeUnaryRight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NodeUnaryRight(NodeToken):\n",
    "    \n",
    "    def __init__(self, operation_definition, parent=None):\n",
    "        self.parent = parent\n",
    "        self.operation_definition = operation_definition\n",
    "        self.precedence = operation_definition.precedence\n",
    "        self.child = None\n",
    "    \n",
    "    def is_complete(self):\n",
    "        return self.child != None\n",
    "        \n",
    "    def set_left(self, node):\n",
    "        self.child = node\n",
    "        node.parent = self\n",
    "\n",
    "    def set_right(self, node):\n",
    "        self.child = node\n",
    "        node.parent = self\n",
    "        \n",
    "    def get_right(self):\n",
    "        return self.child\n",
    "    \n",
    "    def get_evaluable(self):\n",
    "        return VariableFunction(self.operation_definition.token, (self.child.get_evaluable(), ))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'NodeUnaryRight({self.value}, child={self.child})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NodeGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeGroup(NodeToken):\n",
    "    \n",
    "    def __init__(self, group_definition, parent=None):\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        \n",
    "        self.group_definition = group_definition\n",
    "        self.complete = False\n",
    "        \n",
    "        self.shape = {0:1}\n",
    "        self.sep_count = 0\n",
    "    \n",
    "    def is_complete(self):\n",
    "        return self.complete\n",
    "\n",
    "    def close(self):\n",
    "        self.sep_count = 0\n",
    "        self.complete = True\n",
    "        \n",
    "        expected_size = 1\n",
    "        for s in self.shape: expected_size *= s\n",
    "            \n",
    "        if len(self.children) < expected_size:\n",
    "            raise Exception('Inconsistent dimensions')\n",
    "    \n",
    "    def set_right(self, node):\n",
    "        self.children[-1] = node\n",
    "        node.parent = self\n",
    "        \n",
    "    def get_right(self):\n",
    "        return self.children[-1]\n",
    "\n",
    "    def add(self, node):\n",
    "        self.children.append(node)\n",
    "        node.parent = self\n",
    "        \n",
    "        if self.sep_count >= len(self.shape):\n",
    "            for i in range(len(self.shape), self.sep_count+1):\n",
    "                self.shape[i-1] = self.shape.get(i-1, 1)\n",
    "            self.shape[self.sep_count-1] += 1\n",
    "            \n",
    "        self.sep_count = 0\n",
    "        \n",
    "    def increase(self, depth=1):\n",
    "        self.sep_count += depth\n",
    "        \n",
    "        # ensure minumum number of dimensions exists\n",
    "        for i in range(len(self.shape), self.sep_count+1):\n",
    "            self.shape[i-1] = self.shape.get(i-1, 1)\n",
    "    \n",
    "    def get_shape(self):\n",
    "        shape = [(d,s) for d,s in self.shape.items()]\n",
    "        shape.sort(key=lambda x:x[0], reverse=True)\n",
    "        shape = tuple(s for d,s in shape)\n",
    "        return shape\n",
    "    \n",
    "    def get_children(self):\n",
    "        return self.children\n",
    "    \n",
    "    def get_evaluable(self):\n",
    "        \n",
    "        evaluables = [v.get_evaluable() for v in self.children]\n",
    "        \n",
    "        return VariableTensor(evaluables, self.get_shape(), self.group_definition.function)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'NodeGroup({self.group_definition}, children={self.children})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### NodeValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NodeValue(NodeToken):\n",
    "    \n",
    "    def __init__(self, value, value_type, parent=None):\n",
    "        self.parent = parent\n",
    "        self.value = value\n",
    "        self.value_type = value_type\n",
    "    \n",
    "    def is_complete(self):\n",
    "        return True\n",
    "    \n",
    "    def get_evaluable(self):\n",
    "\n",
    "        value = None\n",
    "        if self.value_type == TOKEN_TYPE_STRING:\n",
    "            value = String(self.value)\n",
    "            value = VariableTensor([value], ())\n",
    "            \n",
    "        if self.value_type == TOKEN_TYPE_INTEGER:\n",
    "            value = Integer(self.value)\n",
    "            value = VariableTensor([value], ())\n",
    "            \n",
    "        if self.value_type == TOKEN_TYPE_NUMBER:\n",
    "            value = Real(self.value)\n",
    "            value = VariableTensor([value], ())\n",
    "            \n",
    "        if self.value_type == TOKEN_TYPE_LITERAL:\n",
    "            value = Variable(self.value)\n",
    "        \n",
    "        return value\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'NodeValue({self.value}, {self.value_type})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluable Tree Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Abstract Evaluable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Evaluable():\n",
    "    \"\"\"\n",
    "    represents a node that can be evaluated\n",
    "    \"\"\"\n",
    "    \n",
    "    def eval(self, environment):\n",
    "        raise Exception('eval(environment) not implemented')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Statement - results in one print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Statement():\n",
    "    \n",
    "    def __init__(self, node):\n",
    "        self.node = node\n",
    "        \n",
    "    def eval(self, environment):\n",
    "        \n",
    "        result = self.node.eval(environment)\n",
    "        print(result)\n",
    "        return result\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'Statement({self.node})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VariableFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableFunction(Evaluable):\n",
    "    \n",
    "    def __init__(self, name, parameters):\n",
    "        self.name = name\n",
    "        self.parameters = parameters\n",
    "        if isinstance(parameters, VariableTensor):\n",
    "            self.parameters = parameters.data\n",
    "    \n",
    "    def eval(self, environment):\n",
    "        \n",
    "        assert self.name in environment, f'Function {self.name} not found'\n",
    "        assert type(environment[self.name]) == Function, f'{self.name} is not a function'\n",
    "        \n",
    "        parameters = [p.eval(environment) for p in self.parameters]\n",
    "        \n",
    "        return environment[self.name].eval(environment, parameters)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'VariableFunction_{self.name}({self.parameters})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Variable(Evaluable):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "    def eval(self, environment):\n",
    "        \n",
    "        if self.name not in environment:\n",
    "            raise Exception(f'Variable {self.name} not found')\n",
    "        \n",
    "        return environment[self.name]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"Variable({self.name})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VariableTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableTensor(Evaluable):\n",
    "    \n",
    "    def __init__(self, data, shape, function=None):\n",
    "        self.data = data\n",
    "        self.shape = shape\n",
    "        self.function = function\n",
    "    \n",
    "    def eval(self, environment):\n",
    "        \n",
    "        \n",
    "        values = [v.eval(environment) for v in self.data]\n",
    "        \n",
    "        if self.shape == ():\n",
    "            return Tensor(values[:1], self.shape)\n",
    "        else:\n",
    "            return self.function(values, self.shape)\n",
    "    \n",
    "#         if all(type(v) != Tensor or v.rank == 0 for v in values):\n",
    "#             values = [v[0] if type(v) == Tensor else v for v in values]\n",
    "            \n",
    "#         return Tensor(values, self.shape)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'VariableTensor({self.data}, {self.shape})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensor(Evaluable):\n",
    "    \"\"\"\n",
    "    represents a value/tensor of any type, shape and rank\n",
    "    \"\"\"\n",
    "    def __init__(self, data, shape=()):\n",
    "        \n",
    "        self._data = np.array(data, object).reshape(shape)\n",
    "        self.data = self._data.reshape((self._data.size))\n",
    "        self.first = self.data[0]\n",
    "        \n",
    "        self.shape = self._data.shape\n",
    "        self.size = self._data.size\n",
    "        self.rank = self._data.ndim\n",
    "        \n",
    "        assert self.size > 0, 'Tensor cannot be empty'\n",
    "        \n",
    "        self.dtype = type(self.data[0])\n",
    "        \n",
    "        assert all([type(i) == self.dtype for i in self.data]), 'All items in a Tensor must be of the same type'\n",
    "        \n",
    "#         if len(self.data) == 1:\n",
    "#             self.type = type(data[0])\n",
    "#         else:\n",
    "#             self.type = reduce(lambda a,b: (a if a==b else Tensor), (type(v) for v in data))\n",
    "            \n",
    "#             # TODO if Tensor, turn all non-Tensor into Tensor\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        data = self.data[index] if type(index) == int else self._data[index]\n",
    "        shape = data.shape if type(data) == np.ndarray else ()\n",
    "            \n",
    "        return Tensor(data, shape)\n",
    "        \n",
    "    def __setitem__(self, index, value):\n",
    "        \n",
    "        if type(value) == Tensor:\n",
    "            value = value._data\n",
    "        \n",
    "        if type(index) == int:\n",
    "            self.data[index] = value\n",
    "        else:\n",
    "            self._data[index] = value\n",
    "    \n",
    "    def eval(self, environment):\n",
    "        return self\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        \n",
    "        if self.rank == 0:\n",
    "            return f'Tensor({self.data[()]})'\n",
    "        else:\n",
    "            return f'Tensor({self.data}, {self.shape})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Array(Evaluable):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = np.array(data, object)\n",
    "        self.data = self.data.reshape((self.data.size,))\n",
    "        self.size = self.data.size\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return Array(self.data[index])\n",
    "        \n",
    "    def __setitem__(self, index, value):\n",
    "        self.data[index] = value\n",
    "    \n",
    "    def eval(self, environment):\n",
    "        return self\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'Array({self.data[()]})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Abstract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Data(Evaluable):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class String(Data):\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "    \n",
    "    def eval(self, environment):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Integer(Data):\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "    \n",
    "    def eval(self, environment):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Real(Data):\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        self.value = float(value)\n",
    "    \n",
    "    def eval(self, environment):\n",
    "        return self\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'Real({self.value})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Boolean(Data):\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "    \n",
    "    def eval(self, environment):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Function(Data):\n",
    "        \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.signatures = {}\n",
    "    \n",
    "    def eval(self, environment, parameters):\n",
    "        \n",
    "        signature = tuple(p.dtype for p in parameters)\n",
    "        print('Function','eval', 'parameters', parameters, 'signature', signature)\n",
    "            \n",
    "        function, parameter_names = None, []\n",
    "        \n",
    "        for candidate_signature in self.signatures:\n",
    "            \n",
    "            if len(signature) != len(candidate_signature):\n",
    "                continue\n",
    "            \n",
    "            if all(issubclass(a,b) for a,b in zip(signature, candidate_signature)):\n",
    "                parameter_names, function = self.signatures[candidate_signature]\n",
    "                break;\n",
    "                \n",
    "        if function == None:\n",
    "            raise Exception(f'Signature {self.name}{tuple(p.__name__ for p in signature)} has no matching overload')\n",
    "        \n",
    "        new_scoped_environment = {**environment, **{k:v for k,v in zip(parameter_names, parameters)}}\n",
    "        \n",
    "        return function(new_scoped_environment)\n",
    "    \n",
    "    def __getitem__(self, signature):\n",
    "        return self.signatures[signature]\n",
    "    \n",
    "    def __setitem__(self, signature, value):\n",
    "        self.signatures[signature] = value\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'Function({self.name}, {self.signatures})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built In Functions, Operators and Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### BuiltIns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class BuiltIns():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.functions = []\n",
    "        self.vars = []\n",
    "        self.binary_operators = []\n",
    "        self.left_unary_operators = []\n",
    "        self.right_unary_operators = []\n",
    "        self.groups = []\n",
    "        self.new_items = []\n",
    "        \n",
    "    def register_function(self, name, signature, parameters, function):\n",
    "        self.functions.append((name, signature, parameters, function))\n",
    "        \n",
    "    def register_scalar_function(self, name, signature, function):\n",
    "        \n",
    "        num_parameters = function.__code__.co_argcount\n",
    "        parameters = [f'_p{i}' for i in range(num_parameters)]\n",
    "        \n",
    "        def wrapper(e):\n",
    "            tensors = [e[p] for p in parameters]\n",
    "            \n",
    "            shape = ()\n",
    "            for tensor in tensors:\n",
    "                if tensor.rank > len(shape):\n",
    "                    shape = tensor.shape\n",
    "                    \n",
    "            assert all([t.shape in [(), shape] for t in tensors]), 'Tensor shapes must match or be scalars'\n",
    "            \n",
    "            size = reduce(lambda a,b: a*b, shape, 1)\n",
    "            values = []\n",
    "            \n",
    "            if shape == ():\n",
    "                values.append(function(*[t[0].first for t in tensors]))\n",
    "            else:\n",
    "                for index in range(size):\n",
    "                    pars = [t[0] if t.rank == 0 else t[index] for t in tensors]\n",
    "                    pars = map(lambda p:p.first, pars)\n",
    "                    values.append(function(*pars))\n",
    "            \n",
    "            return Tensor(values, shape)\n",
    "        \n",
    "        self.register_function(name, signature, parameters, wrapper)\n",
    "        \n",
    "    def register_binary_operator(self, name, precedence, signature, parameters, function):\n",
    "        self.register_function(name, signature, parameters, function)\n",
    "        self.binary_operators.append(TokenOperandDefinition(name, precedence))\n",
    "        \n",
    "    def register_scalar_binary_operator(self, name, precedence, signature, function):\n",
    "        self.register_scalar_function(name, signature, function)\n",
    "        self.binary_operators.append(TokenOperandDefinition(name, precedence))\n",
    "        \n",
    "    def register_var(self, name, value):\n",
    "        self.vars.append((name, value))\n",
    "        \n",
    "    def register_grouping(self, open_token, close_token, function):\n",
    "        self.groups.append(TokenGroupDefinition(open_token, close_token, function))\n",
    "        \n",
    "    def register_new_item_seperator(self, token, depth):\n",
    "        self.new_items.append(TokenNewItemDefinition(token, depth))\n",
    "        \n",
    "        \n",
    "built_ins = BuiltIns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Group ( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def group_round(items, shape):\n",
    "    return Array(items)\n",
    "\n",
    "built_ins.register_grouping('(', ')', group_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Group [ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def group_squre(items, shape):\n",
    "    \n",
    "    assert len(items) > 0, 'Tensors can not be empty'\n",
    "    \n",
    "    base_shape = items[0].shape\n",
    "    assert all([i.shape == base_shape for i in items]), 'Tensor elements have inconsistent shapes'\n",
    "    \n",
    "    extended_shape = shape + base_shape\n",
    "    data = np.array([i.data for i in items]).reshape(extended_shape)\n",
    "    \n",
    "    return Tensor(data, extended_shape)\n",
    "\n",
    "built_ins.register_grouping('[', ']', group_squre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Group { }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### New Item Seperators ',' and ';'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "built_ins.register_new_item_seperator(',', 1)\n",
    "built_ins.register_new_item_seperator(';', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Variabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "built_ins.register_var('PI', Tensor([Real(3.141592653589793238462643383279502884197)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Binary Operantors: +, -, *, /, //, %, ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# A + B\n",
    "built_ins.register_scalar_binary_operator('+', 3, (Real, Real), lambda a, b: Real(a.value + b.value))\n",
    "\n",
    "# A - B\n",
    "built_ins.register_scalar_binary_operator('-', 3, (Real, Real), lambda a, b: Real(a.value - b.value))\n",
    "\n",
    "# A * B\n",
    "built_ins.register_scalar_binary_operator('*', 4, (Real, Real), lambda a, b: Real(a.value * b.value))\n",
    "\n",
    "# A / B\n",
    "built_ins.register_scalar_binary_operator('/', 4, (Real, Real), lambda a, b: Real(a.value / b.value))\n",
    "\n",
    "# A // B\n",
    "built_ins.register_scalar_binary_operator('//', 4, (Real, Real), lambda a, b: Real(a.value // b.value))\n",
    "\n",
    "# A % B\n",
    "built_ins.register_scalar_binary_operator('%', 4, (Real, Real), lambda a, b: Real(a.value % b.value))\n",
    "\n",
    "# A ^ B\n",
    "built_ins.register_scalar_binary_operator('^', 5, (Real, Real), lambda a, b: Real(a.value ** b.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication: # #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(e):\n",
    "    A, B = e['_A'], e['_B']\n",
    "    \n",
    "    a_shape = A.shape\n",
    "    b_shape = B.shape\n",
    "    \n",
    "    assert A.rank >= 2 and B.rank >= 2, 'left and right sides must be matrices'\n",
    "    assert a_shape[-1] == b_shape[-2], 'left n_cols must equal right n_rows'\n",
    "    assert A.rank == 2 or B.rank == 2 or a_shape[:-2] == b_shape[:-2], 'number of matrices on the left and right must be equal or 1'\n",
    "    \n",
    "    n_rows = a_shape[-2]\n",
    "    n_cols = b_shape[-1]\n",
    "    n_vec = a_shape[-1]\n",
    "    shape = (a_shape[:-2] if A.rank > B.rank else b_shape[:-2]) + (n_rows, n_cols)\n",
    "    \n",
    "    values = []\n",
    "    \n",
    "    for i_out in itertools.product(*[range(i) for i in shape]):\n",
    "        \n",
    "        v = 0\n",
    "        for j in range(n_vec):\n",
    "            i_a = i_out[:-1] + (j,)\n",
    "            i_b = i_out[:-2] + (j,) + i_out[-1:]\n",
    "            \n",
    "            if A.rank == 2: i_a = i_a[-2:]\n",
    "            if B.rank == 2: i_b = i_b[-2:]\n",
    "            \n",
    "            # print('matmul', i_out, i_a, i_b)\n",
    "            v += A[i_a].first.value * B[i_b].first.value\n",
    "    \n",
    "        values.append(Real(v))\n",
    "    \n",
    "    return Tensor(values, shape)\n",
    "\n",
    "built_ins.register_binary_operator('#', 4, (Real, Real), ('_A', '_B'), matmul)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Tokens Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "# operand kinds\n",
    "# group, close_group, return_to_group, binary, unary_left, unary_right, *_ = enum(10)\n",
    "# (\n",
    "#     OPERAND_TYPE_GROUP, \n",
    "#     OPERAND_TYPE_CLOSE_GROUP, \n",
    "#     OPERAND_TYPE_RETURN_TO_GROUP, \n",
    "#     OPERAND_TYPE_BINARY, \n",
    "#     OPERAND_TYPE_UNARY_LEFT, \n",
    "#     OPERAND_TYPE_UNARY_RIGHT, \n",
    "# *_) = enum(10)\n",
    "\n",
    "\n",
    "TOKEN_TYPE_STRING =   'string'\n",
    "TOKEN_TYPE_INTEGER =  'integer'\n",
    "TOKEN_TYPE_NUMBER =   'number'\n",
    "TOKEN_TYPE_OPERATOR = 'operand'\n",
    "TOKEN_TYPE_OPEN_GROUP =    'group'\n",
    "TOKEN_TYPE_LITERAL =  'literal'\n",
    "\n",
    "TOKEN_TYPE_OPEN_GROUP = 'open group'\n",
    "TOKEN_TYPE_CLOSE_GROUP = 'close group'\n",
    "TOKEN_TYPE_NEW_ITEM    = 'new item'\n",
    "TOKEN_TYPE_BINARY      = 'binary operand'\n",
    "TOKEN_TYPE_UNARY_LEFT  = 'left unary operand'\n",
    "TOKEN_TYPE_UNARY_RIGHT = 'right unary operand'\n",
    "\n",
    "OPERAND_TYPES = [\n",
    "    TOKEN_TYPE_OPEN_GROUP,\n",
    "    TOKEN_TYPE_CLOSE_GROUP, \n",
    "    TOKEN_TYPE_NEW_ITEM, \n",
    "    TOKEN_TYPE_BINARY, \n",
    "    TOKEN_TYPE_UNARY_LEFT, \n",
    "    TOKEN_TYPE_UNARY_RIGHT, \n",
    "]\n",
    "\n",
    "TOKEN_TYPE_VALUE = [\n",
    "    TOKEN_TYPE_STRING,\n",
    "    TOKEN_TYPE_INTEGER,\n",
    "    TOKEN_TYPE_NUMBER,\n",
    "    TOKEN_TYPE_LITERAL,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Token Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# binary_operands = [\n",
    "#     Operand(r'.',   8), \n",
    "#     Operand(r':',   6), \n",
    "#     Operand(r'^',   5), \n",
    "#     Operand(r'*',   4), \n",
    "#     Operand(r'/',   4), \n",
    "#     Operand(r'//',  4), \n",
    "#     Operand(r'%',   4), \n",
    "#     Operand(r'+',   3), \n",
    "#     Operand(r'-',   3), \n",
    "#     Operand(r'&&',  2), \n",
    "#     Operand(r'||',  2), \n",
    "#     Operand(r'xor', 2), \n",
    "#     Operand(r'==',  1), \n",
    "#     Operand(r'!=',  1), \n",
    "#     Operand(r'>',   1), \n",
    "#     Operand(r'>=',  1), \n",
    "#     Operand(r'<',   1), \n",
    "#     Operand(r'<=',  1), \n",
    "#     Operand(r'=',   0),\n",
    "# ]\n",
    "\n",
    "# binary_operands = built_ins.binary_operators\n",
    "\n",
    "# left_unary_operands = [\n",
    "#     Operand(r'+', 7), \n",
    "#     Operand(r'-', 7), \n",
    "#     Operand(r'~', 7), \n",
    "#     Operand(r'=', 0),\n",
    "# ]\n",
    "\n",
    "# right_unary_operands = [\n",
    "#     Operand(r'!', 7),\n",
    "# ]\n",
    "\n",
    "# new_item = [\n",
    "#     TokenNewItemDefinition(',', 1),\n",
    "#     TokenNewItemDefinition(';', 2),\n",
    "# ]\n",
    "\n",
    "# groups = [\n",
    "#     Group(r'\\(', r')'),\n",
    "#     Group(r'\\[', r']'),\n",
    "#     Group(r'\\{', r'}'),\n",
    "#     Group(r'[a-zA-Z][a-zA-Z0-9_]*\\(', r')'),\n",
    "# ]\n",
    "\n",
    "# close_group = [Operand(g.close_op, -1) for g in groups]\n",
    "\n",
    "# sort by length\n",
    "# binary_operands.sort(key = lambda o:(len(o.match), o.precedence), reverse=True)\n",
    "# left_unary_operands.sort(key = lambda o:(len(o.match), o.precedence), reverse=True)\n",
    "# right_unary_operands.sort(key = lambda o:(len(o.match), o.precedence), reverse=True)\n",
    "# new_item.sort(key = lambda o:(len(o.match), o.precedence), reverse=True)\n",
    "\n",
    "# (\n",
    "#     binary_operands,\n",
    "#     left_unary_operands,\n",
    "#     right_unary_operands,\n",
    "#     new_item,\n",
    "#     close_group,\n",
    "# )\n",
    "\n",
    "# TODO sort built in tokens\n",
    "\n",
    "token_definitions = {\n",
    "    TOKEN_TYPE_OPEN_GROUP:  built_ins.groups,\n",
    "    TOKEN_TYPE_CLOSE_GROUP: built_ins.groups, \n",
    "    TOKEN_TYPE_NEW_ITEM:    built_ins.new_items, \n",
    "    TOKEN_TYPE_BINARY:      built_ins.binary_operators, \n",
    "    TOKEN_TYPE_UNARY_LEFT:  built_ins.left_unary_operators, \n",
    "    TOKEN_TYPE_UNARY_RIGHT: built_ins.right_unary_operators, \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Operation Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def find_token_definition(string, token_type, f = lambda x:x.token):\n",
    "    for token_definition in token_definitions[token_type]:\n",
    "        if string == f(token_definition):\n",
    "#         if re.fullmatch(operator.re_match, string) != None:\n",
    "            return token_definition\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Define Token Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'string': '((\\\\\"\"\".*?\\\\\"\"\")|(\\'\\'\\'.*?\\'\\'\\')|(\".*?\")|(\\'.*?\\'))',\n",
       " 'integer': '((0b|0o|0d|0x|[0-9]+_)[0-9a-zA-Z,]+)',\n",
       " 'number': '((([\\\\.][0-9]+)|([0-9]+[\\\\.]?[0-9]*))([eE][-+]?[0-9]+)?[a-z]*)',\n",
       " 'literal': '([A-Za-z_][A-Za-z0-9_]*)',\n",
       " 'open group': '(\\\\()|(\\\\[)',\n",
       " 'binary operand': '(\\\\+)|(\\\\-)|(\\\\*)|(\\\\/)|(\\\\/\\\\/)|(\\\\%)|(\\\\^)|(\\\\#)',\n",
       " 'left unary operand': '()',\n",
       " 'right unary operand': '()',\n",
       " 'new item': '(\\\\,)|(\\\\;)',\n",
       " 'close group': '(\\\\))|(\\\\])'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def re_join(l, f=lambda x:x):\n",
    "    return '(' + ')|('.join([re.escape(f(i)) for i in l]) + ')'\n",
    "\n",
    "# regex\n",
    "re_number =    r\"\"\"((([\\.][0-9]+)|([0-9]+[\\.]?[0-9]*))([eE][-+]?[0-9]+)?[a-z]*)\"\"\"\n",
    "re_integer =   r\"\"\"((0b|0o|0d|0x|[0-9]+_)[0-9a-zA-Z,]+)\"\"\"\n",
    "re_string =    r\"\"\"((\\\"\"\".*?\\\"\"\")|('''.*?''')|(\".*?\")|('.*?'))\"\"\"\n",
    "re_literal =   r\"\"\"([A-Za-z_][A-Za-z0-9_]*)\"\"\"\n",
    "\n",
    "\n",
    "re_open_group =           re_join(built_ins.groups, lambda x:x.open_token)\n",
    "re_close_group =          re_join(built_ins.groups, lambda x:x.close_token)\n",
    "re_binary_operands =      re_join(built_ins.binary_operators, lambda x:x.token)\n",
    "re_left_unary_operands =  re_join(built_ins.left_unary_operators, lambda x:x.token)\n",
    "re_right_unary_operands = re_join(built_ins.right_unary_operators, lambda x:x.token)\n",
    "re_new_item =             re_join(built_ins.new_items, lambda x:x.token)\n",
    "\n",
    "\n",
    "re_tokens = {\n",
    "    TOKEN_TYPE_STRING:      re_string,\n",
    "    TOKEN_TYPE_INTEGER:     re_integer,\n",
    "    TOKEN_TYPE_NUMBER:      re_number,\n",
    "    TOKEN_TYPE_LITERAL:     re_literal,\n",
    "    TOKEN_TYPE_OPEN_GROUP:  re_open_group,\n",
    "    TOKEN_TYPE_BINARY:      re_binary_operands,\n",
    "    TOKEN_TYPE_UNARY_LEFT:  re_left_unary_operands,\n",
    "    TOKEN_TYPE_UNARY_RIGHT: re_right_unary_operands,\n",
    "    TOKEN_TYPE_NEW_ITEM:    re_new_item,\n",
    "    TOKEN_TYPE_CLOSE_GROUP: re_close_group,\n",
    "}\n",
    "\n",
    "re_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Lexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def re_match_length(string, re_pattern):\n",
    "    match = re.match(re_pattern, string)\n",
    "    return match.span()[1] if match != None else 0\n",
    "\n",
    "# TOKEN_TYPE_STRING\n",
    "# TOKEN_TYPE_INTEGER\n",
    "# TOKEN_TYPE_NUMBER\n",
    "# TOKEN_TYPE_LITERAL\n",
    "\n",
    "# TOKEN_TYPE_OPEN_GROUP\n",
    "# TOKEN_TYPE_BINARY\n",
    "# TOKEN_TYPE_UNARY_LEFT\n",
    "# TOKEN_TYPE_UNARY_RIGHT\n",
    "# TOKEN_TYPE_NEW_ITEM\n",
    "# TOKEN_TYPE_CLOSE_GROUP\n",
    "\n",
    "def lexing(string, ans_available=False):\n",
    "    tokens = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(string):\n",
    "            \n",
    "        last_token_type = tokens[-1][0] if len(tokens) > 0 else None\n",
    "        allowed_token_types = []\n",
    "\n",
    "        # begin with\n",
    "        if last_token_type in [\n",
    "            None,\n",
    "        ]:\n",
    "            \n",
    "            allowed_token_types = [TOKEN_TYPE_BINARY] if ans_available else []\n",
    "            allowed_token_types += [\n",
    "                TOKEN_TYPE_UNARY_LEFT,\n",
    "                TOKEN_TYPE_OPEN_GROUP,\n",
    "                TOKEN_TYPE_NEW_ITEM,\n",
    "                TOKEN_TYPE_CLOSE_GROUP,\n",
    "                *TOKEN_TYPE_VALUE,\n",
    "            ]\n",
    "        \n",
    "        if last_token_type in [\\\n",
    "            TOKEN_TYPE_OPEN_GROUP,\n",
    "            TOKEN_TYPE_NEW_ITEM,\n",
    "        ]:\n",
    "            allowed_token_types = [\n",
    "                TOKEN_TYPE_UNARY_LEFT,\n",
    "                TOKEN_TYPE_OPEN_GROUP,\n",
    "                TOKEN_TYPE_NEW_ITEM,\n",
    "                TOKEN_TYPE_CLOSE_GROUP,\n",
    "                *TOKEN_TYPE_VALUE,\n",
    "            ]\n",
    "\n",
    "        # after value\n",
    "        if last_token_type in [\n",
    "            TOKEN_TYPE_CLOSE_GROUP,\n",
    "            TOKEN_TYPE_UNARY_RIGHT,\n",
    "            *TOKEN_TYPE_VALUE,\n",
    "        ]:\n",
    "            allowed_token_types = [\n",
    "                TOKEN_TYPE_UNARY_RIGHT,\n",
    "                TOKEN_TYPE_BINARY,\n",
    "                TOKEN_TYPE_NEW_ITEM,\n",
    "                TOKEN_TYPE_CLOSE_GROUP,\n",
    "            ]\n",
    "\n",
    "        # after operator\n",
    "        if last_token_type in [\n",
    "            TOKEN_TYPE_BINARY,\n",
    "            TOKEN_TYPE_UNARY_LEFT,\n",
    "\n",
    "        ]:\n",
    "            allowed_token_types = [\n",
    "                TOKEN_TYPE_OPEN_GROUP,\n",
    "                TOKEN_TYPE_UNARY_LEFT,\n",
    "                *TOKEN_TYPE_VALUE,\n",
    "            ]\n",
    "            \n",
    "        \n",
    "        # find matching token type\n",
    "        token_type, token_str = None, None\n",
    "        \n",
    "        for possible_token_type in allowed_token_types:\n",
    "            re_pattern = re_tokens[possible_token_type]\n",
    "            \n",
    "            l = re_match_length(string[i:], re_pattern)\n",
    "            if l > 0:\n",
    "                token_type = possible_token_type\n",
    "                token_str = string[i:i+l]\n",
    "                break\n",
    "                \n",
    "\n",
    "                    \n",
    "        # invalid token\n",
    "        if token_type == None:\n",
    "#             raise Exception(f\"Token not allowed at position {i}\")\n",
    "            i += 1\n",
    "        else:\n",
    "            tokens.append((token_type, token_str))\n",
    "            i += len(token_str)\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Treeify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bubble_up(focus, new):\n",
    "    \"\"\"\n",
    "    Finds ancestor/parent in tree upwards from `token` thats the first group token or the first\n",
    "    \"\"\"\n",
    "    \n",
    "    while True:\n",
    "#         print('bubble_up', focus.value, type(focus))\n",
    "#         if type(focus) != NodeValue and (type(focus) == NodeGroup or focus.precedence < new.precedence):\n",
    "        if type(focus) == NodeGroup or focus.precedence < new.precedence:\n",
    "#             print('return', focus.value)\n",
    "            return focus\n",
    "        else:\n",
    "            focus = focus.parent\n",
    "        \n",
    "def bubble_up_to_group(focus):\n",
    "    while True:\n",
    "        if type(focus) == NodeGroup:\n",
    "            return focus\n",
    "        else:\n",
    "            focus = focus.parent\n",
    "\n",
    "# TOKEN_TYPE_STRING\n",
    "# TOKEN_TYPE_INTEGER\n",
    "# TOKEN_TYPE_NUMBER\n",
    "# TOKEN_TYPE_LITERAL\n",
    "\n",
    "# TOKEN_TYPE_OPEN_GROUP\n",
    "# TOKEN_TYPE_BINARY\n",
    "# TOKEN_TYPE_UNARY_LEFT\n",
    "# TOKEN_TYPE_UNARY_RIGHT\n",
    "\n",
    "# TOKEN_TYPE_NEW_ITEM\n",
    "# TOKEN_TYPE_CLOSE_GROUP\n",
    "\n",
    "def build_token_tree(tokens):\n",
    "    \n",
    "    root = NodeGroup(\"ROOT\", None)\n",
    "    focus = root\n",
    "    \n",
    "    for token_type, value in tokens:\n",
    "        \n",
    "        \n",
    "        # focus is\n",
    "        # Binary Operator\n",
    "        # Unary Operator\n",
    "        if type(focus) in [\n",
    "            NodeBinary,\n",
    "            NodeUnaryLeft,\n",
    "        ]:\n",
    "            \n",
    "            # next is \n",
    "            # Unary left\n",
    "            if token_type == TOKEN_TYPE_UNARY_LEFT:\n",
    "#                 print('insert lef unary')\n",
    "                \n",
    "                operand = find_token_definition(value, TOKEN_TYPE_UNARY_LEFT)\n",
    "                next_node = NodeUnaryLeft(operand)\n",
    "                \n",
    "                focus.set_right(next_node)\n",
    "                focus = next_node\n",
    "                \n",
    "            # next is\n",
    "            # Group\n",
    "            elif token_type == TOKEN_TYPE_OPEN_GROUP:\n",
    "#                 print('insert open group')\n",
    "                \n",
    "                group = find_token_definition(value, TOKEN_TYPE_OPEN_GROUP, lambda x:x.open_token)\n",
    "                next_node = NodeGroup(group)\n",
    "                focus.set_right(next_node)\n",
    "                focus = next_node\n",
    "            \n",
    "            # next is\n",
    "            # TOKEN_TYPE_STRING\n",
    "            # TOKEN_TYPE_INTEGER\n",
    "            # TOKEN_TYPE_NUMBER\n",
    "            # TOKEN_TYPE_LITERAL\n",
    "            elif token_type in TOKEN_TYPE_VALUE:\n",
    "#                 print('insert value')\n",
    "                \n",
    "                next_node = NodeValue(value, token_type)\n",
    "                focus.set_right(next_node)\n",
    "                focus = next_node\n",
    "                \n",
    "            else:\n",
    "                raise Exception(f\"token '{value}' not allowed here\")\n",
    "            \n",
    "            \n",
    "        # focus is\n",
    "        # Value\n",
    "        # Closed Group\n",
    "        elif type(focus) == NodeValue or (type(focus) == NodeGroup and focus.is_complete()):\n",
    "            \n",
    "            # next is\n",
    "            # Binary\n",
    "            if token_type == TOKEN_TYPE_BINARY:\n",
    "#                 print('insert binary')\n",
    "                \n",
    "                operand = find_token_definition(value, TOKEN_TYPE_BINARY)\n",
    "                next_node = NodeBinary(operand)\n",
    "                    \n",
    "                parent_node = bubble_up(focus.parent, next_node)\n",
    "                child_node = parent_node.get_right()\n",
    "                parent_node.set_right(next_node)\n",
    "                next_node.set_left(child_node)\n",
    "                focus = next_node\n",
    "                \n",
    "            \n",
    "            # next is\n",
    "            # Unary right\n",
    "            elif token_type == TOKEN_TYPE_UNARY_RIGHT:\n",
    "#                 print('insert right unary')\n",
    "                \n",
    "                operand = find_token_definition(value, TOKEN_TYPE_UNARY_RIGHT)\n",
    "                next_node = NodeUnaryRight(operand)\n",
    "                    \n",
    "                parent_node = focus.parent # bubble_up(focus.parent, next_node)\n",
    "                child_node = parent_node.get_right()\n",
    "                parent_node.set_right(next_node)\n",
    "                next_node.set_left(child_node)\n",
    "                # focus = next_node\n",
    "            \n",
    "            # next is\n",
    "            # New item\n",
    "            elif token_type == TOKEN_TYPE_NEW_ITEM:\n",
    "#                 print('new item')\n",
    "                \n",
    "                token_definition = find_token_definition(value, TOKEN_TYPE_NEW_ITEM)\n",
    "    \n",
    "                parent_node = bubble_up_to_group(focus.parent)\n",
    "                parent_node.increase(token_definition.depth)\n",
    "                focus = parent_node\n",
    "            \n",
    "            # next is\n",
    "            # New item\n",
    "            elif token_type == TOKEN_TYPE_CLOSE_GROUP:\n",
    "#                 print('close group')\n",
    "                \n",
    "                parent_node = bubble_up_to_group(focus.parent)\n",
    "                parent_node.close()\n",
    "                focus = parent_node\n",
    "            \n",
    "            # next is\n",
    "            else:\n",
    "                raise Exception(f\"token '{value}' not allowed here\")\n",
    "#                 print('start new item in parent group')\n",
    "        \n",
    "        \n",
    "        # focus is\n",
    "        # Open Group\n",
    "        elif type(focus) == NodeGroup and not focus.is_complete(): \n",
    "            \n",
    "            # next is\n",
    "            # Binary - use ans on left\n",
    "            if token_type == TOKEN_TYPE_BINARY:\n",
    "#                 print('insert binary with ans as left')\n",
    "\n",
    "                left = NodeValue('ans', TOKEN_TYPE_LITERAL)\n",
    "                \n",
    "                operand = find_token_definition(value, TOKEN_TYPE_BINARY)\n",
    "                next_node = NodeBinary(operand)\n",
    "                next_node.set_left(left)\n",
    "                \n",
    "                focus.add(next_node)\n",
    "                focus = next_node\n",
    "            \n",
    "            # next is\n",
    "            # Unary left\n",
    "            elif token_type == TOKEN_TYPE_UNARY_LEFT:\n",
    "#                 print('add unary left')\n",
    "                \n",
    "                operand = find_token_definition(value, TOKEN_TYPE_UNARY_LEFT)\n",
    "                next_node = NodeUnaryLeft(operand)\n",
    "                \n",
    "                focus.add(next_node)\n",
    "                focus = next_node\n",
    "            \n",
    "            # next is\n",
    "            # Group\n",
    "            elif token_type == TOKEN_TYPE_OPEN_GROUP:\n",
    "#                 print('add open group')\n",
    "                \n",
    "                group = find_token_definition(value, TOKEN_TYPE_OPEN_GROUP, lambda x:x.open_token)\n",
    "                next_node = NodeGroup(group)\n",
    "                focus.add(next_node)\n",
    "                focus = next_node\n",
    "            \n",
    "            # next is\n",
    "            # New item\n",
    "            elif token_type == TOKEN_TYPE_CLOSE_GROUP:\n",
    "#                 print('close group')\n",
    "                \n",
    "                focus.close()\n",
    "            \n",
    "            # next is\n",
    "            # TOKEN_TYPE_STRING\n",
    "            # TOKEN_TYPE_INTEGER\n",
    "            # TOKEN_TYPE_NUMBER\n",
    "            # TOKEN_TYPE_LITERAL\n",
    "            elif token_type in TOKEN_TYPE_VALUE:\n",
    "#                 print('add value')\n",
    "                \n",
    "                next_node = NodeValue(value, token_type)\n",
    "                focus.add(next_node)\n",
    "                focus = next_node\n",
    "                \n",
    "            # next is \n",
    "            # TOKEN_TYPE_NEW_ITEM\n",
    "            elif token_type == TOKEN_TYPE_NEW_ITEM:\n",
    "#                 print('new item/dimension')\n",
    "                \n",
    "                focus.increase()\n",
    "                \n",
    "            # next is\n",
    "            else:\n",
    "                raise Exception(f\"token '{value}' not allowed here\")\n",
    "#                 print('start new item in parent group')\n",
    "            \n",
    "        \n",
    "    \n",
    "    return root\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Computation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_computation_graphs(token_tree):\n",
    "    \n",
    "    satatement_root_tokens = token_tree.get_children()\n",
    "    statements = [Statement(t.get_evaluable()) for t in satatement_root_tokens]\n",
    "    \n",
    "    return statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excecute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(computation_graphs, environment):\n",
    "    return [g.eval(environment) for g in computation_graphs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(query, ans_available=False):\n",
    "        \n",
    "#     commands\n",
    "#     if   query == 'exit':   break\n",
    "#     elif query == 'help':   help()\n",
    "#     elif query == 'ref':    ref()\n",
    "#     elif query == 'clear':  clear()\n",
    "#     elif query == 'copy':   pyperclip.copy(ans)\n",
    "#     elif query == '=':      pyperclip.copy(ans)\n",
    "\n",
    "#     # evaluate query\n",
    "#     elif query != \"\":\n",
    "    \n",
    "    built_in_variables = {k:v for k,v in built_ins.vars}\n",
    "    built_in_functions = {}\n",
    "    \n",
    "    for name, signature, parameters, function in built_ins.functions:\n",
    "        built_in_functions[name] = built_in_functions.get(name, Function(name))\n",
    "        built_in_functions[name][signature] = (parameters, function)\n",
    "        \n",
    "    \n",
    "    environment = {**built_in_variables, **built_in_functions}\n",
    "    print(environment, end='\\n\\n')\n",
    "    \n",
    "\n",
    "    tokens = lexing(query, ans_available)\n",
    "    print(tokens, end='\\n\\n')\n",
    "    \n",
    "    token_tree = build_token_tree(tokens)\n",
    "    print(token_tree, end='\\n\\n')\n",
    "    \n",
    "    computation_graphs = build_computation_graphs(token_tree)\n",
    "    print(computation_graphs, end='\\n\\n')\n",
    "    \n",
    "    results = evaluate(computation_graphs, environment)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PI': Tensor([Real(3.141592653589793)]), '+': Function(+, {(<class '__main__.Real'>, <class '__main__.Real'>): (['_p0', '_p1'], <function BuiltIns.register_scalar_function.<locals>.wrapper at 0x000001867F5467B8>)}), '-': Function(-, {(<class '__main__.Real'>, <class '__main__.Real'>): (['_p0', '_p1'], <function BuiltIns.register_scalar_function.<locals>.wrapper at 0x000001867F546840>)}), '*': Function(*, {(<class '__main__.Real'>, <class '__main__.Real'>): (['_p0', '_p1'], <function BuiltIns.register_scalar_function.<locals>.wrapper at 0x000001867F546400>)}), '/': Function(/, {(<class '__main__.Real'>, <class '__main__.Real'>): (['_p0', '_p1'], <function BuiltIns.register_scalar_function.<locals>.wrapper at 0x000001867F546510>)}), '//': Function(//, {(<class '__main__.Real'>, <class '__main__.Real'>): (['_p0', '_p1'], <function BuiltIns.register_scalar_function.<locals>.wrapper at 0x000001867F546158>)}), '%': Function(%, {(<class '__main__.Real'>, <class '__main__.Real'>): (['_p0', '_p1'], <function BuiltIns.register_scalar_function.<locals>.wrapper at 0x000001867F5460D0>)}), '^': Function(^, {(<class '__main__.Real'>, <class '__main__.Real'>): (['_p0', '_p1'], <function BuiltIns.register_scalar_function.<locals>.wrapper at 0x000001867F546D08>)}), '#': Function(#, {(<class '__main__.Real'>, <class '__main__.Real'>): (('_A', '_B'), <function matmul at 0x000001867F51C2F0>)})}\n",
      "\n",
      "[('number', '1'), ('binary operand', '+'), ('open group', '['), ('number', '1'), ('new item', ','), ('number', '2'), ('new item', ','), ('number', '4'), ('close group', ']'), ('binary operand', '/'), ('open group', '['), ('number', '2'), ('new item', ','), ('number', '4'), ('new item', ','), ('number', '8'), ('close group', ']'), ('binary operand', '*'), ('number', '2'), ('binary operand', '-'), ('number', '1')]\n",
      "\n",
      "NodeGroup(ROOT, children=[NodeBinary(TokenOperandDefinition(-, 3.0), left=NodeBinary(TokenOperandDefinition(+, 3.0), left=NodeValue(1, number), right=NodeBinary(TokenOperandDefinition(*, 4.0), left=NodeBinary(TokenOperandDefinition(/, 4.0), left=NodeGroup(TokenGroupDefinition([, ]), children=[NodeValue(1, number), NodeValue(2, number), NodeValue(4, number)]), right=NodeGroup(TokenGroupDefinition([, ]), children=[NodeValue(2, number), NodeValue(4, number), NodeValue(8, number)])), right=NodeValue(2, number))), right=NodeValue(1, number))])\n",
      "\n",
      "[Statement(VariableFunction_-((VariableFunction_+((VariableTensor([Real(1.0)], ()), VariableFunction_*((VariableFunction_/((VariableTensor([VariableTensor([Real(1.0)], ()), VariableTensor([Real(2.0)], ()), VariableTensor([Real(4.0)], ())], (3,)), VariableTensor([VariableTensor([Real(2.0)], ()), VariableTensor([Real(4.0)], ()), VariableTensor([Real(8.0)], ())], (3,)))), VariableTensor([Real(2.0)], ()))))), VariableTensor([Real(1.0)], ()))))]\n",
      "\n",
      "Function eval parameters [Tensor([Real(1.0) Real(2.0) Real(4.0)], (3,)), Tensor([Real(2.0) Real(4.0) Real(8.0)], (3,))] signature (<class '__main__.Real'>, <class '__main__.Real'>)\n",
      "Function eval parameters [Tensor([Real(0.5) Real(0.5) Real(0.5)], (3,)), Tensor([Real(2.0)])] signature (<class '__main__.Real'>, <class '__main__.Real'>)\n",
      "Function eval parameters [Tensor([Real(1.0)]), Tensor([Real(1.0) Real(1.0) Real(1.0)], (3,))] signature (<class '__main__.Real'>, <class '__main__.Real'>)\n",
      "Function eval parameters [Tensor([Real(2.0) Real(2.0) Real(2.0)], (3,)), Tensor([Real(1.0)])] signature (<class '__main__.Real'>, <class '__main__.Real'>)\n",
      "Tensor([Real(1.0) Real(1.0) Real(1.0)], (3,))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Tensor([Real(1.0) Real(1.0) Real(1.0)], (3,))]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc('1 + [1,2,4] / [2,4,8] * 2 - 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PI': Tensor([Real(3.141592653589793)]), '+': Function(+, {(<class '__main__.Real'>, <class '__main__.Real'>): (['_p0', '_p1'], <function BuiltIns.register_scalar_function.<locals>.wrapper at 0x000001867F5467B8>)}), '-': Function(-, {(<class '__main__.Real'>, <class '__main__.Real'>): (['_p0', '_p1'], <function BuiltIns.register_scalar_function.<locals>.wrapper at 0x000001867F546840>)}), '*': Function(*, {(<class '__main__.Real'>, <class '__main__.Real'>): (['_p0', '_p1'], <function BuiltIns.register_scalar_function.<locals>.wrapper at 0x000001867F546400>)}), '/': Function(/, {(<class '__main__.Real'>, <class '__main__.Real'>): (['_p0', '_p1'], <function BuiltIns.register_scalar_function.<locals>.wrapper at 0x000001867F546510>)}), '//': Function(//, {(<class '__main__.Real'>, <class '__main__.Real'>): (['_p0', '_p1'], <function BuiltIns.register_scalar_function.<locals>.wrapper at 0x000001867F546158>)}), '%': Function(%, {(<class '__main__.Real'>, <class '__main__.Real'>): (['_p0', '_p1'], <function BuiltIns.register_scalar_function.<locals>.wrapper at 0x000001867F5460D0>)}), '^': Function(^, {(<class '__main__.Real'>, <class '__main__.Real'>): (['_p0', '_p1'], <function BuiltIns.register_scalar_function.<locals>.wrapper at 0x000001867F546D08>)}), '#': Function(#, {(<class '__main__.Real'>, <class '__main__.Real'>): (('_A', '_B'), <function matmul at 0x000001867F51C2F0>)})}\n",
      "\n",
      "[('number', '2'), ('binary operand', '^'), ('open group', '['), ('number', '1'), ('new item', ','), ('number', '2'), ('new item', ','), ('number', '3'), ('new item', ','), ('number', '4'), ('close group', ']'), ('new item', ','), ('open group', '['), ('number', '1'), ('new item', ','), ('number', '2'), ('new item', ','), ('number', '3'), ('new item', ','), ('number', '4'), ('close group', ']'), ('binary operand', '^'), ('number', '2'), ('new item', ','), ('open group', '['), ('number', '2'), ('new item', ','), ('number', '4'), ('new item', ','), ('number', '8'), ('close group', ']'), ('binary operand', '^'), ('open group', '['), ('number', '2'), ('new item', ','), ('number', '3'), ('new item', ','), ('number', '4'), ('close group', ']'), ('new item', ','), ('literal', 'PI'), ('binary operand', '*'), ('open group', '['), ('number', '1'), ('binary operand', '/'), ('number', '2'), ('new item', ','), ('number', '1'), ('new item', ','), ('number', '2'), ('new item', ','), ('new item', ','), ('new item', ','), ('close group', ']')]\n",
      "\n",
      "NodeGroup(ROOT, children=[NodeBinary(TokenOperandDefinition(^, 5.0), left=NodeValue(2, number), right=NodeGroup(TokenGroupDefinition([, ]), children=[NodeValue(1, number), NodeValue(2, number), NodeValue(3, number), NodeValue(4, number)])), NodeBinary(TokenOperandDefinition(^, 5.0), left=NodeGroup(TokenGroupDefinition([, ]), children=[NodeValue(1, number), NodeValue(2, number), NodeValue(3, number), NodeValue(4, number)]), right=NodeValue(2, number)), NodeBinary(TokenOperandDefinition(^, 5.0), left=NodeGroup(TokenGroupDefinition([, ]), children=[NodeValue(2, number), NodeValue(4, number), NodeValue(8, number)]), right=NodeGroup(TokenGroupDefinition([, ]), children=[NodeValue(2, number), NodeValue(3, number), NodeValue(4, number)])), NodeBinary(TokenOperandDefinition(*, 4.0), left=NodeValue(PI, literal), right=NodeGroup(TokenGroupDefinition([, ]), children=[NodeBinary(TokenOperandDefinition(/, 4.0), left=NodeValue(1, number), right=NodeValue(2, number)), NodeValue(1, number), NodeValue(2, number)]))])\n",
      "\n",
      "[Statement(VariableFunction_^((VariableTensor([Real(2.0)], ()), VariableTensor([VariableTensor([Real(1.0)], ()), VariableTensor([Real(2.0)], ()), VariableTensor([Real(3.0)], ()), VariableTensor([Real(4.0)], ())], (4,))))), Statement(VariableFunction_^((VariableTensor([VariableTensor([Real(1.0)], ()), VariableTensor([Real(2.0)], ()), VariableTensor([Real(3.0)], ()), VariableTensor([Real(4.0)], ())], (4,)), VariableTensor([Real(2.0)], ())))), Statement(VariableFunction_^((VariableTensor([VariableTensor([Real(2.0)], ()), VariableTensor([Real(4.0)], ()), VariableTensor([Real(8.0)], ())], (3,)), VariableTensor([VariableTensor([Real(2.0)], ()), VariableTensor([Real(3.0)], ()), VariableTensor([Real(4.0)], ())], (3,))))), Statement(VariableFunction_*((Variable(PI), VariableTensor([VariableFunction_/((VariableTensor([Real(1.0)], ()), VariableTensor([Real(2.0)], ()))), VariableTensor([Real(1.0)], ()), VariableTensor([Real(2.0)], ())], (1, 1, 3)))))]\n",
      "\n",
      "Function eval parameters [Tensor([Real(2.0)]), Tensor([Real(1.0) Real(2.0) Real(3.0) Real(4.0)], (4,))] signature (<class '__main__.Real'>, <class '__main__.Real'>)\n",
      "Tensor([Real(2.0) Real(4.0) Real(8.0) Real(16.0)], (4,))\n",
      "Function eval parameters [Tensor([Real(1.0) Real(2.0) Real(3.0) Real(4.0)], (4,)), Tensor([Real(2.0)])] signature (<class '__main__.Real'>, <class '__main__.Real'>)\n",
      "Tensor([Real(1.0) Real(4.0) Real(9.0) Real(16.0)], (4,))\n",
      "Function eval parameters [Tensor([Real(2.0) Real(4.0) Real(8.0)], (3,)), Tensor([Real(2.0) Real(3.0) Real(4.0)], (3,))] signature (<class '__main__.Real'>, <class '__main__.Real'>)\n",
      "Tensor([Real(4.0) Real(64.0) Real(4096.0)], (3,))\n",
      "Function eval parameters [Tensor([Real(1.0)]), Tensor([Real(2.0)])] signature (<class '__main__.Real'>, <class '__main__.Real'>)\n",
      "Function eval parameters [Tensor([Real(3.141592653589793)]), Tensor([Real(0.5) Real(1.0) Real(2.0)], (1, 1, 3))] signature (<class '__main__.Real'>, <class '__main__.Real'>)\n",
      "Tensor([Real(1.5707963267948966) Real(3.141592653589793) Real(6.283185307179586)], (1, 1, 3))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Tensor([Real(2.0) Real(4.0) Real(8.0) Real(16.0)], (4,)),\n",
       " Tensor([Real(1.0) Real(4.0) Real(9.0) Real(16.0)], (4,)),\n",
       " Tensor([Real(4.0) Real(64.0) Real(4096.0)], (3,)),\n",
       " Tensor([Real(1.5707963267948966) Real(3.141592653589793) Real(6.283185307179586)], (1, 1, 3))]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc('2 ^ [1,2,3,4], [1,2,3,4] ^ 2, [2,4,8] ^ [2,3,4], PI * [1/2, 1, 2,,,]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PI': Tensor([Real(3.141592653589793)]), '+': Function(+, {(<class '__main__.Real'>, <class '__main__.Real'>): (['_p0', '_p1'], <function BuiltIns.register_scalar_function.<locals>.wrapper at 0x000001867F5467B8>)}), '-': Function(-, {(<class '__main__.Real'>, <class '__main__.Real'>): (['_p0', '_p1'], <function BuiltIns.register_scalar_function.<locals>.wrapper at 0x000001867F546840>)}), '*': Function(*, {(<class '__main__.Real'>, <class '__main__.Real'>): (['_p0', '_p1'], <function BuiltIns.register_scalar_function.<locals>.wrapper at 0x000001867F546400>)}), '/': Function(/, {(<class '__main__.Real'>, <class '__main__.Real'>): (['_p0', '_p1'], <function BuiltIns.register_scalar_function.<locals>.wrapper at 0x000001867F546510>)}), '//': Function(//, {(<class '__main__.Real'>, <class '__main__.Real'>): (['_p0', '_p1'], <function BuiltIns.register_scalar_function.<locals>.wrapper at 0x000001867F546158>)}), '%': Function(%, {(<class '__main__.Real'>, <class '__main__.Real'>): (['_p0', '_p1'], <function BuiltIns.register_scalar_function.<locals>.wrapper at 0x000001867F5460D0>)}), '^': Function(^, {(<class '__main__.Real'>, <class '__main__.Real'>): (['_p0', '_p1'], <function BuiltIns.register_scalar_function.<locals>.wrapper at 0x000001867F546D08>)}), '#': Function(#, {(<class '__main__.Real'>, <class '__main__.Real'>): (('_A', '_B'), <function matmul at 0x000001867F57D620>)})}\n",
      "\n",
      "[('open group', '['), ('number', '1'), ('new item', ','), ('number', '2'), ('new item', ','), ('new item', ','), ('number', '3'), ('new item', ','), ('number', '4'), ('new item', ','), ('new item', ','), ('new item', ','), ('number', '5'), ('new item', ','), ('number', '6'), ('new item', ','), ('new item', ','), ('number', '7'), ('new item', ','), ('number', '8'), ('close group', ']'), ('binary operand', '#'), ('open group', '['), ('number', '5'), ('new item', ','), ('number', '6'), ('new item', ','), ('new item', ','), ('number', '7'), ('new item', ','), ('number', '8'), ('new item', ','), ('new item', ','), ('new item', ','), ('number', '1'), ('new item', ','), ('number', '2'), ('new item', ','), ('new item', ','), ('number', '3'), ('new item', ','), ('number', '4'), ('close group', ']')]\n",
      "\n",
      "NodeGroup(ROOT, children=[NodeBinary(TokenOperandDefinition(#, 4.0), left=NodeGroup(TokenGroupDefinition([, ]), children=[NodeValue(1, number), NodeValue(2, number), NodeValue(3, number), NodeValue(4, number), NodeValue(5, number), NodeValue(6, number), NodeValue(7, number), NodeValue(8, number)]), right=NodeGroup(TokenGroupDefinition([, ]), children=[NodeValue(5, number), NodeValue(6, number), NodeValue(7, number), NodeValue(8, number), NodeValue(1, number), NodeValue(2, number), NodeValue(3, number), NodeValue(4, number)]))])\n",
      "\n",
      "[Statement(VariableFunction_#((VariableTensor([VariableTensor([Real(1.0)], ()), VariableTensor([Real(2.0)], ()), VariableTensor([Real(3.0)], ()), VariableTensor([Real(4.0)], ()), VariableTensor([Real(5.0)], ()), VariableTensor([Real(6.0)], ()), VariableTensor([Real(7.0)], ()), VariableTensor([Real(8.0)], ())], (2, 2, 2)), VariableTensor([VariableTensor([Real(5.0)], ()), VariableTensor([Real(6.0)], ()), VariableTensor([Real(7.0)], ()), VariableTensor([Real(8.0)], ()), VariableTensor([Real(1.0)], ()), VariableTensor([Real(2.0)], ()), VariableTensor([Real(3.0)], ()), VariableTensor([Real(4.0)], ())], (2, 2, 2)))))]\n",
      "\n",
      "Function eval parameters [Tensor([Real(1.0) Real(2.0) Real(3.0) Real(4.0) Real(5.0) Real(6.0) Real(7.0)\n",
      " Real(8.0)], (2, 2, 2)), Tensor([Real(5.0) Real(6.0) Real(7.0) Real(8.0) Real(1.0) Real(2.0) Real(3.0)\n",
      " Real(4.0)], (2, 2, 2))] signature (<class '__main__.Real'>, <class '__main__.Real'>)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Real' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-84d0517bd136>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcalc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[1,2,,3,4,,,5,6,,7,8] # [5,6,,7,8,,,1,2,,3,4]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-40-dbb5630de61c>\u001b[0m in \u001b[0;36mcalc\u001b[1;34m(query, ans_available)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputation_graphs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\n\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputation_graphs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menvironment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-39-e21679a6e795>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(computation_graphs, environment)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputation_graphs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menvironment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcomputation_graphs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-39-e21679a6e795>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputation_graphs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menvironment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcomputation_graphs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-5476de534196>\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, environment)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menvironment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-744d3588d991>\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, environment)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0menvironment\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-316807de3acb>\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, environment, parameters)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mnew_scoped_environment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0menvironment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameter_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_scoped_environment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-3330489250dd>\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(e)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'_A'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'_B'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0ma_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mb_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Real' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "calc('[1,2,,3,4,,,5,6,,7,8] # [5,6,,7,8,,,1,2,,3,4]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc('(1.2e-4+e) ^ -2j! -000.4e3j % fun(12cm, a, 7).abs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
