{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import math, pyperclip, os, re\n",
    "from decimal import Decimal as _Decimal\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data types: Real, Complex, Int, Boolean, String, Undefined\n",
    "Data structures: Scalar, Vector, Matrix, ...\n",
    "Variables: v\n",
    "Functions: fun\n",
    "Named operators: v operation u\n",
    "Conversion specifier: 45deg\n",
    "Data properties: object.property\n",
    "Oppertation: Numeric, Sets, Comparison \n",
    "\n",
    "Data Structures\n",
    "Tensor: [a, b,, c, d,,, ...]\n",
    "List: (a, b, c, ...)\n",
    "Function Body: {expression}\n",
    "\n",
    "Implicit Operations\n",
    "2(expression)      *\n",
    "(expression)2      *\n",
    "var(expression)    *\n",
    "fun(parameters)    call\n",
    "\n",
    "Named operators\n",
    "on two values: v operation u\n",
    "on one value: v.operation\n",
    "\n",
    "Input and Output conversion\n",
    "1m + 12cm @ cm\n",
    "2hr + 45min + 1hr + 30min @ datetime\n",
    "0b1100 * 0xFF @ dec\n",
    "\n",
    "Basic Operations:\n",
    "Standard:       | Bitwise: int&bool | Comparison:           | \n",
    "+           add | ~             not | ==             equals | \n",
    "-      subtract | &&            and | !=          not equal | \n",
    "*      multiply | ||             or | <           less than | \n",
    "/        divide | <xor>         xor | >        greater then | \n",
    "//      int div | <<     left shift | <=      less or equal | \n",
    "%       modulus | >>    right shift | >=   greater or equal | \n",
    "^         power |                   |                       | \n",
    "!     factorial |                   |                       | \n",
    "|val|  absolute |                   |                       | \n",
    "=    assignment |                   |                       | \n",
    "\n",
    "Ternary Operators\n",
    "= =                return values = function = body\n",
    "a < x < b          between\n",
    "a if cond else b   \n",
    "\n",
    "Higher Ranking Data Structure Operations:\n",
    "Vector:                 | Matrix:                          | Reductions:\n",
    "<dot>       dot product | <matmul>   matrix multiplication | <all>\n",
    "<cross>   cross product | |mat|                            | <any>\n",
    "|vec|            length | .T              transpose matrix | <\n",
    ".length          length | \n",
    ".angle            angle | \n",
    "\n",
    "\n",
    "\n",
    "1 + sqrt 4\n",
    "1 + sqrt x\n",
    "1 + $4\n",
    "1 + 3 root 8\n",
    "1 + b root x\n",
    "1 + b $ x\n",
    "\n",
    "10 nPr 2\n",
    "n nPr r\n",
    "10 nCr 2\n",
    "n nCr r\n",
    "\n",
    "[1, 2,, 3, 4] # [5, 6,, 7, 8]\n",
    "[1, 2,, 3, 4].T\n",
    "mat1.T\n",
    "\n",
    "5*x\n",
    "\n",
    "sin 30deg\n",
    "sin pi\n",
    "sin2 pi\n",
    "sini 0.5\n",
    "\n",
    "Function definitions\n",
    "fun = x => x^2               single value output\n",
    "fun = x => [x, x*2, x^2]     tensor outputs\n",
    "fun = x => (x, x*2, x^2)     multiple outputs\n",
    "fun = x => {                 piecewise function\n",
    "    0,   if x < 0 ; \n",
    "    x^2, if 0 <= x <= 1 ; \n",
    "    x,   else\n",
    "}\n",
    "\n",
    "fun = (x,y,z) => {\n",
    "    a = x+2 ; \n",
    "    b = y*2 ; \n",
    "    c = z^2 ; \n",
    "    (a,b,c)\n",
    "}\n",
    "\n",
    "if x < 0 do {\n",
    "    x = 0\n",
    "}\n",
    "\n",
    "for i in 0:10 do {\n",
    "    x += i\n",
    "}\n",
    "\n",
    "while x < 0 do {\n",
    "    x += 1\n",
    "}\n",
    "\n",
    "@display = scientific 8\n",
    "@display = hex\n",
    "\n",
    "\n",
    "Statistical Operations:\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Conversion specifiers\n",
    "\n",
    "Time:\n",
    "    Seconds: s, ms, µs, ns, ps, \n",
    "        fs, as, zs, ys, ks, Ms, Gs, Ts, Ps, Es, Zs, Ys\n",
    "    Other: min, hr, D, W, M, Y, am, pm\n",
    "    \n",
    "Distance:\n",
    "    Metric: m, dm, cm, mm, µm, nm, pm, km, \n",
    "        fm, am, zm, ym, Mm, Gm, Tm, Pm, Em, Zm, Ym\n",
    "    Imperial: th, in, ft, yd, mi\n",
    "    Other: nmi\n",
    "\n",
    "Mass: \n",
    "    Metrix: mg, µg, ng, pg, kg, Mg, tonne\n",
    "        dg, cg, fg, ag, zg, yg, dag, hg, Mg, Gg, Tg, Pg, Eg, Zg, Yg\n",
    "    Imperial: oz, lb, ton\n",
    "    Other: mol\n",
    "    \n",
    "Temparature: K, C, F, R\n",
    "\n",
    "Luminosity: cd, lx\n",
    "\n",
    "Force: N, kN, lbf, pdl\n",
    "\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Token Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### TokenOperandDefinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class TokenOperandDefinition():\n",
    "    def __init__(self, token, precedence):\n",
    "        \n",
    "        self.token = token\n",
    "        self.precedence = float(precedence)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'TokenOperandDefinition({self.token}, {self.precedence})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### TokenGroupDefinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class TokenGroupDefinition():\n",
    "    def __init__(self, open_token, close_token, function):\n",
    "        \n",
    "        self.open_token = open_token\n",
    "        self.close_token = close_token\n",
    "        \n",
    "        self.function = function\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'TokenGroupDefinition({self.open_token}, {self.close_token})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### TokenNewItemDefinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class TokenNewItemDefinition():\n",
    "    def __init__(self, token, depth):\n",
    "        \n",
    "        self.token = token\n",
    "        self.depth = int(depth)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'TokenNewItemDefinition({self.token}, {self.levels})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Token Tree Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Abstract NodeToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NodeToken():\n",
    "    \"\"\"\n",
    "    represents a token that can be parsed\n",
    "    \"\"\"\n",
    "    \n",
    "    def is_complete(self):\n",
    "        raise Exception('is_complete() not implemented')\n",
    "        \n",
    "    def set_left(self, node):\n",
    "        raise Exception('set_left(node) not implemented')\n",
    "\n",
    "    def set_right(self, node):\n",
    "        raise Exception('set_right(node) not implemented')\n",
    "        \n",
    "    def get_right(self):\n",
    "        raise Exception('get_right() not implemented')\n",
    "        \n",
    "    def get_evaluable(self):\n",
    "        raise Exception('get_evaluable() not implemented')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### NodeBinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NodeBinary(NodeToken):\n",
    "    \"\"\"\n",
    "    represents a token that can be parsed into a value/operation\n",
    "    \"\"\"\n",
    "    def __init__(self, operation_definition, parent=None):\n",
    "        self.parent = parent\n",
    "        self.operation_definition = operation_definition\n",
    "        self.precedence = operation_definition.precedence\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "    \n",
    "    def is_complete(self):\n",
    "        return self.left != None and self.right != None\n",
    "        \n",
    "    def set_left(self, node):\n",
    "        self.left = node\n",
    "        node.parent = self\n",
    "\n",
    "    def set_right(self, node):\n",
    "        self.right = node\n",
    "        node.parent = self\n",
    "        \n",
    "    def get_right(self):\n",
    "        return self.right\n",
    "    \n",
    "    def get_evaluable(self):\n",
    "        return VariableFunction(self.operation_definition.token, (self.left.get_evaluable(), self.right.get_evaluable()))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'NodeBinary({self.operation_definition}, left={self.left}, right={self.right})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### NodeUnaryLeft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NodeUnaryLeft(NodeToken):\n",
    "    \n",
    "    def __init__(self, operation_definition, parent=None):\n",
    "        self.parent = parent\n",
    "        self.operation_definition = operation_definition\n",
    "        self.precedence = operation_definition.precedence\n",
    "        self.child = None\n",
    "    \n",
    "    def is_complete(self):\n",
    "        return self.child != None\n",
    "        \n",
    "    def set_left(self, node):\n",
    "        self.child = node\n",
    "        node.parent = self\n",
    "\n",
    "    def set_right(self, node):\n",
    "        self.child = node\n",
    "        node.parent = self\n",
    "        \n",
    "    def get_right(self):\n",
    "        return self.child\n",
    "    \n",
    "    def get_evaluable(self):\n",
    "        return VariableFunction(self.operation_definition.token, (self.child.get_evaluable(), ))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'NodeUnaryLeft({self.operation_definition}, child={self.child})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### NodeUnaryRight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NodeUnaryRight(NodeToken):\n",
    "    \n",
    "    def __init__(self, operation_definition, parent=None):\n",
    "        self.parent = parent\n",
    "        self.operation_definition = operation_definition\n",
    "        self.precedence = operation_definition.precedence\n",
    "        self.child = None\n",
    "    \n",
    "    def is_complete(self):\n",
    "        return self.child != None\n",
    "        \n",
    "    def set_left(self, node):\n",
    "        self.child = node\n",
    "        node.parent = self\n",
    "\n",
    "    def set_right(self, node):\n",
    "        self.child = node\n",
    "        node.parent = self\n",
    "        \n",
    "    def get_right(self):\n",
    "        return self.child\n",
    "    \n",
    "    def get_evaluable(self):\n",
    "        return VariableFunction(self.operation_definition.token, (self.child.get_evaluable(), ))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'NodeUnaryRight({self.operation_definition}, child={self.child})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### NodeGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NodeGroup(NodeToken):\n",
    "    \n",
    "    def __init__(self, group_definition, parent=None):\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        \n",
    "        self.group_definition = group_definition\n",
    "        self.complete = False\n",
    "        \n",
    "        self.shape = {}\n",
    "        self.sep_count = 0\n",
    "    \n",
    "    def is_complete(self):\n",
    "        return self.complete\n",
    "\n",
    "    def close(self):\n",
    "        self.sep_count = 0\n",
    "        self.complete = True\n",
    "        \n",
    "        expected_size = 1\n",
    "        for d,s in self.shape.items(): expected_size *= s\n",
    "        \n",
    "        assert len(self.children) == expected_size, f'Inconsistent dimensions shape={self.shape}, expected={expected_size}, actual={len(self.children)}'\n",
    "    \n",
    "    def set_right(self, node):\n",
    "        self.children[-1] = node\n",
    "        node.parent = self\n",
    "        \n",
    "    def get_right(self):\n",
    "        return self.children[-1]\n",
    "\n",
    "    def add(self, node):\n",
    "        self.children.append(node)\n",
    "        node.parent = self\n",
    "        \n",
    "        if len(self.shape) > 0 and self.sep_count >= len(self.shape):\n",
    "            for i in range(len(self.shape), self.sep_count+1):\n",
    "                self.shape[i-1] = self.shape.get(i-1, 1)\n",
    "            self.shape[self.sep_count-1] += 1\n",
    "            \n",
    "        self.sep_count = 0\n",
    "        \n",
    "    def increase(self, depth=1):\n",
    "        self.sep_count += depth\n",
    "        \n",
    "        if len(self.shape) == 0:\n",
    "            self.shape[0] = 1\n",
    "        \n",
    "        # ensure minumum number of dimensions exists\n",
    "        for i in range(len(self.shape), self.sep_count+1):\n",
    "            self.shape[i-1] = self.shape.get(i-1, 1)\n",
    "    \n",
    "    def get_shape(self):\n",
    "        shape = list(self.shape.items())\n",
    "        shape.sort(key=lambda x:x[0], reverse=True)\n",
    "        shape = tuple(s for d,s in shape)\n",
    "        return shape\n",
    "    \n",
    "    def get_children(self):\n",
    "        return self.children\n",
    "    \n",
    "    def get_evaluable(self):\n",
    "        \n",
    "        evaluables = [v.get_evaluable() for v in self.children]\n",
    "        \n",
    "        return VariableTensor(evaluables, self.get_shape(), self.group_definition.function)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'NodeGroup({self.group_definition}, children={self.children})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### NodeValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NodeValue(NodeToken):\n",
    "    \n",
    "    def __init__(self, value, value_type, parent=None):\n",
    "        self.parent = parent\n",
    "        self.value = value\n",
    "        self.value_type = value_type\n",
    "    \n",
    "    def is_complete(self):\n",
    "        return True\n",
    "    \n",
    "    def get_evaluable(self):\n",
    "\n",
    "        value = None\n",
    "        if self.value_type == TOKEN_TYPE_STRING:\n",
    "            value = String(self.value)\n",
    "            value = VariableTensor([value], ())\n",
    "            \n",
    "        if self.value_type == TOKEN_TYPE_INTEGER:\n",
    "            value = Integer(self.value)\n",
    "            value = VariableTensor([value], ())\n",
    "            \n",
    "        if self.value_type == TOKEN_TYPE_NUMBER:\n",
    "            value = Real(self.value)\n",
    "            value = VariableTensor([value], ())\n",
    "            \n",
    "        if self.value_type == TOKEN_TYPE_LITERAL:\n",
    "            value = Variable(self.value)\n",
    "        \n",
    "        return value\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'NodeValue({self.value}, {self.value_type})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluable Tree Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Abstract Evaluable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Evaluable():\n",
    "    \"\"\"\n",
    "    represents a node that can be evaluated\n",
    "    \"\"\"\n",
    "    \n",
    "    def eval(self, environment, **kwargs):\n",
    "        raise Exception('eval(environment) not implemented')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Statement - results in one print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Statement():\n",
    "    \n",
    "    def __init__(self, node):\n",
    "        self.node = node\n",
    "        \n",
    "    def eval(self, environment, evaluable=False, **kwargs):\n",
    "        \n",
    "        if evaluable:\n",
    "            return self.node\n",
    "        \n",
    "        result = self.node.eval(environment)\n",
    "#         print(result)\n",
    "        return result\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'Statement({self.node})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### VariableFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class VariableFunction(Evaluable):\n",
    "    \n",
    "    def __init__(self, name, parameters):\n",
    "        \n",
    "        self.dtype = Evaluable\n",
    "        self.name = name\n",
    "        self.parameters = parameters\n",
    "        if isinstance(parameters, VariableTensor):\n",
    "            self.parameters = parameters.data\n",
    "    \n",
    "    def eval(self, environment, evaluable=False, **kwargs):\n",
    "        \n",
    "        if evaluable:\n",
    "            return self\n",
    "        \n",
    "        assert self.name in environment, f'Function {self.name} not found'\n",
    "        assert type(environment[self.name]) == FunctionSet, f'{self.name} is not a function'\n",
    "        \n",
    "        return environment[self.name].eval(environment, self.parameters)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'VariableFunction_{self.name}({self.parameters})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Variable(Evaluable):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        \n",
    "        self.dtype = Evaluable\n",
    "        self.name = name\n",
    "    \n",
    "    def eval(self, environment, references=False, evaluable=False, **kwargs):\n",
    "        \n",
    "        if references:\n",
    "            return Tensor(Reference(self.name), ())\n",
    "        \n",
    "        if evaluable:\n",
    "            return self\n",
    "        \n",
    "        if self.name not in environment:\n",
    "            raise Exception(f'Variable {self.name} not found')\n",
    "        \n",
    "        return environment[self.name]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"Variable({self.name})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### VariableTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class VariableTensor(Evaluable):\n",
    "    \n",
    "    def __init__(self, data, shape, function=None):\n",
    "        \n",
    "        self.dtype = Evaluable\n",
    "        self.data = data\n",
    "        self.shape = shape\n",
    "        self.function = function\n",
    "    \n",
    "    def eval(self, environment, evaluable=False, **kwargs):\n",
    "        \n",
    "        if evaluable:\n",
    "            return self\n",
    "        \n",
    "        values = [v.eval(environment, **kwargs) for v in self.data]\n",
    "        \n",
    "        if self.function == None and self.shape == ():\n",
    "            return Tensor(values[:1], self.shape)\n",
    "        else:\n",
    "            return self.function(environment, values, self.shape, **kwargs)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'VariableTensor({self.data}, {self.shape})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Tensor(Evaluable):\n",
    "    \"\"\"\n",
    "    represents a value/tensor of any type, shape and rank\n",
    "    \"\"\"\n",
    "    def __init__(self, data, shape=()):\n",
    "        \n",
    "        data = np.array(data, object)\n",
    "        data = data.reshape((data.size,))\n",
    "        \n",
    "        assert data.size > 0, 'Tensor cannot be empty'\n",
    "        \n",
    "        if all(type(t) == Tensor for t in data):\n",
    "            inner_shape = data[0].shape\n",
    "            assert all(t.shape == inner_shape for t in data), 'Cannot combine tensors of different shapes'\n",
    "            \n",
    "            data = np.concatenate([t.data for t in data])\n",
    "            shape = shape + inner_shape\n",
    "        \n",
    "        self._data = np.array(data, object).reshape(shape)\n",
    "        self.data = self._data.reshape((self._data.size))\n",
    "        \n",
    "        self.first = self.data[0]\n",
    "        self.shape = self._data.shape\n",
    "        self.size = self._data.size\n",
    "        self.rank = self._data.ndim\n",
    "        self.dtype = type(self.data[0])\n",
    "        \n",
    "        assert all([type(i) == self.dtype for i in self.data]), 'All items in a Tensor must be of the same type'\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        data = self.data[index] if type(index) == int else self._data[index]\n",
    "        shape = data.shape if type(data) == np.ndarray else ()\n",
    "            \n",
    "        return Tensor(data, shape)\n",
    "        \n",
    "    def __setitem__(self, index, value):\n",
    "        \n",
    "        if type(value) == Tensor:\n",
    "            value = value._data\n",
    "        \n",
    "        if type(index) == int:\n",
    "            self.data[index] = value\n",
    "        else:\n",
    "            self._data[index] = value\n",
    "    \n",
    "    def eval(self, environment, **kwargs):\n",
    "        return self\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        \n",
    "        if self.rank == 0:\n",
    "            return f'Tensor({self.data[()]})'\n",
    "        else:\n",
    "            return f'Tensor({self.data}, {self.shape})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Array(Evaluable):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = np.array(data, object)\n",
    "        self.data = self.data.reshape((self.data.size,))\n",
    "        self.size = self.data.size\n",
    "        self.dtype = Array\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        if type(index) == int:\n",
    "            return self.data[index]\n",
    "        else:\n",
    "            return Array(self.data[index])\n",
    "        \n",
    "    def __setitem__(self, index, value):\n",
    "        self.data[index] = value\n",
    "    \n",
    "    def eval(self, environment, **kwargs):\n",
    "        return self\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'Array({self.data[()]})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FunctionSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionSet(Evaluable):\n",
    "    \n",
    "    def __init__(self, name, evaluation_paremeters=None):\n",
    "        self.name = name\n",
    "        self.signatures = {}\n",
    "        self.evaluation_paremeters = evaluation_paremeters or {}\n",
    "        \n",
    "        self.dtype = FunctionSet\n",
    "        \n",
    "    def __contains__(self, partial_signature):\n",
    "        l = len(partial_signature)\n",
    "        for signature in self.signatures:\n",
    "            if signature[:l] == partial_signature:\n",
    "                return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    def __getitem__(self, signature):\n",
    "        return self.signatures[signature]\n",
    "    \n",
    "    def __setitem__(self, signature, value):\n",
    "        par_names, function = value\n",
    "        self.signatures[signature] = (par_names, function)\n",
    "        \n",
    "    def add(self, function_signature):\n",
    "        self.signatures[function_signature.parameter_types] = function_signature\n",
    "        \n",
    "    def eval(self, environment, parameters, **kwargs):\n",
    "        \n",
    "        parameters = list(parameters)\n",
    "        signature = [type(p) for p in parameters]\n",
    "        \n",
    "        for i, parameter in enumerate(parameters):\n",
    "            eval_params = self.evaluation_paremeters.get(i, {})\n",
    "            parameters[i] = parameter.eval(environment, **eval_params)\n",
    "            signature[i] = parameters[i].dtype\n",
    "        \n",
    "        signature = tuple(signature)\n",
    "        function_signature = None\n",
    "        \n",
    "        for signature_candidate in self.signatures:\n",
    "            if len(signature) == len(signature_candidate) and all([a==b or a==None for a,b in zip(signature_candidate, signature)]):\n",
    "                function_signature = self.signatures[signature_candidate]\n",
    "        \n",
    "#         assert signature in self.signatures, f'Signature {self.name}{tuple(p.__name__ for p in signature)} has no matching overload'\n",
    "        assert function_signature != None, f'Signature {self.name}{tuple(p.__name__ for p in signature)} has no matching overload'\n",
    "            \n",
    "#         function_signature = self.signatures[signature]\n",
    "        \n",
    "        function = function_signature.function\n",
    "        parameter_names = function_signature.parameter_names\n",
    "        \n",
    "        actual_shapes = [p.shape if type(p) == Tensor else () for p in parameters]\n",
    "        actual_ranks = [len(s) for s in actual_shapes]\n",
    "        \n",
    "        ranks = [r if r!=None else a for r,a in zip(function_signature.parameter_ranks, actual_ranks)]\n",
    "        extended_shapes = [s if r==0 else s[:-r] for s,r in zip(actual_shapes, ranks)]\n",
    "        \n",
    "        extended_shape = reduce(lambda x,y: x if len(x) > len(y) else y, extended_shapes)\n",
    "        extended_ranks = [len(s) for s in extended_shapes]\n",
    "        \n",
    "        assert all([s in [extended_shape, ()] for s in extended_shapes]), f'Ranks, shape or extended shapes do not match'\n",
    "        \n",
    "        if extended_shape == ():\n",
    "            return self.runFunction(function, environment, parameter_names, parameters)\n",
    "        \n",
    "        else:\n",
    "            data = np.empty(extended_shape, dtype=object)\n",
    "            \n",
    "            for i in product(*[range(d) for d in extended_shape]):\n",
    "                extracted_parameters = [p if r == 0 else p[i] for p, r in zip(parameters, extended_ranks)]\n",
    "                \n",
    "                data[i] = self.runFunction(function, environment, parameter_names, extracted_parameters)._data.tolist()\n",
    "                    \n",
    "            data = np.array(data.tolist())\n",
    "            \n",
    "            return Tensor(data, data.shape)\n",
    "        \n",
    "    def runFunction(self, function, environment, parameter_names, parameters):\n",
    "        \n",
    "        if parameter_names == False or parameter_names == None:\n",
    "            return function(*parameters)\n",
    "        \n",
    "        elif parameter_names == True:\n",
    "            return function(environment, *parameters)\n",
    "\n",
    "        else:\n",
    "            new_scoped_environment = environment.enterScope({k:v for k,v in zip(parameter_names, parameters)})\n",
    "            return function(new_scoped_environment)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'FunctionSet({self.name}, {self.signatures})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Abstract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Data(Evaluable):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class String(Data):\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "    \n",
    "    def eval(self, environment, **kwargs):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Integer(Data):\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "    \n",
    "    def eval(self, environment, **kwargs):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Real(Data):\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        self.value = float(value)\n",
    "    \n",
    "    def eval(self, environment, **kwargs):\n",
    "        return self\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'Real({self.value})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Boolean(Data):\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "    \n",
    "    def eval(self, environment, **kwargs):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### FunctionSignature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class FunctionSignature():\n",
    "    \n",
    "    def __init__(self, name, function, parameter_names, parameter_types, parameter_ranks=None, parameter_shapes=None):\n",
    "        \n",
    "        self.name = name\n",
    "        self.function = function\n",
    "        self.parameter_count = len(parameter_types)\n",
    "        self.parameter_names = parameter_names\n",
    "        self.parameter_types = parameter_types\n",
    "        self.parameter_ranks = parameter_ranks or self.parameter_count*(None,)\n",
    "        self.parameter_shapes = parameter_shapes or self.parameter_count*(None,)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'FunctionSignature{(self.name, self.function, self.parameter_names, self.parameter_types, self.parameter_ranks, self.parameter_shapes)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Reference(Data):\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "    \n",
    "    def eval(self, environment, **kwargs):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### ConversionSpecification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ConversionSpecification(Data):\n",
    "    \n",
    "    def __init__(self, forward, backward):\n",
    "        self.forward = forward\n",
    "        self.backward = backward\n",
    "        \n",
    "    def eval(self, environment, parameter, direction=1, **kwargs):\n",
    "        \n",
    "        if direction  > 0:\n",
    "            return self.forward(parameter)\n",
    "        \n",
    "        if direction  < 0:\n",
    "            return self.backward(parameter)\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built In Functions, Operators and Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### BuiltIns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class BuiltIns():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.functions = []\n",
    "        self.function_parameter_evaluation_parameters = {}\n",
    "        self.vars = []\n",
    "        self.binary_operators = []\n",
    "        self.left_unary_operators = []\n",
    "        self.right_unary_operators = []\n",
    "        self.groups = []\n",
    "        self.new_items = []\n",
    "        \n",
    "    def register_function(self, name, function, parameter_names, parameter_types, parameter_ranks=None, parameter_shapes=None):\n",
    "        self.functions.append((name, function, parameter_names, parameter_types, parameter_ranks, parameter_shapes))\n",
    "        \n",
    "    def set_evaluation_parameter(self, function_name, parameter_index, key, value):\n",
    "        parameter_list = self.function_parameter_evaluation_parameters.get(function_name, {})\n",
    "        parameters = parameter_list.get(parameter_index, {})\n",
    "        parameters[key] = value\n",
    "        parameter_list[parameter_index] = parameters\n",
    "        self.function_parameter_evaluation_parameters[function_name] = parameter_list\n",
    "        \n",
    "    def register_binary_operator(self, name, precedence):\n",
    "        self.binary_operators.append(TokenOperandDefinition(name, precedence))\n",
    "        \n",
    "    def register_left_unary_operator(self, name, precedence):\n",
    "        self.left_unary_operators.append(TokenOperandDefinition(name, precedence))\n",
    "        \n",
    "    def register_right_unary_operator(self, name, precedence):\n",
    "        self.right_unary_operators.append(TokenOperandDefinition(name, precedence))\n",
    "        \n",
    "    def register_var(self, name, value):\n",
    "        self.vars.append((name, value))\n",
    "        \n",
    "    def register_grouping(self, open_token, close_token, function):\n",
    "        self.groups.append(TokenGroupDefinition(open_token, close_token, function))\n",
    "        \n",
    "    def register_new_item_seperator(self, token, depth):\n",
    "        self.new_items.append(TokenNewItemDefinition(token, depth))\n",
    "        \n",
    "        \n",
    "built_ins = BuiltIns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Group ( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def group_round(environment, items, shape, force_array=False, **kwargs):\n",
    "    \n",
    "    if shape == () and force_array == False:\n",
    "        return items[0]\n",
    "    else:\n",
    "        return Array(items)\n",
    "\n",
    "built_ins.register_grouping('(', ')', group_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Group [ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def group_squre(environment, items, shape, **kwargs):\n",
    "    \n",
    "    assert len(items) > 0, 'Tensors can not be empty'\n",
    "    \n",
    "    base_shape = items[0].shape\n",
    "    assert all([i.shape == base_shape for i in items]), 'Tensor elements have inconsistent shapes'\n",
    "    \n",
    "    extended_shape = shape + base_shape\n",
    "    data = np.array([i.data for i in items]).reshape(extended_shape)\n",
    "    \n",
    "    return Tensor(data, extended_shape)\n",
    "\n",
    "built_ins.register_grouping('[', ']', group_squre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Group { }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Group | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def group_straight(environment, items, shape, **kwargs):\n",
    "    \n",
    "    assert shape == (), 'Cannot take absolute value of an array'\n",
    "    assert items[0].dtype == Real, 'Cannot take absolute value of non Real value'\n",
    "    \n",
    "#     return Tensor(Real(abs(items[0].first.value)))\n",
    "\n",
    "    return VariableFunction('abs', items).eval(environment)\n",
    "\n",
    "built_ins.register_grouping('|', '|', group_straight)\n",
    "built_ins.register_grouping('||', '||', group_straight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### New Item Seperators ',' and ';'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "built_ins.register_new_item_seperator(',', 1)\n",
    "built_ins.register_new_item_seperator(';', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Variabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "built_ins.register_var('PI', Tensor([Real(3.141592653589793238462643383279502884197)]))\n",
    "built_ins.register_var('e', Tensor([Real(2.718281828459045235360287471352662497757)]))\n",
    "built_ins.register_var('phi', Tensor([Real(1.61803398874989484820458683436563811772)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Declare Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Unary Operations: -, +\n",
    "built_ins.register_left_unary_operator('+', 7)\n",
    "built_ins.register_left_unary_operator('-', 7)\n",
    "\n",
    "# Binary Operations:\n",
    "\n",
    "# arithmetic\n",
    "built_ins.register_binary_operator('+',   3)\n",
    "built_ins.register_binary_operator('-',   3)\n",
    "built_ins.register_binary_operator('*',   4)\n",
    "built_ins.register_binary_operator('4',   4)\n",
    "built_ins.register_binary_operator('/',   4)\n",
    "built_ins.register_binary_operator('//',  4)\n",
    "built_ins.register_binary_operator('%',   4)\n",
    "built_ins.register_binary_operator('mod', 4)\n",
    "built_ins.register_binary_operator('^',   5)\n",
    "\n",
    "# matrix\n",
    "built_ins.register_binary_operator('#',   4)\n",
    "built_ins.register_binary_operator('matmul', 4)\n",
    "\n",
    "# vector\n",
    "built_ins.register_binary_operator('.*' , 4)\n",
    "built_ins.register_binary_operator('dot', 4)\n",
    "\n",
    "# root\n",
    "built_ins.register_left_unary_operator('$', 6)\n",
    "built_ins.register_binary_operator('$', 6)\n",
    "\n",
    "# function call\n",
    "built_ins.register_binary_operator('9', 9)\n",
    "built_ins.set_evaluation_parameter('9', 1, 'force_array', True)\n",
    "\n",
    "# function definition\n",
    "built_ins.register_binary_operator('=>', 1)\n",
    "built_ins.set_evaluation_parameter('=>', 0, 'references', True)\n",
    "built_ins.set_evaluation_parameter('=>', 1, 'evaluable', True)\n",
    "\n",
    "built_ins.register_binary_operator('=', 0)\n",
    "built_ins.set_evaluation_parameter('=', 0, 'references', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment: ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignment(environment, key, value):\n",
    "    \n",
    "    if type(key) == Array:\n",
    "        for k, v in zip(key, value):\n",
    "            assignment(environment, k, v)\n",
    "    else:\n",
    "        environment[key.first.value] = value\n",
    "        \n",
    "    return value\n",
    "\n",
    "built_ins.register_function('=', assignment, True, (Array, None))\n",
    "built_ins.register_function('=', assignment, True, (Reference, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Definition: =>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_function(environment, parameters, evaluable):\n",
    "    \n",
    "    if type(parameters) == Tensor and parameters.dtype == Reference:\n",
    "        parameter_names = [parameters.first.value]\n",
    "    elif type(parameters) == Array:\n",
    "        parameter_names = [p.first.value for p in parameters.data]\n",
    "    \n",
    "    parameter_types = tuple([None] * len(parameter_names))\n",
    "    \n",
    "    def function(environment):\n",
    "        return evaluable.eval(environment)\n",
    "    \n",
    "    function_signature = FunctionSignature('', function, parameter_names, parameter_types, parameter_ranks=None, parameter_shapes=None)\n",
    "\n",
    "    function_set = FunctionSet('')\n",
    "    function_set.add(function_signature)\n",
    "    \n",
    "    return function_set\n",
    "\n",
    "built_ins.register_function('=>', define_function, True, (Reference, None))\n",
    "built_ins.register_function('=>', define_function, True, (Array, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Unary Operations: -, +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "built_ins.register_function('+', lambda t:Tensor(Real(+t.first.value)), None, (Real,), (0,))\n",
    "built_ins.register_function('-', lambda t:Tensor(Real(-t.first.value)), None, (Real,), (0,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Binary Operantors: +, -, *, /, //, %, ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# A + B\n",
    "built_ins.register_function('+', lambda a, b: Tensor(Real(a.first.value + b.first.value)), None, (Real, Real), (0, 0))\n",
    "\n",
    "# A - B\n",
    "built_ins.register_function('-', lambda a, b: Tensor(Real(a.first.value - b.first.value)), None, (Real, Real), (0, 0))\n",
    "\n",
    "# A * B\n",
    "built_ins.register_function('*', lambda a, b: Tensor(Real(a.first.value * b.first.value)), None, (Real, Real), (0, 0))\n",
    "built_ins.register_function('4', lambda a, b: Tensor(Real(a.first.value * b.first.value)), None, (Real, Real), (0, 0))\n",
    "\n",
    "# A / B\n",
    "built_ins.register_function('/', lambda a, b: Tensor(Real(a.first.value / b.first.value)), None, (Real, Real), (0, 0))\n",
    "\n",
    "# A // B\n",
    "built_ins.register_function('//', lambda a, b: Tensor(Real(a.first.value // b.first.value)), None, (Real, Real), (0, 0))\n",
    "\n",
    "# A % B\n",
    "built_ins.register_function('%', lambda a, b: Tensor(Real(a.first.value % b.first.value)), None, (Real, Real), (0, 0))\n",
    "built_ins.register_function('mod', lambda a, b: Tensor(Real(a.first.value % b.first.value)), None, (Real, Real), (0, 0))\n",
    "\n",
    "# A ^ B\n",
    "built_ins.register_function('^', lambda a, b: Tensor(Real(a.first.value ** b.first.value)), None, (Real, Real), (0, 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Matrix Multiplication: # #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def matmul(A, B):\n",
    "    \n",
    "    a_shape = A.shape\n",
    "    b_shape = B.shape\n",
    "    \n",
    "    assert A.rank >= 2 and B.rank >= 2, 'left and right sides must be matrices'\n",
    "    assert a_shape[-1] == b_shape[-2], 'left n_cols must equal right n_rows'\n",
    "    \n",
    "    n_rows = a_shape[0]\n",
    "    n_cols = b_shape[1]\n",
    "    n_vec = a_shape[1]\n",
    "    shape = (n_rows , n_cols)\n",
    "    \n",
    "    data = np.empty(shape, dtype=object)\n",
    "    \n",
    "    for row in range(n_rows):\n",
    "        for col in range(n_cols):\n",
    "            v = 0\n",
    "            for i in range(n_vec):\n",
    "                v += A[(row, i)].first.value * B[(i, col)].first.value\n",
    "            data[row,col] = Real(v)\n",
    "    \n",
    "    return Tensor(data, shape)\n",
    "\n",
    "built_ins.register_function('#', matmul, None, (Real, Real), (2, 2))\n",
    "built_ins.register_function('matmul', matmul, None, (Real, Real), (2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Vector Dot Product: .*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def dot(A, B):\n",
    "    \n",
    "    a_shape = A.shape\n",
    "    b_shape = B.shape\n",
    "    \n",
    "    assert A.rank == 1 and B.rank == 1, 'left and right sides must be vectors'\n",
    "    assert a_shape == b_shape, 'vector length must match'\n",
    "    \n",
    "    n_vec = a_shape[-1]\n",
    "    \n",
    "    v = 0\n",
    "    for i in range(n_vec):\n",
    "        v += A[(i,)].first.value * B[(i,)].first.value\n",
    "    \n",
    "    return Tensor(Real(v))\n",
    "\n",
    "built_ins.register_function('.*', dot, None, (Real, Real), (1, 1))\n",
    "built_ins.register_function('dot', dot, None, (Real, Real), (1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Absolute value abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def absolute(A):\n",
    "    return Tensor(Real(abs(A.first.value)))\n",
    "\n",
    "built_ins.register_function('abs', absolute, None, (Real,), (0,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Root and Square root $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def root(A, B):\n",
    "    return Tensor(Real(math.pow(B.first.value, 1/A.first.value)))\n",
    "\n",
    "def sqrt(A):\n",
    "    return Tensor(Real(math.sqrt(A.first.value)))\n",
    "\n",
    "built_ins.register_function('$', sqrt, None, (Real,), (0,))\n",
    "built_ins.register_function('$', root, None, (Real, Real), (0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Function Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def function_call(environment, function_set, parameters):\n",
    "    return function_set.eval(environment, parameters)\n",
    "\n",
    "built_ins.register_function('9', function_call, True, (FunctionSet, Array))\n",
    "\n",
    "\n",
    "def foo(A):\n",
    "    return Tensor(Real(A.first.value * A.first.value))\n",
    "def bar(A, B):\n",
    "    return Tensor(Real(A.first.value * B.first.value))\n",
    "    \n",
    "built_ins.register_function('fun', foo, False, (Real,), (0,))\n",
    "built_ins.register_function('fun', bar, False, (Real, Real), (0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion Specifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Define Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Tokens Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "# operand kinds\n",
    "# group, close_group, return_to_group, binary, unary_left, unary_right, *_ = enum(10)\n",
    "# (\n",
    "#     OPERAND_TYPE_GROUP, \n",
    "#     OPERAND_TYPE_CLOSE_GROUP, \n",
    "#     OPERAND_TYPE_RETURN_TO_GROUP, \n",
    "#     OPERAND_TYPE_BINARY, \n",
    "#     OPERAND_TYPE_UNARY_LEFT, \n",
    "#     OPERAND_TYPE_UNARY_RIGHT, \n",
    "# *_) = enum(10)\n",
    "\n",
    "\n",
    "TOKEN_TYPE_STRING =   'string'\n",
    "TOKEN_TYPE_INTEGER =  'integer'\n",
    "TOKEN_TYPE_NUMBER =   'number'\n",
    "TOKEN_TYPE_OPERATOR = 'operand'\n",
    "TOKEN_TYPE_OPEN_GROUP = 'group'\n",
    "TOKEN_TYPE_LITERAL =  'literal'\n",
    "\n",
    "TOKEN_TYPE_OPEN_GROUP = 'open group'\n",
    "TOKEN_TYPE_CLOSE_GROUP = 'close group'\n",
    "TOKEN_TYPE_NEW_ITEM    = 'new item'\n",
    "TOKEN_TYPE_BINARY      = 'binary operand'\n",
    "TOKEN_TYPE_UNARY_LEFT  = 'left unary operand'\n",
    "TOKEN_TYPE_UNARY_RIGHT = 'right unary operand'\n",
    "\n",
    "OPERAND_TYPES = [\n",
    "    TOKEN_TYPE_OPEN_GROUP,\n",
    "    TOKEN_TYPE_CLOSE_GROUP, \n",
    "    TOKEN_TYPE_NEW_ITEM, \n",
    "    TOKEN_TYPE_BINARY, \n",
    "    TOKEN_TYPE_UNARY_LEFT, \n",
    "    TOKEN_TYPE_UNARY_RIGHT, \n",
    "]\n",
    "\n",
    "TOKEN_TYPE_VALUE = [\n",
    "    TOKEN_TYPE_STRING,\n",
    "    TOKEN_TYPE_INTEGER,\n",
    "    TOKEN_TYPE_NUMBER,\n",
    "    TOKEN_TYPE_LITERAL,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Token Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# binary_operands = [\n",
    "#     Operand(r'.',   8), \n",
    "#     Operand(r':',   6), \n",
    "#     Operand(r'^',   5), \n",
    "#     Operand(r'*',   4), \n",
    "#     Operand(r'/',   4), \n",
    "#     Operand(r'//',  4), \n",
    "#     Operand(r'%',   4), \n",
    "#     Operand(r'+',   3), \n",
    "#     Operand(r'-',   3), \n",
    "#     Operand(r'&&',  2), \n",
    "#     Operand(r'||',  2), \n",
    "#     Operand(r'xor', 2), \n",
    "#     Operand(r'==',  1), \n",
    "#     Operand(r'!=',  1), \n",
    "#     Operand(r'>',   1), \n",
    "#     Operand(r'>=',  1), \n",
    "#     Operand(r'<',   1), \n",
    "#     Operand(r'<=',  1), \n",
    "#     Operand(r'=',   0),\n",
    "# ]\n",
    "\n",
    "# binary_operands = built_ins.binary_operators\n",
    "\n",
    "# left_unary_operands = [\n",
    "#     Operand(r'+', 7), \n",
    "#     Operand(r'-', 7), \n",
    "#     Operand(r'~', 7), \n",
    "#     Operand(r'=', 0),\n",
    "# ]\n",
    "\n",
    "# right_unary_operands = [\n",
    "#     Operand(r'!', 7),\n",
    "# ]\n",
    "\n",
    "# new_item = [\n",
    "#     TokenNewItemDefinition(',', 1),\n",
    "#     TokenNewItemDefinition(';', 2),\n",
    "# ]\n",
    "\n",
    "# groups = [\n",
    "#     Group(r'\\(', r')'),\n",
    "#     Group(r'\\[', r']'),\n",
    "#     Group(r'\\{', r'}'),\n",
    "#     Group(r'[a-zA-Z][a-zA-Z0-9_]*\\(', r')'),\n",
    "# ]\n",
    "\n",
    "# close_group = [Operand(g.close_op, -1) for g in groups]\n",
    "\n",
    "# sort by length\n",
    "# binary_operands.sort(key = lambda o:(len(o.match), o.precedence), reverse=True)\n",
    "# left_unary_operands.sort(key = lambda o:(len(o.match), o.precedence), reverse=True)\n",
    "# right_unary_operands.sort(key = lambda o:(len(o.match), o.precedence), reverse=True)\n",
    "# new_item.sort(key = lambda o:(len(o.match), o.precedence), reverse=True)\n",
    "\n",
    "# (\n",
    "#     binary_operands,\n",
    "#     left_unary_operands,\n",
    "#     right_unary_operands,\n",
    "#     new_item,\n",
    "#     close_group,\n",
    "# )\n",
    "\n",
    "# TODO sort built in tokens\n",
    "\n",
    "token_definitions = {\n",
    "    TOKEN_TYPE_OPEN_GROUP:  built_ins.groups,\n",
    "    TOKEN_TYPE_CLOSE_GROUP: built_ins.groups, \n",
    "    TOKEN_TYPE_NEW_ITEM:    built_ins.new_items, \n",
    "    TOKEN_TYPE_BINARY:      built_ins.binary_operators, \n",
    "    TOKEN_TYPE_UNARY_LEFT:  built_ins.left_unary_operators, \n",
    "    TOKEN_TYPE_UNARY_RIGHT: built_ins.right_unary_operators, \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Operation Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def find_token_definition(string, token_type, f = lambda x:x.token):\n",
    "    for token_definition in token_definitions[token_type]:\n",
    "        if string == f(token_definition):\n",
    "#         if re.fullmatch(operator.re_match, string) != None:\n",
    "            return token_definition\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Define Token Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'string': '((\\\\\"\"\".*?\\\\\"\"\")|(\\'\\'\\'.*?\\'\\'\\')|(\".*?\")|(\\'.*?\\'))',\n",
       " 'integer': '((0b|0o|0d|0x|[0-9]+_)[0-9a-zA-Z,]+)',\n",
       " 'number': '((([\\\\.][0-9]+)|([0-9]+[\\\\.]?[0-9]*))([eE][-+]?[0-9]+)?)',\n",
       " 'literal': '([A-Za-z_][A-Za-z0-9_]*)',\n",
       " 'open group': '(\\\\|\\\\|)|(\\\\()|(\\\\[)|(\\\\|)',\n",
       " 'binary operand': '(matmul)|(mod)|(dot)|(\\\\/\\\\/)|(\\\\.\\\\*)|(\\\\=\\\\>)|(\\\\+)|(\\\\-)|(\\\\*)|(4)|(\\\\/)|(\\\\%)|(\\\\^)|(\\\\#)|(\\\\$)|(9)|(\\\\=)',\n",
       " 'left unary operand': '(\\\\+)|(\\\\-)|(\\\\$)',\n",
       " 'right unary operand': '()',\n",
       " 'new item': '(\\\\,)|(\\\\;)',\n",
       " 'close group': '(\\\\|\\\\|)|(\\\\))|(\\\\])|(\\\\|)'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def re_join(l, f=lambda x:x):\n",
    "    items = [f(i) for i in l]\n",
    "    items.sort(key=lambda x:len(x), reverse=True)\n",
    "    return '(' + ')|('.join([re.escape(i) for i in items]) + ')'\n",
    "\n",
    "# regex\n",
    "re_number =    r\"\"\"((([\\.][0-9]+)|([0-9]+[\\.]?[0-9]*))([eE][-+]?[0-9]+)?)\"\"\"\n",
    "re_integer =   r\"\"\"((0b|0o|0d|0x|[0-9]+_)[0-9a-zA-Z,]+)\"\"\"\n",
    "re_string =    r\"\"\"((\\\"\"\".*?\\\"\"\")|('''.*?''')|(\".*?\")|('.*?'))\"\"\"\n",
    "re_literal =   r\"\"\"([A-Za-z_][A-Za-z0-9_]*)\"\"\"\n",
    "\n",
    "\n",
    "re_open_group =           re_join(built_ins.groups, lambda x:x.open_token)\n",
    "re_close_group =          re_join(built_ins.groups, lambda x:x.close_token)\n",
    "re_binary_operands =      re_join(built_ins.binary_operators, lambda x:x.token)\n",
    "re_left_unary_operands =  re_join(built_ins.left_unary_operators, lambda x:x.token)\n",
    "re_right_unary_operands = re_join(built_ins.right_unary_operators, lambda x:x.token)\n",
    "re_new_item =             re_join(built_ins.new_items, lambda x:x.token)\n",
    "\n",
    "\n",
    "re_tokens = {\n",
    "    TOKEN_TYPE_STRING:      re_string,\n",
    "    TOKEN_TYPE_INTEGER:     re_integer,\n",
    "    TOKEN_TYPE_NUMBER:      re_number,\n",
    "    TOKEN_TYPE_LITERAL:     re_literal,\n",
    "    TOKEN_TYPE_OPEN_GROUP:  re_open_group,\n",
    "    TOKEN_TYPE_BINARY:      re_binary_operands,\n",
    "    TOKEN_TYPE_UNARY_LEFT:  re_left_unary_operands,\n",
    "    TOKEN_TYPE_UNARY_RIGHT: re_right_unary_operands,\n",
    "    TOKEN_TYPE_NEW_ITEM:    re_new_item,\n",
    "    TOKEN_TYPE_CLOSE_GROUP: re_close_group,\n",
    "}\n",
    "\n",
    "re_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Lexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def re_match_length(string, re_pattern):\n",
    "    match = re.match(re_pattern, string)\n",
    "    return match.span()[1] if match != None else 0\n",
    "\n",
    "# TOKEN_TYPE_STRING\n",
    "# TOKEN_TYPE_INTEGER\n",
    "# TOKEN_TYPE_NUMBER\n",
    "# TOKEN_TYPE_LITERAL\n",
    "\n",
    "# TOKEN_TYPE_OPEN_GROUP\n",
    "# TOKEN_TYPE_BINARY\n",
    "# TOKEN_TYPE_UNARY_LEFT\n",
    "# TOKEN_TYPE_UNARY_RIGHT\n",
    "# TOKEN_TYPE_NEW_ITEM\n",
    "# TOKEN_TYPE_CLOSE_GROUP\n",
    "\n",
    "def lexing(string, ans_available=False):\n",
    "    tokens = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(string):\n",
    "            \n",
    "        last_token_type = tokens[-1][0] if len(tokens) > 0 else None\n",
    "        allowed_token_types = []\n",
    "        allowed_token_types_with_implicit_op = {}\n",
    "\n",
    "        # begin with\n",
    "        if last_token_type in [\n",
    "            None,\n",
    "        ]:\n",
    "            \n",
    "            allowed_token_types = [TOKEN_TYPE_BINARY] if ans_available else []\n",
    "            allowed_token_types += [\n",
    "                TOKEN_TYPE_UNARY_LEFT,\n",
    "                TOKEN_TYPE_OPEN_GROUP,\n",
    "                TOKEN_TYPE_NEW_ITEM,\n",
    "                TOKEN_TYPE_CLOSE_GROUP,\n",
    "                *TOKEN_TYPE_VALUE,\n",
    "            ]\n",
    "        \n",
    "        if last_token_type in [\\\n",
    "            TOKEN_TYPE_OPEN_GROUP,\n",
    "            TOKEN_TYPE_NEW_ITEM,\n",
    "        ]:\n",
    "            allowed_token_types = [\n",
    "                TOKEN_TYPE_UNARY_LEFT,\n",
    "                TOKEN_TYPE_OPEN_GROUP,\n",
    "                TOKEN_TYPE_NEW_ITEM,\n",
    "                TOKEN_TYPE_CLOSE_GROUP,\n",
    "                *TOKEN_TYPE_VALUE,\n",
    "            ]\n",
    "\n",
    "        # after value excluding literal\n",
    "        if last_token_type in [\n",
    "            TOKEN_TYPE_CLOSE_GROUP,\n",
    "            TOKEN_TYPE_UNARY_RIGHT,\n",
    "            TOKEN_TYPE_STRING,\n",
    "            TOKEN_TYPE_INTEGER,\n",
    "            TOKEN_TYPE_NUMBER,\n",
    "        ]:\n",
    "            allowed_token_types = [\n",
    "                TOKEN_TYPE_UNARY_RIGHT,\n",
    "                TOKEN_TYPE_BINARY,\n",
    "                TOKEN_TYPE_NEW_ITEM,\n",
    "                TOKEN_TYPE_CLOSE_GROUP,\n",
    "            ]\n",
    "            allowed_token_types_with_implicit_op = {\n",
    "                TOKEN_TYPE_OPEN_GROUP: '4',\n",
    "                TOKEN_TYPE_LITERAL: '4',\n",
    "            }\n",
    "            \n",
    "        # after literal value\n",
    "        if last_token_type in [\n",
    "            TOKEN_TYPE_LITERAL,\n",
    "        ]:\n",
    "            allowed_token_types = [\n",
    "                TOKEN_TYPE_UNARY_RIGHT,\n",
    "                TOKEN_TYPE_BINARY,\n",
    "                TOKEN_TYPE_NEW_ITEM,\n",
    "                TOKEN_TYPE_CLOSE_GROUP,\n",
    "            ]\n",
    "            allowed_token_types_with_implicit_op = {\n",
    "                TOKEN_TYPE_OPEN_GROUP: '9',\n",
    "            }\n",
    "\n",
    "        # after operator\n",
    "        if last_token_type in [\n",
    "            TOKEN_TYPE_BINARY,\n",
    "            TOKEN_TYPE_UNARY_LEFT,\n",
    "\n",
    "        ]:\n",
    "            allowed_token_types = [\n",
    "                TOKEN_TYPE_OPEN_GROUP,\n",
    "                TOKEN_TYPE_UNARY_LEFT,\n",
    "                *TOKEN_TYPE_VALUE,\n",
    "            ]\n",
    "            \n",
    "        \n",
    "        # find matching token type\n",
    "        token_type, token_str = None, None\n",
    "        \n",
    "        all_allowed_token_types = [(t, None) for t in allowed_token_types] + list(allowed_token_types_with_implicit_op.items())\n",
    "        for possible_token_type, implicit_op in all_allowed_token_types:\n",
    "            re_pattern = re_tokens[possible_token_type]\n",
    "            \n",
    "            l = re_match_length(string[i:], re_pattern)\n",
    "            if l > 0:\n",
    "                \n",
    "                if implicit_op != None:\n",
    "                    tokens.append((TOKEN_TYPE_BINARY, implicit_op))\n",
    "                \n",
    "                token_type = possible_token_type\n",
    "                token_str = string[i:i+l]\n",
    "                break\n",
    "                \n",
    "\n",
    "                    \n",
    "        # invalid token\n",
    "        if token_type == None:\n",
    "#             raise Exception(f\"Token not allowed at position {i}\")\n",
    "            i += 1\n",
    "        else:\n",
    "            tokens.append((token_type, token_str))\n",
    "            i += len(token_str)\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Treeify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bubble_up(focus, new):\n",
    "    \"\"\"\n",
    "    Finds ancestor/parent in tree upwards from `token` thats the first group token or the first\n",
    "    \"\"\"\n",
    "    \n",
    "    while True:\n",
    "#         print('bubble_up', focus.value, type(focus))\n",
    "#         if type(focus) != NodeValue and (type(focus) == NodeGroup or focus.precedence < new.precedence):\n",
    "        if type(focus) == NodeGroup or focus.precedence < new.precedence:\n",
    "#             print('return', focus.value)\n",
    "            return focus\n",
    "        else:\n",
    "            focus = focus.parent\n",
    "        \n",
    "def bubble_up_to_group(focus):\n",
    "    while True:\n",
    "        if type(focus) == NodeGroup:\n",
    "            return focus\n",
    "        else:\n",
    "            focus = focus.parent\n",
    "\n",
    "# TOKEN_TYPE_STRING\n",
    "# TOKEN_TYPE_INTEGER\n",
    "# TOKEN_TYPE_NUMBER\n",
    "# TOKEN_TYPE_LITERAL\n",
    "\n",
    "# TOKEN_TYPE_OPEN_GROUP\n",
    "# TOKEN_TYPE_BINARY\n",
    "# TOKEN_TYPE_UNARY_LEFT\n",
    "# TOKEN_TYPE_UNARY_RIGHT\n",
    "\n",
    "# TOKEN_TYPE_NEW_ITEM\n",
    "# TOKEN_TYPE_CLOSE_GROUP\n",
    "\n",
    "def build_token_tree(tokens):\n",
    "    \n",
    "    root = NodeGroup(\"ROOT\", None)\n",
    "    focus = root\n",
    "    \n",
    "    for token_type, value in tokens:\n",
    "        \n",
    "        \n",
    "        # focus is\n",
    "        # Binary Operator\n",
    "        # Unary Operator\n",
    "        if type(focus) in [\n",
    "            NodeBinary,\n",
    "            NodeUnaryLeft,\n",
    "        ]:\n",
    "            \n",
    "            # next is \n",
    "            # Unary left\n",
    "            if token_type == TOKEN_TYPE_UNARY_LEFT:\n",
    "#                 print('insert lef unary')\n",
    "                \n",
    "                operand = find_token_definition(value, TOKEN_TYPE_UNARY_LEFT)\n",
    "                next_node = NodeUnaryLeft(operand)\n",
    "                \n",
    "                focus.set_right(next_node)\n",
    "                focus = next_node\n",
    "                \n",
    "            # next is\n",
    "            # Group\n",
    "            elif token_type == TOKEN_TYPE_OPEN_GROUP:\n",
    "#                 print('insert open group')\n",
    "                \n",
    "                group = find_token_definition(value, TOKEN_TYPE_OPEN_GROUP, lambda x:x.open_token)\n",
    "                next_node = NodeGroup(group)\n",
    "                focus.set_right(next_node)\n",
    "                focus = next_node\n",
    "            \n",
    "            # next is\n",
    "            # TOKEN_TYPE_STRING\n",
    "            # TOKEN_TYPE_INTEGER\n",
    "            # TOKEN_TYPE_NUMBER\n",
    "            # TOKEN_TYPE_LITERAL\n",
    "            elif token_type in TOKEN_TYPE_VALUE:\n",
    "#                 print('insert value')\n",
    "                \n",
    "                next_node = NodeValue(value, token_type)\n",
    "                focus.set_right(next_node)\n",
    "                focus = next_node\n",
    "                \n",
    "            else:\n",
    "                raise Exception(f\"token '{value}' not allowed here\")\n",
    "            \n",
    "            \n",
    "        # focus is\n",
    "        # Value\n",
    "        # Closed Group\n",
    "        elif type(focus) == NodeValue or (type(focus) == NodeGroup and focus.is_complete()):\n",
    "            \n",
    "            # next is\n",
    "            # Binary\n",
    "            if token_type == TOKEN_TYPE_BINARY:\n",
    "#                 print('insert binary')\n",
    "                \n",
    "                operand = find_token_definition(value, TOKEN_TYPE_BINARY)\n",
    "                next_node = NodeBinary(operand)\n",
    "                    \n",
    "                parent_node = bubble_up(focus.parent, next_node)\n",
    "                child_node = parent_node.get_right()\n",
    "                parent_node.set_right(next_node)\n",
    "                next_node.set_left(child_node)\n",
    "                focus = next_node\n",
    "                \n",
    "            \n",
    "            # next is\n",
    "            # Unary right\n",
    "            elif token_type == TOKEN_TYPE_UNARY_RIGHT:\n",
    "#                 print('insert right unary')\n",
    "                \n",
    "                operand = find_token_definition(value, TOKEN_TYPE_UNARY_RIGHT)\n",
    "                next_node = NodeUnaryRight(operand)\n",
    "                    \n",
    "                parent_node = focus.parent # bubble_up(focus.parent, next_node)\n",
    "                child_node = parent_node.get_right()\n",
    "                parent_node.set_right(next_node)\n",
    "                next_node.set_left(child_node)\n",
    "                # focus = next_node\n",
    "            \n",
    "            # next is\n",
    "            # New item\n",
    "            elif token_type == TOKEN_TYPE_NEW_ITEM:\n",
    "#                 print('new item')\n",
    "                \n",
    "                token_definition = find_token_definition(value, TOKEN_TYPE_NEW_ITEM)\n",
    "    \n",
    "                parent_node = bubble_up_to_group(focus.parent)\n",
    "                parent_node.increase(token_definition.depth)\n",
    "                focus = parent_node\n",
    "            \n",
    "            # next is\n",
    "            # New item\n",
    "            elif token_type == TOKEN_TYPE_CLOSE_GROUP:\n",
    "#                 print('close group')\n",
    "                \n",
    "                parent_node = bubble_up_to_group(focus.parent)\n",
    "                parent_node.close()\n",
    "                focus = parent_node\n",
    "            \n",
    "            # next is\n",
    "            else:\n",
    "                raise Exception(f\"token '{value}' not allowed here\")\n",
    "#                 print('start new item in parent group')\n",
    "        \n",
    "        \n",
    "        # focus is\n",
    "        # Open Group\n",
    "        elif type(focus) == NodeGroup and not focus.is_complete(): \n",
    "            \n",
    "            # next is\n",
    "            # Binary - use ans on left\n",
    "            if token_type == TOKEN_TYPE_BINARY:\n",
    "#                 print('insert binary with ans as left')\n",
    "\n",
    "                left = NodeValue('ans', TOKEN_TYPE_LITERAL)\n",
    "                \n",
    "                operand = find_token_definition(value, TOKEN_TYPE_BINARY)\n",
    "                next_node = NodeBinary(operand)\n",
    "                next_node.set_left(left)\n",
    "                \n",
    "                focus.add(next_node)\n",
    "                focus = next_node\n",
    "            \n",
    "            # next is\n",
    "            # Unary left\n",
    "            elif token_type == TOKEN_TYPE_UNARY_LEFT:\n",
    "#                 print('add unary left')\n",
    "                \n",
    "                operand = find_token_definition(value, TOKEN_TYPE_UNARY_LEFT)\n",
    "                next_node = NodeUnaryLeft(operand)\n",
    "                \n",
    "                focus.add(next_node)\n",
    "                focus = next_node\n",
    "            \n",
    "            # next is\n",
    "            # Group\n",
    "            elif token_type == TOKEN_TYPE_OPEN_GROUP:\n",
    "#                 print('add open group')\n",
    "                \n",
    "                group = find_token_definition(value, TOKEN_TYPE_OPEN_GROUP, lambda x:x.open_token)\n",
    "                next_node = NodeGroup(group)\n",
    "                focus.add(next_node)\n",
    "                focus = next_node\n",
    "            \n",
    "            # next is\n",
    "            # New item\n",
    "            elif token_type == TOKEN_TYPE_CLOSE_GROUP:\n",
    "#                 print('close group')\n",
    "                \n",
    "                focus.close()\n",
    "            \n",
    "            # next is\n",
    "            # TOKEN_TYPE_STRING\n",
    "            # TOKEN_TYPE_INTEGER\n",
    "            # TOKEN_TYPE_NUMBER\n",
    "            # TOKEN_TYPE_LITERAL\n",
    "            elif token_type in TOKEN_TYPE_VALUE:\n",
    "#                 print('add value')\n",
    "                \n",
    "                next_node = NodeValue(value, token_type)\n",
    "                focus.add(next_node)\n",
    "                focus = next_node\n",
    "                \n",
    "            # next is \n",
    "            # TOKEN_TYPE_NEW_ITEM\n",
    "            elif token_type == TOKEN_TYPE_NEW_ITEM:\n",
    "#                 print('new item/dimension')\n",
    "                \n",
    "                focus.increase()\n",
    "                \n",
    "            # next is\n",
    "            else:\n",
    "                raise Exception(f\"token '{value}' not allowed here\")\n",
    "#                 print('start new item in parent group')\n",
    "            \n",
    "        \n",
    "    \n",
    "    return root\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Computation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_computation_graphs(token_tree):\n",
    "    \n",
    "    satatement_root_tokens = token_tree.get_children()\n",
    "    statements = [Statement(t.get_evaluable()) for t in satatement_root_tokens]\n",
    "    \n",
    "    return statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excecute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Environment():\n",
    "       \n",
    "    def __init__(self, parent=None, dictionary=None):\n",
    "        self.parent = parent\n",
    "        self.dictionary = dictionary or {}\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \n",
    "        if key in self.dictionary:\n",
    "            return self.dictionary[key]\n",
    "        elif self.parent != None:\n",
    "            return self.parent[key]\n",
    "        else:\n",
    "            assert False, f'key {key} is not defined in this scope'\n",
    "        \n",
    "    def __setitem__(self, key, value):\n",
    "        \n",
    "        if type(key) in [list, tuple] and type(value) in [list, tuple]:\n",
    "            for k,v in zip(key, value):\n",
    "                self[key] = value\n",
    "        \n",
    "        else:\n",
    "            if key in self.dictionary:\n",
    "                self.dictionary[key] = value\n",
    "            elif self.parent != None:\n",
    "                self.parent[key] = value\n",
    "            else:\n",
    "                self.dictionary[key] = value\n",
    "    \n",
    "    def __contains__(self, key):\n",
    "        \n",
    "        if key in self.dictionary:\n",
    "            return True\n",
    "        elif self.parent != None:\n",
    "            return key in self.parent\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def enterScope(self, dictionary=None):\n",
    "        return Environment(self, dictionary)\n",
    "        \n",
    "    def exitScope(self):\n",
    "        return self if self.parent == None else self.parent\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'Environment({self.dictionary, self.parent})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def evaluate(computation_graphs, environment):\n",
    "    return [g.eval(environment) for g in computation_graphs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def calc(query, ans_available=False, debug=False):\n",
    "        \n",
    "#     commands\n",
    "#     if   query == 'exit':   break\n",
    "#     elif query == 'help':   help()\n",
    "#     elif query == 'ref':    ref()\n",
    "#     elif query == 'clear':  clear()\n",
    "#     elif query == 'copy':   pyperclip.copy(ans)\n",
    "#     elif query == '=':      pyperclip.copy(ans)\n",
    "\n",
    "#     # evaluate query\n",
    "#     elif query != \"\":\n",
    "    \n",
    "    built_in_variables = {k:v for k,v in built_ins.vars}\n",
    "    built_in_functions = {}\n",
    "    \n",
    "    for name, function, parameter_names, parameter_types, parameter_ranks, parameter_shapes in built_ins.functions:\n",
    "        \n",
    "        parameter_evaluation_parameters = built_ins.function_parameter_evaluation_parameters.get(name, {})\n",
    "        \n",
    "        built_in_functions[name] = built_in_functions.get(name, FunctionSet(name, parameter_evaluation_parameters))\n",
    "        built_in_functions[name].add(FunctionSignature(\n",
    "            name, \n",
    "            function, \n",
    "            parameter_names, \n",
    "            parameter_types, \n",
    "            parameter_ranks, \n",
    "            parameter_shapes\n",
    "        ))\n",
    "        \n",
    "    \n",
    "    environment = Environment(None, {**built_in_variables, **built_in_functions})\n",
    "    if debug: print(environment, end='\\n\\n')\n",
    "    \n",
    "    tokens = lexing(query, ans_available)\n",
    "    if debug: print(tokens, end='\\n\\n')\n",
    "    \n",
    "    token_tree = build_token_tree(tokens)\n",
    "    if debug: print(token_tree, end='\\n\\n')\n",
    "    \n",
    "    computation_graphs = build_computation_graphs(token_tree)\n",
    "    if debug: print(computation_graphs, end='\\n\\n')\n",
    "    \n",
    "    results = evaluate(computation_graphs, environment)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calc('(1 + [1,2,3]) * 2, 1 + [1,2,3] * 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calc('2 ^ [1,2,3,4], [1,2,3,4] ^ 2, [2,4,8] ^ [2,3,4], PI * [1/2, 1, 2,,,]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calc('[1,2,,3,4,,5,6] # [1,2,3,,4,5,6]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc('|0 - |10-100| |, |0-1|, ||0-1||, |[1,-1,2,-2]|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc('$[1,4,9,16], 3$[1,8,27,64], 0.1$10, 10^(1/0.1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc('[1,2,3] .* [3,2,1], [1,2,3,,] # [3,,2,,1], [1,2,3,,4,5,6] .* [4,5,6,,7,8,9]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc('x = 1, y = 2, x = 3, x^y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc('a = ((2, 4), 8), ((x, y), z) = a, x^y, y^z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calc('x = [1,2,,3,4], (a,b,c,d) = x, (a,b,c,d)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc('x = 5, 2 * x, 2(3)(3+4)x, 3x^2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tensor([Real(8.0)]),\n",
       " Tensor([Real(9.0)]),\n",
       " Tensor([Real(4.0) Real(10.0) Real(18.0)], (3,))]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc('fun(2, 4), fun(3), fun([1,2,3], [4,5,6])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FunctionSet(, {(None,): FunctionSignature('', <function define_function.<locals>.function at 0x00000171577F7C80>, ['x'], (None,), (None,), (None,))}),\n",
       " Tensor([Real(125.0)])]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc('f = x => x^3, f(5)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FunctionSet(, {(None, None): FunctionSignature('', <function define_function.<locals>.function at 0x00000171577F78C8>, ['x', 'y'], (None, None), (None, None), (None, None))}),\n",
       " Tensor([Real(81.0)]),\n",
       " Tensor([Real(1.0) Real(32.0) Real(729.0)], (3,))]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc('f = (x, y) => x^y, f(3,4), f([1,2,3], [4,5,6])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 275,
   "position": {
    "height": "297px",
    "left": "1537px",
    "right": "20px",
    "top": "119px",
    "width": "363px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
