{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import math, pyperclip, os, re\n",
    "from decimal import Decimal as _Decimal\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data types: Real, Complex, Int, Boolean, String, Undefined\n",
    "Data structures: Scalar, Vector, Matrix, ...\n",
    "Variables: v\n",
    "Functions: fun\n",
    "Named operators: v operation u\n",
    "Conversion specifier: 45deg\n",
    "Data properties: object.property\n",
    "Oppertation: Numeric, Sets, Comparison \n",
    "\n",
    "Named operators\n",
    "on two values: v operation u\n",
    "on one value: v.operation\n",
    "\n",
    "Input and Output conversion\n",
    "hex : 0b1100 * 3_210 + 15_12E3\n",
    "datetime : 2h + 45m + 1h + 30m\n",
    "base 4 : 10\n",
    "\n",
    "Basic Operations:\n",
    "Standard:       | Bitwise: int&bool | Comparison:           | \n",
    "+           add | ~             not | ==             equals | \n",
    "-      subtract | &&            and | !=          not equal | \n",
    "*      multiply | ||             or | <           less than | \n",
    "/        divide | <xor>         xor | >        greater then | \n",
    "//      int div | <<     left shift | <=      less or equal | \n",
    "%       modulus | >>    right shift | >=   greater or equal | \n",
    "^         power |                   |                       | \n",
    "!     factorial |                   |                       | \n",
    "|val|  absolute |                   |                       | \n",
    "=    assignment |                   |                       | \n",
    "\n",
    "Higher Ranking Data Structure Operations:\n",
    "Vector:                 | Matrix:                          | Reductions:\n",
    "<dot>       dot product | <matmul>   matrix multiplication | <all>\n",
    "<cross>   cross product | |mat|                            | <any>\n",
    "|vec|            length | .T              transpose matrix | <\n",
    ".length          length | \n",
    ".angle            angle | \n",
    "\n",
    "\n",
    "\n",
    "1 + sqrt 4\n",
    "1 + sqrt x\n",
    "1 + $4\n",
    "1 + 3 root 8\n",
    "1 + b root x\n",
    "1 + b $ x\n",
    "\n",
    "10 nPr 2\n",
    "n nPr r\n",
    "10 nCr 2\n",
    "n nCr r\n",
    "\n",
    "[1, 2,, 3, 4] matmul [5, 6,, 7, 8]\n",
    "[1, 2,, 3, 4] MatMul [5, 6,, 7, 8]\n",
    "[1, 2,, 3, 4] MATMUL [5, 6,, 7, 8]\n",
    "[1, 2,, 3, 4] # [5, 6,, 7, 8]\n",
    "mat1 matmul mat2\n",
    "mat1 MatMul mat2\n",
    "mat1 MATMUL mat2\n",
    "[1, 2,, 3, 4].T\n",
    "mat1.T\n",
    "\n",
    "5*x\n",
    "\n",
    "sin pi\n",
    "sin2 pi\n",
    "sini 0.5\n",
    "\n",
    "@display = scientific 8\n",
    "@display = hex\n",
    "\n",
    "\n",
    "Statistical Operations:\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DType():\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.dtype = name\n",
    "        self.value = None\n",
    "    \n",
    "    @staticmethod\n",
    "    def name(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def __str__(self):\n",
    "        return str(self.va)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Token Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Operands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Operand():\n",
    "    def __init__(self, match, precedence):\n",
    "        self.match = match\n",
    "        self.re_match = re.escape(match)\n",
    "        self.precedence = float(precedence)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Operand({self.re_match}, {self.precedence})'\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'Operand({self.re_match}, {self.precedence})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Group():\n",
    "    def __init__(self, re_match, close_op):\n",
    "        self.re_match = re_match\n",
    "        self.close_op = close_op\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Group({self.re_match}, {self.close_op})'\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'Group({self.re_match}, {self.close_op})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Tree Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Abstract NodeToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NodeToken():\n",
    "    \"\"\"\n",
    "    represents a token that can be parsed\n",
    "    \"\"\"\n",
    "        \n",
    "    def dict(self):\n",
    "        raise Exception('dict() not implemented')\n",
    "    \n",
    "    def is_complete(self):\n",
    "        raise Exception('is_complete() not implemented')\n",
    "        \n",
    "    def set_left(self, node):\n",
    "        raise Exception('set_left(node) not implemented')\n",
    "\n",
    "    def set_right(self, node):\n",
    "        raise Exception('set_right(node) not implemented')\n",
    "        \n",
    "    def get_right(self):\n",
    "        raise Exception('get_right() not implemented')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### NodeBinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NodeBinary(NodeToken):\n",
    "    \"\"\"\n",
    "    represents a token that can be parsed into a value/operation\n",
    "    \"\"\"\n",
    "    def __init__(self, value, precedence, parent=None):\n",
    "        self.parent = parent\n",
    "        self.value = value\n",
    "        self.precedence = precedence\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "    def dict(self):\n",
    "        return {self.value: {'left': self.left.dict(), 'right': self.right.dict()}}\n",
    "    \n",
    "    def is_complete(self):\n",
    "        return self.left != None and self.right != None\n",
    "        \n",
    "    def set_left(self, node):\n",
    "        self.left = node\n",
    "        node.parent = self\n",
    "\n",
    "    def set_right(self, node):\n",
    "        self.right = node\n",
    "        node.parent = self\n",
    "        \n",
    "    def get_right(self):\n",
    "        return self.right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### NodeUnaryLeft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NodeUnaryLeft(NodeToken):\n",
    "    \n",
    "    def __init__(self, value, precedence, parent=None):\n",
    "        self.parent = parent\n",
    "        self.value = value\n",
    "        self.precedence = precedence\n",
    "        self.child = None\n",
    "        \n",
    "    def dict(self):\n",
    "        return {self.value: {'child': self.child.dict()}}\n",
    "    \n",
    "    def is_complete(self):\n",
    "        return self.child != None\n",
    "        \n",
    "    def set_left(self, node):\n",
    "        self.child = node\n",
    "        node.parent = self\n",
    "\n",
    "    def set_right(self, node):\n",
    "        self.child = node\n",
    "        node.parent = self\n",
    "        \n",
    "    def get_right(self):\n",
    "        return self.child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### NodeUnaryRight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NodeUnaryRight(NodeToken):\n",
    "    \n",
    "    def __init__(self, value, precedence, parent=None):\n",
    "        self.parent = parent\n",
    "        self.value = value\n",
    "        self.precedence = precedence\n",
    "        self.child = None\n",
    "        \n",
    "    def dict(self):\n",
    "        return {self.value: {'child': self.child.dict()}}\n",
    "    \n",
    "    def is_complete(self):\n",
    "        return self.child != None\n",
    "        \n",
    "    def set_left(self, node):\n",
    "        self.child = node\n",
    "        node.parent = self\n",
    "\n",
    "    def set_right(self, node):\n",
    "        self.child = node\n",
    "        node.parent = self\n",
    "        \n",
    "    def get_right(self):\n",
    "        return self.child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### NodeGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NodeGroup(NodeToken):\n",
    "    \n",
    "    def __init__(self, value, closing_token, parent=None):\n",
    "        self.parent = parent\n",
    "        self.value = value\n",
    "        self.closing_token = closing_token\n",
    "        self.complete = False\n",
    "        self.children = []\n",
    "        \n",
    "        self.shape = {0:1}\n",
    "        self.sep_count = 0\n",
    "        \n",
    "    def dict(self):\n",
    "        return {(self.value, self.get_shape()): [c.dict() for c in self.children]}\n",
    "    \n",
    "    def is_complete(self):\n",
    "        return self.complete\n",
    "\n",
    "    def close(self):\n",
    "        self.sep_count = 0\n",
    "        self.complete = True\n",
    "        \n",
    "        expected_size = 1\n",
    "        for s in self.get_shape(): expected_size *= s\n",
    "            \n",
    "        if len(self.children) < expected_size:\n",
    "            raise Exception('Inconsistent dimensions')\n",
    "    \n",
    "    def set_right(self, node):\n",
    "        self.children[-1] = node\n",
    "        node.parent = self\n",
    "        \n",
    "    def get_right(self):\n",
    "        return self.children[-1]\n",
    "\n",
    "    def add(self, node):\n",
    "        self.children.append(node)\n",
    "        node.parent = self\n",
    "        \n",
    "        if self.sep_count >= len(self.shape):\n",
    "            for i in range(len(self.shape), self.sep_count+1):\n",
    "                self.shape[i-1] = self.shape.get(i-1, 1)\n",
    "            self.shape[self.sep_count-1] += 1\n",
    "            \n",
    "        self.sep_count = 0\n",
    "        \n",
    "    def increase(self):\n",
    "        self.sep_count += 1\n",
    "        \n",
    "        # ensure minumum number of dimensions exists\n",
    "        for i in range(len(self.shape), self.sep_count+1):\n",
    "            self.shape[i-1] = self.shape.get(i-1, 1)\n",
    "        \n",
    "#         shape_size = 1\n",
    "#         for d,s in self.shape.items(): shape_size *= s\n",
    "        \n",
    "#         dim = shape_size - len(self.children)\n",
    "#         print(f'shape_size:{shape_size}, children:{len(self.children)}, dim:{dim}')\n",
    "        \n",
    "#         if dim+1 >= len(self.shape):\n",
    "#             if dim > 0:\n",
    "#                 self.shape[dim-1] = self.shape.get(dim-1, 1) - 1\n",
    "#             self.shape[dim] = self.shape.get(dim, 1) + 1\n",
    "#             print(self.shape)\n",
    "    \n",
    "    def get_shape(self):\n",
    "        shape = [(d,s) for d,s in self.shape.items()]\n",
    "        shape.sort(key=lambda x:x[0], reverse=True)\n",
    "        shape = tuple(s for d,s in shape)\n",
    "        return shape\n",
    "    \n",
    "    def get_rank(self):\n",
    "        return len(self.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### NodeValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NodeValue(NodeToken):\n",
    "    \n",
    "    def __init__(self, value, kind, parent=None):\n",
    "        self.parent = parent\n",
    "        self.value = value\n",
    "        self.kind = kind\n",
    "        \n",
    "    def dict(self):\n",
    "        return self.value\n",
    "    \n",
    "    def is_complete(self):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluatable Tree Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract NodeEvaluable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeEvaluable():\n",
    "    \"\"\"\n",
    "    represents a node that can be evaluated\n",
    "    \"\"\"\n",
    "        \n",
    "    def dict(self):\n",
    "        raise Exception('dict() not implemented')\n",
    "    \n",
    "    def eval(self, environment):\n",
    "        raise Exception('eval(environment) not implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Display():\n",
    "    def __init__(self, node):\n",
    "        self.node = node\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy dtypes\n",
    "# {\n",
    "# 'int':     [numpy.int8,      numpy.int16,      numpy.int32,  numpy.int64], \n",
    "# 'uint':    [numpy.uint8,     numpy.uint16,     numpy.uint32, numpy.uint64], \n",
    "# 'float':   [numpy.float16,   numpy.float32,    numpy.float64], \n",
    "# 'complex': [numpy.complex64, numpy.complex128], \n",
    "# 'others':  [bool, object, bytes, str, numpy.void]\n",
    "# }\n",
    "\n",
    "dtypes = {\n",
    "    'int': np.uint64,\n",
    "    'real': object, # Decimal\n",
    "    'complex': np.complex128,\n",
    "    'bool': bool,\n",
    "    'str': str,\n",
    "}\n",
    "\n",
    "class Tensor():\n",
    "    \"\"\"\n",
    "    represents a value of any type and rank\n",
    "    \"\"\"\n",
    "    def __init__(self, dtype, rank=0, shape=()):\n",
    "        self.dtype = dtype\n",
    "        self.rank = rank\n",
    "        self.shape = shape\n",
    "        self.value = None\n",
    "        \n",
    "    def __get__(self, index):\n",
    "        return self.value[index]\n",
    "        \n",
    "    def __set__(self, index, value):\n",
    "        self.value[index] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Define Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Tokens Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "# operand kinds\n",
    "# group, close_group, return_to_group, binary, unary_left, unary_right, *_ = enum(10)\n",
    "# (\n",
    "#     OPERAND_TYPE_GROUP, \n",
    "#     OPERAND_TYPE_CLOSE_GROUP, \n",
    "#     OPERAND_TYPE_RETURN_TO_GROUP, \n",
    "#     OPERAND_TYPE_BINARY, \n",
    "#     OPERAND_TYPE_UNARY_LEFT, \n",
    "#     OPERAND_TYPE_UNARY_RIGHT, \n",
    "# *_) = enum(10)\n",
    "\n",
    "\n",
    "TOKEN_TYPE_STRING =   'string'\n",
    "TOKEN_TYPE_INTEGER =  'integer'\n",
    "TOKEN_TYPE_NUMBER =   'number'\n",
    "TOKEN_TYPE_OPERATOR = 'operand'\n",
    "TOKEN_TYPE_GROUP =    'group'\n",
    "TOKEN_TYPE_LITERAL =  'literal'\n",
    "\n",
    "TOKEN_TYPE_CLOSE_GROUP = 'close group'\n",
    "TOKEN_TYPE_NEW_ITEM    = 'new item'\n",
    "TOKEN_TYPE_BINARY      = 'binary operand'\n",
    "TOKEN_TYPE_UNARY_LEFT  = 'left unary operand'\n",
    "TOKEN_TYPE_UNARY_RIGHT = 'right unary operand'\n",
    "\n",
    "OPERAND_TYPES = [\n",
    "    TOKEN_TYPE_CLOSE_GROUP, \n",
    "    TOKEN_TYPE_NEW_ITEM, \n",
    "    TOKEN_TYPE_BINARY, \n",
    "    TOKEN_TYPE_UNARY_LEFT, \n",
    "    TOKEN_TYPE_UNARY_RIGHT, \n",
    "]\n",
    "\n",
    "TOKEN_TYPE_VALUE = [\n",
    "    TOKEN_TYPE_STRING,\n",
    "    TOKEN_TYPE_INTEGER,\n",
    "    TOKEN_TYPE_NUMBER,\n",
    "    TOKEN_TYPE_LITERAL,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Token Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Operand(xor, 2.0),\n",
       "  Operand(\\/\\/, 4.0),\n",
       "  Operand(\\&\\&, 2.0),\n",
       "  Operand(\\|\\|, 2.0),\n",
       "  Operand(\\=\\=, 1.0),\n",
       "  Operand(\\!\\=, 1.0),\n",
       "  Operand(\\>\\=, 1.0),\n",
       "  Operand(\\<\\=, 1.0),\n",
       "  Operand(\\., 8.0),\n",
       "  Operand(\\:, 6.0),\n",
       "  Operand(\\^, 5.0),\n",
       "  Operand(\\*, 4.0),\n",
       "  Operand(\\/, 4.0),\n",
       "  Operand(\\%, 4.0),\n",
       "  Operand(\\+, 3.0),\n",
       "  Operand(\\-, 3.0),\n",
       "  Operand(\\>, 1.0),\n",
       "  Operand(\\<, 1.0),\n",
       "  Operand(\\=, 0.0)],\n",
       " [Operand(\\+, 7.0), Operand(\\-, 7.0), Operand(\\~, 7.0), Operand(\\=, 0.0)],\n",
       " [Operand(\\!, 7.0)],\n",
       " [Operand(\\,, -1.0)],\n",
       " [Operand(\\), -1.0), Operand(\\], -1.0), Operand(\\}, -1.0), Operand(\\), -1.0)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_operands = [\n",
    "    Operand(r'.',   8), \n",
    "    Operand(r':',   6), \n",
    "    Operand(r'^',   5), \n",
    "    Operand(r'*',   4), \n",
    "    Operand(r'/',   4), \n",
    "    Operand(r'//',  4), \n",
    "    Operand(r'%',   4), \n",
    "    Operand(r'+',   3), \n",
    "    Operand(r'-',   3), \n",
    "    Operand(r'&&',  2), \n",
    "    Operand(r'||',  2), \n",
    "    Operand(r'xor', 2), \n",
    "    Operand(r'==',  1), \n",
    "    Operand(r'!=',  1), \n",
    "    Operand(r'>',   1), \n",
    "    Operand(r'>=',  1), \n",
    "    Operand(r'<',   1), \n",
    "    Operand(r'<=',  1), \n",
    "    Operand(r'=',   0),\n",
    "]\n",
    "\n",
    "left_unary_operands = [\n",
    "    Operand(r'+', 7), \n",
    "    Operand(r'-', 7), \n",
    "    Operand(r'~', 7), \n",
    "    Operand(r'=', 0),\n",
    "]\n",
    "\n",
    "right_unary_operands = [\n",
    "    Operand(r'!', 7),\n",
    "]\n",
    "\n",
    "new_item = [\n",
    "    Operand(r',', -1),\n",
    "]\n",
    "\n",
    "groups = [\n",
    "    Group(r'\\(', r')'),\n",
    "    Group(r'\\[', r']'),\n",
    "    Group(r'\\{', r'}'),\n",
    "    Group(r'[a-zA-Z][a-zA-Z0-9_]*\\(', r')'),\n",
    "]\n",
    "\n",
    "close_group = [Operand(g.close_op, -1) for g in groups]\n",
    "\n",
    "# sort by length\n",
    "binary_operands.sort(key = lambda o:(len(o.match), o.precedence), reverse=True)\n",
    "left_unary_operands.sort(key = lambda o:(len(o.match), o.precedence), reverse=True)\n",
    "right_unary_operands.sort(key = lambda o:(len(o.match), o.precedence), reverse=True)\n",
    "new_item.sort(key = lambda o:(len(o.match), o.precedence), reverse=True)\n",
    "\n",
    "(\n",
    "    binary_operands,\n",
    "    left_unary_operands,\n",
    "    right_unary_operands,\n",
    "    new_item,\n",
    "    close_group,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Operation Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def filter_attribute(items, exact={}, regex={}, reverse_regex={}):\n",
    "#     filtered = []\n",
    "    \n",
    "#     for item in items:\n",
    "#         match = True\n",
    "#         for p in exact:\n",
    "#             match &= getattr(item, p) == exact[p]\n",
    "#         for p in regex:\n",
    "#             match &= re.fullmatch(regex[p], getattr(item, p)) != None\n",
    "#         for p in reverse_regex:\n",
    "#             match &= re.fullmatch(getattr(item, p), reverse_regex[p]) != None\n",
    "            \n",
    "#         if match:\n",
    "#             filtered.append(item)\n",
    "            \n",
    "#     return filtered\n",
    "    \n",
    "    \n",
    "# def find_operand(string, op_kind):\n",
    "#     filtered = filter_attribute(operands, {'op_kind':op_kind},{},{'re_match':string})\n",
    "    \n",
    "#     if len(filtered) == 0:\n",
    "#         return None\n",
    "# #         raise Exception(f\"Operand '{string}' not found for this context.\")\n",
    "    \n",
    "#     return filtered[0]\n",
    "            \n",
    "        \n",
    "# def find_group(string):\n",
    "#     filtered = filter_attribute(groups, {},{},{'re_match':string})\n",
    "    \n",
    "#     if len(filtered) == 0:\n",
    "#         raise Exception(f\"Group token '{string}' not found.\")\n",
    "    \n",
    "#     return filtered[0]\n",
    "\n",
    "\n",
    "# def get_possible_operation_types(string):\n",
    "# #     types = [find_operand(string, t) for t in order]\n",
    "# #     types = [t for t in types if t != None]\n",
    "#     types = {t:find_operand(string, t) for t in OPERAND_TYPES}\n",
    "#     types = {t:o.op_kind for t,o in types.items() if o != None}\n",
    "#     return types\n",
    "\n",
    "def find_operand(string, operators):\n",
    "    for operator in operators:\n",
    "        if re.fullmatch(operator.re_match, string) != None:\n",
    "            return operator\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Define Token Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'string': '((\\\\\"\"\".*?\\\\\"\"\")|(\\'\\'\\'.*?\\'\\'\\')|(\".*?\")|(\\'.*?\\'))',\n",
       " 'integer': '((0b|0o|0d|0x|[0-9]+_)[0-9a-zA-Z,]+)',\n",
       " 'number': '((([\\\\.][0-9_]+)|([0-9_]+[\\\\.]?[0-9_]*))([eE][-+]?[0-9_]+)?[a-z]*)',\n",
       " 'literal': '([A-Za-z_][A-Za-z0-9_]*)',\n",
       " 'group': '(\\\\()|(\\\\[)|(\\\\{)|([a-zA-Z][a-zA-Z0-9_]*\\\\()',\n",
       " 'binary operand': '(xor)|(\\\\/\\\\/)|(\\\\&\\\\&)|(\\\\|\\\\|)|(\\\\=\\\\=)|(\\\\!\\\\=)|(\\\\>\\\\=)|(\\\\<\\\\=)|(\\\\.)|(\\\\:)|(\\\\^)|(\\\\*)|(\\\\/)|(\\\\%)|(\\\\+)|(\\\\-)|(\\\\>)|(\\\\<)|(\\\\=)',\n",
       " 'left unary operand': '(\\\\+)|(\\\\-)|(\\\\~)|(\\\\=)',\n",
       " 'right unary operand': '(\\\\!)',\n",
       " 'new item': '(\\\\,)',\n",
       " 'close group': '(\\\\))|(\\\\])|(\\\\})|(\\\\))'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def re_join(l, f=lambda x:x):\n",
    "    return '(' + ')|('.join([f(i) for i in l]) + ')'\n",
    "\n",
    "# regex\n",
    "re_number =    r\"\"\"((([\\.][0-9_]+)|([0-9_]+[\\.]?[0-9_]*))([eE][-+]?[0-9_]+)?[a-z]*)\"\"\"\n",
    "re_integer =   r\"\"\"((0b|0o|0d|0x|[0-9]+_)[0-9a-zA-Z,]+)\"\"\"\n",
    "re_string =    r\"\"\"((\\\"\"\".*?\\\"\"\")|('''.*?''')|(\".*?\")|('.*?'))\"\"\"\n",
    "re_literal =   r\"\"\"([A-Za-z_][A-Za-z0-9_]*)\"\"\"\n",
    "\n",
    "re_groups =               re_join(groups, lambda x:x.re_match)\n",
    "re_binary_operands =      re_join(binary_operands, lambda x:x.re_match)\n",
    "re_left_unary_operands =  re_join(left_unary_operands, lambda x:x.re_match)\n",
    "re_right_unary_operands = re_join(right_unary_operands, lambda x:x.re_match)\n",
    "re_new_item =             re_join(new_item, lambda x:x.re_match)\n",
    "re_close_group =          re_join(close_group, lambda x:x.re_match)\n",
    "\n",
    "\n",
    "re_tokens = {\n",
    "    TOKEN_TYPE_STRING:      re_string,\n",
    "    TOKEN_TYPE_INTEGER:     re_integer,\n",
    "    TOKEN_TYPE_NUMBER:      re_number,\n",
    "    TOKEN_TYPE_LITERAL:     re_literal,\n",
    "    TOKEN_TYPE_GROUP:       re_groups,\n",
    "    TOKEN_TYPE_BINARY:      re_binary_operands,\n",
    "    TOKEN_TYPE_UNARY_LEFT:  re_left_unary_operands,\n",
    "    TOKEN_TYPE_UNARY_RIGHT: re_right_unary_operands,\n",
    "    TOKEN_TYPE_NEW_ITEM:    re_new_item,\n",
    "    TOKEN_TYPE_CLOSE_GROUP: re_close_group,\n",
    "}\n",
    "\n",
    "re_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Lexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def re_match_length(string, re_pattern):\n",
    "    match = re.match(re_pattern, string)\n",
    "    return match.span()[1] if match != None else 0\n",
    "\n",
    "# TOKEN_TYPE_STRING\n",
    "# TOKEN_TYPE_INTEGER\n",
    "# TOKEN_TYPE_NUMBER\n",
    "# TOKEN_TYPE_LITERAL\n",
    "\n",
    "# TOKEN_TYPE_GROUP\n",
    "# TOKEN_TYPE_BINARY\n",
    "# TOKEN_TYPE_UNARY_LEFT\n",
    "# TOKEN_TYPE_UNARY_RIGHT\n",
    "# TOKEN_TYPE_NEW_ITEM\n",
    "# TOKEN_TYPE_CLOSE_GROUP\n",
    "\n",
    "TOKEN_TYPE_VALUE = [\n",
    "    TOKEN_TYPE_STRING,\n",
    "    TOKEN_TYPE_INTEGER,\n",
    "    TOKEN_TYPE_NUMBER,\n",
    "    TOKEN_TYPE_LITERAL,\n",
    "]\n",
    "\n",
    "def lexing(string):\n",
    "    tokens = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(string):\n",
    "            \n",
    "        last_token_type = tokens[-1][0] if len(tokens) > 0 else None\n",
    "        allowed_token_types = []\n",
    "\n",
    "        # begin with\n",
    "        if last_token_type in [\n",
    "            None,\n",
    "            TOKEN_TYPE_GROUP,\n",
    "            TOKEN_TYPE_NEW_ITEM,\n",
    "        ]:\n",
    "            allowed_token_types = [\n",
    "                TOKEN_TYPE_UNARY_LEFT,\n",
    "                TOKEN_TYPE_GROUP,\n",
    "                TOKEN_TYPE_NEW_ITEM,\n",
    "                TOKEN_TYPE_CLOSE_GROUP,\n",
    "                *TOKEN_TYPE_VALUE,\n",
    "            ]\n",
    "\n",
    "        # after value\n",
    "        if last_token_type in [\n",
    "            TOKEN_TYPE_CLOSE_GROUP,\n",
    "            TOKEN_TYPE_UNARY_RIGHT,\n",
    "            *TOKEN_TYPE_VALUE,\n",
    "        ]:\n",
    "            allowed_token_types = [\n",
    "                TOKEN_TYPE_UNARY_RIGHT,\n",
    "                TOKEN_TYPE_BINARY,\n",
    "                TOKEN_TYPE_NEW_ITEM,\n",
    "                TOKEN_TYPE_CLOSE_GROUP,\n",
    "            ]\n",
    "\n",
    "        # after operator\n",
    "        if last_token_type in [\n",
    "            TOKEN_TYPE_BINARY,\n",
    "            TOKEN_TYPE_UNARY_LEFT,\n",
    "\n",
    "        ]:\n",
    "            allowed_token_types = [\n",
    "                TOKEN_TYPE_GROUP,\n",
    "                TOKEN_TYPE_UNARY_LEFT,\n",
    "                *TOKEN_TYPE_VALUE,\n",
    "            ]\n",
    "            \n",
    "        \n",
    "        # find matching token type\n",
    "        token_type, token_str = None, None\n",
    "        \n",
    "        for possible_token_type in allowed_token_types:\n",
    "            re_pattern = re_tokens[possible_token_type]\n",
    "            \n",
    "            l = re_match_length(string[i:], re_pattern)\n",
    "            if l > 0:\n",
    "                token_type = possible_token_type\n",
    "                token_str = string[i:i+l]\n",
    "                break\n",
    "                \n",
    "\n",
    "                    \n",
    "        # invalid token\n",
    "        if token_type == None:\n",
    "#             raise Exception(f\"Token not allowed at position {i}\")\n",
    "            i += 1\n",
    "        else:\n",
    "            tokens.append((token_type, token_str))\n",
    "            i += len(token_str)\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Treeify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bubble_up(focus, new):\n",
    "    \"\"\"\n",
    "    Finds ancestor/parent in tree upwards from `token` thats the first group token or the first\n",
    "    \"\"\"\n",
    "    \n",
    "    while True:\n",
    "#         print('bubble_up', focus.value, type(focus))\n",
    "#         if type(focus) != NodeValue and (type(focus) == NodeGroup or focus.precedence < new.precedence):\n",
    "        if type(focus) == NodeGroup or focus.precedence < new.precedence:\n",
    "#             print('return', focus.value)\n",
    "            return focus\n",
    "        else:\n",
    "            focus = focus.parent\n",
    "        \n",
    "def bubble_up_to_group(focus):\n",
    "    while True:\n",
    "        if type(focus) == NodeGroup:\n",
    "            return focus\n",
    "        else:\n",
    "            focus = focus.parent\n",
    "\n",
    "# TOKEN_TYPE_STRING\n",
    "# TOKEN_TYPE_INTEGER\n",
    "# TOKEN_TYPE_NUMBER\n",
    "# TOKEN_TYPE_LITERAL\n",
    "\n",
    "# TOKEN_TYPE_GROUP\n",
    "# TOKEN_TYPE_BINARY\n",
    "# TOKEN_TYPE_UNARY_LEFT\n",
    "# TOKEN_TYPE_UNARY_RIGHT\n",
    "\n",
    "# TOKEN_TYPE_NEW_ITEM\n",
    "# TOKEN_TYPE_CLOSE_GROUP\n",
    "\n",
    "def build_token_tree(tokens):\n",
    "    \n",
    "    root = NodeGroup(\"ROOT\", None)\n",
    "    focus = root\n",
    "    \n",
    "    for token_type, value in tokens:\n",
    "        \n",
    "#         print('')\n",
    "#         print(f\"focus:{focus.value}, focus_type:{type(focus)}, value:{value}, token_type:{token_type}\")\n",
    "        \n",
    "        \n",
    "        # focus is\n",
    "        # Binary Operator\n",
    "        # Unary Operator\n",
    "        if type(focus) in [\n",
    "            NodeBinary,\n",
    "            NodeUnaryLeft,\n",
    "        ]:\n",
    "            \n",
    "            # next is \n",
    "            # Unary left\n",
    "            if token_type == TOKEN_TYPE_UNARY_LEFT:\n",
    "#                 print('insert lef unary')\n",
    "                \n",
    "                operand = find_operand(value, left_unary_operands)\n",
    "                next_node = NodeUnaryLeft(operand, operand.precedence)\n",
    "                \n",
    "                focus.set_right(next_node)\n",
    "                focus = next_node\n",
    "                \n",
    "            # next is\n",
    "            # Group\n",
    "            elif token_type == TOKEN_TYPE_GROUP:\n",
    "#                 print('insert open group')\n",
    "                \n",
    "                group = find_operand(value, groups)\n",
    "                next_node = NodeGroup(group, group.close_op)\n",
    "                focus.set_right(next_node)\n",
    "                focus = next_node\n",
    "            \n",
    "            # next is\n",
    "            # TOKEN_TYPE_STRING\n",
    "            # TOKEN_TYPE_INTEGER\n",
    "            # TOKEN_TYPE_NUMBER\n",
    "            # TOKEN_TYPE_LITERAL\n",
    "            elif token_type in TOKEN_TYPE_VALUE:\n",
    "#                 print('insert value')\n",
    "                \n",
    "                next_node = NodeValue(value, token_type)\n",
    "                focus.set_right(next_node)\n",
    "                focus = next_node\n",
    "                \n",
    "            else:\n",
    "                raise Exception(f\"token '{value}' not allowed here\")\n",
    "            \n",
    "            \n",
    "        # focus is\n",
    "        # Value\n",
    "        # Closed Group\n",
    "        elif type(focus) == NodeValue or (type(focus) == NodeGroup and focus.is_complete()):\n",
    "            \n",
    "            # next is\n",
    "            # Binary\n",
    "            if token_type == TOKEN_TYPE_BINARY:\n",
    "#                 print('insert binary')\n",
    "                \n",
    "                operand = find_operand(value, binary_operands)\n",
    "                next_node = NodeBinary(operand, operand.precedence)\n",
    "                    \n",
    "                parent_node = bubble_up(focus.parent, next_node)\n",
    "                child_node = parent_node.get_right()\n",
    "                parent_node.set_right(next_node)\n",
    "                next_node.set_left(child_node)\n",
    "                focus = next_node\n",
    "                \n",
    "            \n",
    "            # next is\n",
    "            # Unary right\n",
    "            elif token_type == TOKEN_TYPE_UNARY_RIGHT:\n",
    "#                 print('insert right unary')\n",
    "                \n",
    "                operand = find_operand(value, right_unary_operands)\n",
    "                next_node = NodeUnaryRight(operand, operand.precedence)\n",
    "                    \n",
    "                parent_node = focus.parent # bubble_up(focus.parent, next_node)\n",
    "                child_node = parent_node.get_right()\n",
    "                parent_node.set_right(next_node)\n",
    "                next_node.set_left(child_node)\n",
    "                # focus = next_node\n",
    "            \n",
    "            # next is\n",
    "            # Close group\n",
    "            elif token_type == TOKEN_TYPE_NEW_ITEM:\n",
    "#                 print('new item')\n",
    "                \n",
    "                parent_node = bubble_up_to_group(focus.parent)\n",
    "                parent_node.increase()\n",
    "                focus = parent_node\n",
    "            \n",
    "            # next is\n",
    "            # New item\n",
    "            elif token_type == TOKEN_TYPE_CLOSE_GROUP:\n",
    "#                 print('close group')\n",
    "                \n",
    "                parent_node = bubble_up_to_group(focus.parent)\n",
    "                parent_node.close()\n",
    "                focus = parent_node\n",
    "            \n",
    "            # next is\n",
    "            else:\n",
    "                raise Exception(f\"token '{value}' not allowed here\")\n",
    "#                 print('start new item in parent group')\n",
    "        \n",
    "        \n",
    "        # focus is\n",
    "        # Open Group\n",
    "        elif type(focus) == NodeGroup and not focus.is_complete(): \n",
    "            \n",
    "            # next is\n",
    "            # Unary left\n",
    "            if token_type == TOKEN_TYPE_UNARY_LEFT:\n",
    "#                 print('add unary left')\n",
    "                \n",
    "                operand = find_operand(value, left_unary_operands)\n",
    "                next_node = NodeUnary(operand, operand.precedence)\n",
    "                \n",
    "                focus.add(next_node)\n",
    "                focus = next_node\n",
    "            \n",
    "            # next is\n",
    "            # Group\n",
    "            elif token_type == TOKEN_TYPE_GROUP:\n",
    "#                 print('add open group')\n",
    "                \n",
    "                group = find_operand(value, groups)\n",
    "                next_node = NodeGroup(group, group.close_op)\n",
    "                focus.add(next_node)\n",
    "                focus = next_node\n",
    "            \n",
    "            # next is\n",
    "            # New item\n",
    "            elif token_type == TOKEN_TYPE_CLOSE_GROUP:\n",
    "#                 print('close group')\n",
    "                \n",
    "                focus.close()\n",
    "            \n",
    "            # next is\n",
    "            # TOKEN_TYPE_STRING\n",
    "            # TOKEN_TYPE_INTEGER\n",
    "            # TOKEN_TYPE_NUMBER\n",
    "            # TOKEN_TYPE_LITERAL\n",
    "            elif token_type in TOKEN_TYPE_VALUE:\n",
    "#                 print('add value')\n",
    "                \n",
    "                next_node = NodeValue(value, token_type)\n",
    "                focus.add(next_node)\n",
    "                focus = next_node\n",
    "                \n",
    "            # next is \n",
    "            # TOKEN_TYPE_NEW_ITEM\n",
    "            elif token_type == TOKEN_TYPE_NEW_ITEM:\n",
    "#                 print('new item/dimension')\n",
    "                \n",
    "                focus.increase()\n",
    "                \n",
    "            \n",
    "            # next is\n",
    "            else:\n",
    "                raise Exception(f\"token '{value}' not allowed here\")\n",
    "#                 print('start new item in parent group')\n",
    "            \n",
    "        \n",
    "    \n",
    "    return root\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_evaluation_tree(token_tree):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def evaluate(expression):\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(query):\n",
    "        \n",
    "#     commands\n",
    "#     if   query == 'exit':   break\n",
    "#     elif query == 'help':   help()\n",
    "#     elif query == 'ref':    ref()\n",
    "#     elif query == 'clear':  clear()\n",
    "#     elif query == 'copy':   pyperclip.copy(ans)\n",
    "#     elif query == '=':      pyperclip.copy(ans)\n",
    "\n",
    "#     # evaluate query\n",
    "#     elif query != \"\":\n",
    "\n",
    "    tokens = lexing(query)\n",
    "    print(tokens, end='\\n\\n')\n",
    "    \n",
    "    token_tree = build_token_tree(tokens)\n",
    "    print(token_tree.dict(), end='\\n\\n')\n",
    "    \n",
    "    evaluation_tree = build_evaluation_tree(token_tree)\n",
    "    print(evaluation_tree.dict(), end='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('group', '('), ('number', '1.2e-4'), ('binary operand', '+'), ('literal', 'e'), ('close group', ')'), ('binary operand', '^'), ('left unary operand', '-'), ('number', '2j'), ('right unary operand', '!'), ('binary operand', '-'), ('number', '000.4e3j'), ('binary operand', '%'), ('group', 'fun('), ('number', '12cm'), ('new item', ','), ('literal', 'a'), ('new item', ','), ('number', '7'), ('close group', ')'), ('binary operand', '.'), ('literal', 'abs')]\n",
      "\n",
      "{('ROOT', (1,)): [{Operand(\\-, 3.0): {'left': {Operand(\\^, 5.0): {'left': {(Group(\\(, )), (1,)): [{Operand(\\+, 3.0): {'left': '1.2e-4', 'right': 'e'}}]}, 'right': {Operand(\\-, 7.0): {'child': {Operand(\\!, 7.0): {'child': '2j'}}}}}}, 'right': {Operand(\\%, 4.0): {'left': '000.4e3j', 'right': {Operand(\\., 8.0): {'left': {(Group([a-zA-Z][a-zA-Z0-9_]*\\(, )), (3,)): ['12cm', 'a', '7']}, 'right': 'abs'}}}}}}]}\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-26dc094143a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcalc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'(1.2e-4+e) ^ -2j! -000.4e3j % fun(12cm, a, 7).abs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-23-acc9e400ea94>\u001b[0m in \u001b[0;36mcalc\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mevaluation_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_evaluation_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_tree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluation_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\n\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'dict'"
     ]
    }
   ],
   "source": [
    "calc('(1.2e-4+e) ^ -2j! -000.4e3j % fun(12cm, a, 7).abs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
